import os
import streamlit as st
import logging
import google.auth
from vertexai.preview.generative_models import GenerativeModel, GenerationConfig, Part

# Configure logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

# Gemini configuration exactly as per your template (no location or explicit project ID)
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "D:/datascience-254609-genai.json"
credentials, project_id = google.auth.default()
transcription_model = GenerativeModel("gemini-1.5-flash-002")

# Define the transcription prompt and audio file URI
prompt = """
Can you transcribe this interview, in the format of timecode, speaker, caption.
Use speaker A, speaker B, etc. to identify speakers.
"""
audio_file_uri = "gs://cloud-samples-data/generative-ai/audio/pixel.mp3"
audio_file = Part.from_uri(audio_file_uri, mime_type="audio/mpeg")
contents = [audio_file, prompt]

# Streamlit UI
st.title("Gemini Transcription App")
st.write("Click the button below to transcribe the sample audio.")

if st.button("Transcribe Audio"):
    try:
        response = transcription_model.generate_content(contents, generation_config=GenerationConfig(audio_timestamp=True))
        st.text_area("Transcription Output", response.text)
    except Exception as e:
        st.error(f"An error occurred: {str(e)}")
        logger.error("Transcription error", exc_info=True)
