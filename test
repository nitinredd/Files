import os
import time
import logging
import json

import google.auth
import pandas as pd
import streamlit as st
from rapidfuzz import process, fuzz
from vertexai.preview.generative_models import (
    GenerativeModel,
    SafetySetting,
    HarmCategory,
    HarmBlockThreshold,
)

# ---------- Logging ----------
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

# ---------- Configuration ----------
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "D:/datascience-254609-genai.json"
credentials, project_id = google.auth.default()

# Use multimodal Gemini 2.5 Pro
model = GenerativeModel("gemini-2.0-flash-thinking-exp-01-21")

safety_config = [
    SafetySetting(category=HarmCategory.HARM_CATEGORY_UNSPECIFIED, threshold=HarmBlockThreshold.BLOCK_NONE),
    SafetySetting(category=HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold=HarmBlockThreshold.BLOCK_NONE),
    SafetySetting(category=HarmCategory.HARM_CATEGORY_HARASSMENT, threshold=HarmBlockThreshold.BLOCK_NONE),
    SafetySetting(category=HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold=HarmBlockThreshold.BLOCK_NONE),
    SafetySetting(category=HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold=HarmBlockThreshold.BLOCK_NONE),
]

# ---------- Safe LLM Call ----------
def safe_gemini_text_call(prompt: str, max_retries: int = 3, delay: float = 2.0) -> str:
    for attempt in range(1, max_retries + 1):
        try:
            logger.debug(f"Gemini call attempt {attempt} | prompt length={len(prompt)}")
            resp = model.generate_content([prompt], safety_settings=safety_config)
            if hasattr(resp, "text") and resp.text:
                return resp.text.strip()
            if "blocked" in str(resp).lower():
                raise ValueError("Blocked by safety filter")
            raise ValueError("Empty response from Gemini")
        except Exception as e:
            logger.warning(f"Attempt {attempt} failed: {e}")
            if attempt < max_retries:
                time.sleep(delay)
            else:
                logger.error("Max retries reached, aborting.")
                raise
    raise RuntimeError("safe_gemini_text_call unexpected exit")

# ---------- Agents ----------
class Agent:
    def __init__(self, name: str): self.name = name
    def handle(self, *args, **kwargs):
        raise NotImplementedError

class QueryUnderstandingAgent(Agent):
    def __init__(self): super().__init__("QueryUnderstandingAgent")
    def handle(self, query: str) -> dict:
        # fallback simple regex entity extraction
        import re
        eq = re.search(r"equipment\s+(\w+)", query, re.I)
        pl = re.search(r"plant\s+(\w+)", query, re.I)
        # parameter is rest of the query minus equipment and plant terms
        param = query
        for w in [eq.group(1) if eq else None, pl.group(1) if pl else None]:
            if w:
                param = re.sub(re.escape(w), "", param, flags=re.IGNORECASE)
        # remove filler words
        param = re.sub(r"\b(what|is|the|in|for|of|range|unit|operation|equipment|plant)\b", "", param, flags=re.IGNORECASE).strip()
        return {"equipment": eq.group(1) if eq else None,
                "plant": pl.group(1)     if pl else None,
                "parameter": param}

class SchemaRetrievalAgent(Agent):
    def __init__(self, reader):
        super().__init__("SchemaRetrievalAgent")
        self.reader = reader
    def handle(self, intent: dict) -> dict:
        # fallback: fuzzy match parameter to all sheet columns
        best = {}
        for sheet, cols in self.reader.sheets.items():
            # fuzzy match parameter to column names
            matches = process.extract(intent['parameter'], cols.columns.tolist(), scorer=fuzz.token_set_ratio, score_cutoff=40)
            if matches:
                best[sheet] = [m[0] for m in matches]
        return best

class DataExtractionAgent(Agent):
    def __init__(self, reader):
        super().__init__("DataExtractionAgent")
        self.reader = reader
    def handle(self, intent: dict, schema_map: dict) -> dict:
        results = {}
        for sheet, cols in schema_map.items():
            df = self.reader.sheets.get(sheet)
            if df is None or df.empty:
                continue
            sub = df
            # filter by equipment term: match against any column
            if intent.get("equipment"):
                eq_col, score, _ = process.extractOne(intent["equipment"], sub.columns, scorer=fuzz.token_set_ratio)
                sub = sub[sub[eq_col].astype(str).str.contains(intent["equipment"], case=False, regex=False)]
            # filter by plant term
            if intent.get("plant"):
                pl_col, score, _ = process.extractOne(intent["plant"], sub.columns, scorer=fuzz.token_set_ratio)
                sub = sub[sub[pl_col].astype(str).str.contains(intent["plant"], case=False, regex=False)]
            if sub.empty:
                continue
            # select only matched parameter columns
            selected = [c for c in cols if c in sub.columns]
            if selected:
                results[sheet] = sub[selected]
        return results

class ResponseGenerationAgent(Agent):
    def __init__(self): super().__init__("ResponseGenerationAgent")
    def handle(self, intent: dict, extracted: dict) -> str:
        text = f"**Results for '{intent['parameter']}'** on equipment **{intent['equipment']}** in plant **{intent['plant']}**:\n"
        for sheet, df in extracted.items():
            text += f"\n**Sheet: {sheet}**\n" + df.to_markdown(index=False) + "\n"
        return text

class CoordinatorAgent(Agent):
    def __init__(self, reader):
        super().__init__("Coordinator")
        self.understander = QueryUnderstandingAgent()
        self.schema       = SchemaRetrievalAgent(reader)
        self.extractor    = DataExtractionAgent(reader)
        self.generator    = ResponseGenerationAgent()
    def handle(self, query: str):
        intent     = self.understander.handle(query)
        schema_map = self.schema.handle(intent)
        extracted  = self.extractor.handle(intent, schema_map)
        if not extracted:
            return None, None
        resp = self.generator.handle(intent, extracted)
        return resp, extracted

# ---------- Excel Reader ----------
class ExcelReaderAgent(Agent):
    def __init__(self, files):
        super().__init__("ExcelReader")
        self.sheets = {}
        for f in files:
            xl = pd.ExcelFile(f)
            for s in xl.sheet_names:
                self.sheets[s] = xl.parse(s)

# ---------- Streamlit UI ----------
st.set_page_config(page_title="Excel Chatbot", layout="wide")

if 'agents' not in st.session_state:
    files = ['formula master_osd.xlsx', 'masterlist osd equipments.xlsx']
    reader      = ExcelReaderAgent(files)
    coordinator = CoordinatorAgent(reader)
    st.session_state['agents'] = {'reader': reader, 'coordinator': coordinator}

reader      = st.session_state['agents']['reader']
coordinator = st.session_state['agents']['coordinator']

st.title("Agentic Excel Chatbot")
query = st.text_input("Enter your question:")
if st.button("Ask") and query:
    with st.spinner("Thinking..."):
        try:
            answer, extracted = coordinator.handle(query)
            if not extracted:
                st.error("No matching data found.")
            else:
                st.markdown(answer)
        except Exception as e:
            logger.exception("Error in pipeline")
            st.error(f"Failed: {e}")
