"""
Python Version: 3.8+

Requirements (requirements.txt):
-------------------------------
streamlit
pandas
langchain
vertexai-preview      # (or the appropriate package name for Gemini)
google-auth
openpyxl              # for reading Excel files
-------------------------------
"""

import os
import logging
import sqlite3
import re

import streamlit as st
import pandas as pd
import google.auth

# -------------------------------
# Gemini 2.0 Flash-Thinking Setup
# -------------------------------
from vertexai.preview.generative_models import (
    GenerativeModel,
    SafetySetting,
    HarmCategory,
    HarmBlockThreshold,
)

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

# Set up credentials for Vertex AI
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "D:/datascience-254609-genai.json"
credentials, project_id = google.auth.default()

# Initialize the Gemini 2.0 flash-thinking model
gemini_model = GenerativeModel("gemini-2.0-flash-thinking-exp-01-21")

# Define model safety settings (adjust enum names as required)
safety_config = [
    SafetySetting(
         category=HarmCategory.UNSPECIAL,  # adjust as needed
         threshold=HarmBlockThreshold.BLOCK_NONE
    ),
    SafetySetting(
         category=HarmCategory.RANGEROUS_CONIENT,  # adjust to your actual enum name
         threshold=HarmBlockThreshold.BLOCK_NONE
    )
]

# -------------------------------
# Wrap Gemini as a LangChain LLM
# -------------------------------
from langchain.llms.base import LLM
from typing import Optional, List

class GeminiLLM(LLM):
    """
    A simple wrapper for Gemini 2.0 flash-thinking that conforms to the LangChain LLM interface.
    """
    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:
        logger.debug("Sending prompt to Gemini: %s", prompt)
        response = gemini_model.generate(prompt, safety_config=safety_config)
        logger.debug("Gemini response: %s", response.text)
        return response.text

    @property
    def _identifying_params(self) -> dict:
        return {"model": "gemini-2.0-flash-thinking-exp-01-21"}

    @property
    def _llm_type(self) -> str:
        return "gemini"

# -------------------------------
# Function: Create an agent for a single sheet
# -------------------------------
from langchain.agents import create_sql_agent
from langchain.sql_database import SQLDatabase

def create_agent_for_sheet(sheet_name: str, df: pd.DataFrame, llm: LLM):
    """
    Given a sheet name and its DataFrame, create an in-memory SQLite database with a table 'data'
    and return a LangChain SQL agent restricted to that table.
    """
    # Create an in-memory SQLite database for this sheet
    conn = sqlite3.connect(":memory:")
    df.to_sql("data", conn, index=False, if_exists="replace")
    
    # Create a SQLDatabase object using the connection
    sql_db = SQLDatabase(conn=conn)
    
    # Create a SQL agent; the agent will be limited to querying the table "data"
    agent = create_sql_agent(llm=llm, database=sql_db, verbose=True)
    return agent

# -------------------------------
# Load Embedded Excel Workbook
# -------------------------------
# The workbook is embedded in the code (assumed to be in the same directory)
EXCEL_FILE = "embedded_workbook.xlsx"

try:
    # Read all sheets from the embedded Excel file
    sheets_dict = pd.read_excel(EXCEL_FILE, sheet_name=None, engine="openpyxl")
    st.success(f"Loaded embedded workbook with {len(sheets_dict)} sheet(s).")
except Exception as e:
    st.error(f"Error reading embedded Excel file: {e}")
    sheets_dict = {}

# Expected sheet names (adjust these names based on your actual workbook)
expected_sheet_names = [
    "child1_prod_cust_data", 
    "child1_sku_cust_data",
    "child2_sku_cust_data",
    "child2_prod_cust_data",
    "child3_prod_cust_data",
    "child3_sku_cust_data",
    "sheet1"
]

# Create a dictionary to store agents for each sheet (only for sheets that exist)
agents = {}
for sheet in expected_sheet_names:
    if sheet in sheets_dict:
        df = sheets_dict[sheet]
        agents[sheet] = create_agent_for_sheet(sheet, df, GeminiLLM())
        st.write(f"Agent created for sheet: **{sheet}** (Rows: {len(df)})")
    else:
        st.warning(f"Expected sheet '{sheet}' not found in the workbook.")

# -------------------------------
# Streamlit App Interface
# -------------------------------
st.set_page_config(page_title="Multi-Sheet Excel Query", layout="centered")
st.title("Multi-Sheet Excel Query Interface")
st.write("Enter your query below to get actionable insights from your embedded Excel workbook.")

# Text input for the query (centered on the page)
user_query = st.text_input("Your Query:", key="query_input")

# Display three dynamic example prompts below the text input
st.markdown("#### Example Prompts:")
col1, col2, col3 = st.columns(3)
if col1.button("Total sales by region"):
    st.session_state.query_input = "Show me the total sales by region."
if col2.button("Top-selling product"):
    st.session_state.query_input = "Which product had the highest sales?"
if col3.button("Sales trends over time"):
    st.session_state.query_input = "What are the trends in sales over time?"

# When the user clicks "Run Query", process the query across all agents
if st.button("Run Query"):
    if user_query.strip() == "":
        st.error("Please enter a query.")
    else:
        results = {}
        st.info("Processing query on all sheets. This may take a moment...")
        for sheet_name, agent in agents.items():
            try:
                st.write(f"**Running query on sheet: {sheet_name}**")
                result = agent.run(user_query)
                results[sheet_name] = result
                st.markdown(f"**Result from {sheet_name}:**")
                st.write(result)
            except Exception as e:
                st.error(f"Error processing query on sheet {sheet_name}: {e}")

        # Aggregated Results (display all responses)
        st.markdown("## Aggregated Results")
        for sheet_name, res in results.items():
            st.markdown(f"### {sheet_name}")
            st.write(res)
