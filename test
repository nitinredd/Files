import os
import io
import json
import sqlite3
import pandas as pd
import logging
import speech_recognition as sr
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, StreamingResponse
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
import tempfile

from gtts import gTTS
from langchain_openai import AzureChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.tools import Tool
from langchain.agents import create_react_agent, AgentExecutor
from langchain import hub

# ─── CONFIG ──────────────────────────────────────────────────────

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Azure GPT configuration
base_url=""
api_version="2024-02-15-preview"
api_key=""
deployment_name="GPT4o"
model_name="GPT4o"

# Paths to embedded JSON files
EMBEDDED_FILES = {
    'data_1': r"C:\Users\Desktop\WORK\Formulations\Scale_up_Predictor_chatbot\Dataset\Prime_M+F_JSON.json",
}

# Sample tiles
TILE_QUESTIONS = {
    "Product A": ["What is the API used?", "What is the batch size?", "Who is the manufacturer?"],
    "Line B":    ["What is the speed range?", "What equipment is used?", "What is the pressure limit?"],
    "Facility X":["Who owns this facility?", "What lines are operational?"],
    "Formulation Z": ["List excipients used", "Describe dissolution method"],
    "Process Y": ["Steps in granulation?", "Drying temperature?"],
    "Machine Q": ["Model number details?", "Maintenance interval?"],
    "Raw Material P": ["What are specs?", "Approved vendors?"]
}

# ─── SETUP LLM ───────────────────────────────────────────────────

llm = AzureChatOpenAI(
    azure_deployment=deployment_name,
    model=model_name,
    api_version=api_version,
    api_key=api_key,
    azure_endpoint=base_url,
    temperature=0
)

# ─── INTELLIGENT DATABASE SYSTEM ─────────────────────────────────

class IntelligentDataStore:
    """
    Creates an in-memory SQLite database from JSON data.
    Allows complex querying without embeddings.
    """
    
    def __init__(self):
        self.conn = sqlite3.connect(':memory:', check_same_thread=False)
        self.tables = {}
        self.schema_info = {}
    
    def load_json_to_db(self, name: str, json_path: str):
        """Load JSON data into SQLite database."""
        logger.info(f"[DB] Loading {name} into database...")
        
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # Normalize JSON to DataFrame
        if isinstance(data, list):
            df = pd.json_normalize(data)
        else:
            df = pd.json_normalize([data])
        
        # Clean column names for SQL compatibility
        df.columns = [col.lower().replace('.', '_').replace(' ', '_').replace('-', '_') 
                      for col in df.columns]
        
        # Store in SQLite
        table_name = name.lower().replace(' ', '_')
        df.to_sql(table_name, self.conn, if_exists='replace', index=False)
        
        self.tables[table_name] = df
        self.schema_info[table_name] = {
            'columns': list(df.columns),
            'row_count': len(df),
            'sample_values': {col: df[col].dropna().head(3).tolist() for col in df.columns[:10]}
        }
        
        logger.info(f"[DB] ✓ Loaded {len(df)} records with {len(df.columns)} columns into '{table_name}'")
        logger.info(f"[DB] Columns: {list(df.columns[:15])}")
    
    def get_schema_description(self) -> str:
        """Generate a natural language description of the database schema."""
        description = "Database Schema:\n\n"
        
        for table_name, info in self.schema_info.items():
            description += f"Table: {table_name}\n"
            description += f"  Records: {info['row_count']}\n"
            description += f"  Columns: {', '.join(info['columns'][:20])}\n"
            description += f"  Sample values:\n"
            for col, values in list(info['sample_values'].items())[:5]:
                if values:
                    description += f"    {col}: {values}\n"
            description += "\n"
        
        return description
    
    def execute_query(self, query: str) -> str:
        """Execute SQL query and return results as formatted string."""
        try:
            logger.info(f"[DB] Executing query: {query[:200]}...")
            
            df = pd.read_sql_query(query, self.conn)
            
            if df.empty:
                return "No results found for this query."
            
            # Format results
            result = f"Found {len(df)} records:\n\n"
            
            # Show up to 20 results
            for idx, row in df.head(20).iterrows():
                result += f"Record {idx + 1}:\n"
                for col, val in row.items():
                    if pd.notna(val):
                        result += f"  {col}: {val}\n"
                result += "\n"
            
            if len(df) > 20:
                result += f"\n(Showing 20 of {len(df)} total results)\n"
            
            return result
            
        except Exception as e:
            logger.error(f"[DB] Query error: {e}")
            return f"Query execution error: {str(e)}"
    
    def get_column_info(self, table_name: str, column_name: str) -> Dict:
        """Get detailed information about a specific column."""
        if table_name not in self.tables:
            return {"error": "Table not found"}
        
        df = self.tables[table_name]
        
        if column_name not in df.columns:
            return {"error": "Column not found"}
        
        col_data = df[column_name].dropna()
        
        info = {
            "data_type": str(df[column_name].dtype),
            "non_null_count": len(col_data),
            "unique_values": int(col_data.nunique()),
        }
        
        # Add numeric stats if applicable
        if pd.api.types.is_numeric_dtype(col_data):
            info.update({
                "min": float(col_data.min()),
                "max": float(col_data.max()),
                "mean": float(col_data.mean()),
            })
        else:
            # Add sample values for non-numeric
            info["sample_values"] = col_data.head(10).tolist()
        
        return info

# ─── INTELLIGENT AGENT SYSTEM ────────────────────────────────────

class SmartQueryAgent:
    """
    LLM-powered agent that understands natural language queries
    and translates them into SQL queries.
    """
    
    def __init__(self, db_store: IntelligentDataStore, llm):
        self.db = db_store
        self.llm = llm
        self.query_history = []
    
    def create_sql_query_tool(self):
        """Create a tool for executing SQL queries."""
        def run_sql(query: str) -> str:
            """Execute a SQL query on the database. Use this to retrieve data."""
            return self.db.execute_query(query)
        
        return Tool(
            name="sql_query",
            func=run_sql,
            description="Execute SQL queries on the database to retrieve information. Input should be a valid SQL SELECT query."
        )
    
    def create_schema_tool(self):
        """Create a tool for getting schema information."""
        def get_schema(dummy: str = "") -> str:
            """Get the database schema and table information."""
            return self.db.get_schema_description()
        
        return Tool(
            name="get_schema",
            func=get_schema,
            description="Get information about available tables and their columns. Use this first to understand what data is available."
        )
    
    def query_with_llm(self, user_query: str) -> str:
        """
        Use LLM to understand the query and generate appropriate SQL.
        This is the intelligent part - LLM figures out what the user wants.
        """
        
        schema = self.db.get_schema_description()
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """You are an expert data analyst with SQL expertise. Your job is to help users query a database containing formulation and manufacturing data.

Database Schema:
{schema}

Your task:
1. Understand the user's natural language question
2. Generate an appropriate SQL query to answer it
3. Execute the query and explain the results

IMPORTANT RULES:
- Always use proper SQL syntax (SELECT, FROM, WHERE, etc.)
- Column names and table names are case-insensitive
- Use LIKE with % wildcards for partial text matching
- Use proper SQL operators (=, >, <, BETWEEN, IN, etc.)
- If the user asks about multiple things, use multiple queries or JOIN if needed
- Always limit results to avoid overwhelming output (LIMIT 50)
- If you're not sure about exact column names, query the schema first

For text searches, use: WHERE column_name LIKE '%search_term%'
For numeric comparisons, use: WHERE column_name > value
For multiple conditions, use: WHERE condition1 AND condition2

Examples:
- "Show me products with batch size over 1000" → SELECT * FROM table WHERE batch_size > 1000 LIMIT 50
- "Find formulations containing lactose" → SELECT * FROM table WHERE formulation LIKE '%lactose%' LIMIT 50
- "What equipment is used for product X?" → SELECT equipment FROM table WHERE product_name LIKE '%X%' LIMIT 50
"""),
            ("human", "{question}")
        ])
        
        # Generate SQL query using LLM
        chain = prompt | self.llm
        response = chain.invoke({
            "question": user_query,
            "schema": schema
        })
        
        # Extract SQL from response
        response_text = response.content
        
        # Try to find SQL query in response
        import re
        sql_match = re.search(r'```sql\n(.*?)\n```', response_text, re.DOTALL)
        if not sql_match:
            sql_match = re.search(r'SELECT.*?(?:;|$)', response_text, re.IGNORECASE | re.DOTALL)
        
        if sql_match:
            sql_query = sql_match.group(1) if sql_match.lastindex else sql_match.group(0)
            sql_query = sql_query.strip().rstrip(';')
            
            logger.info(f"[Agent] Generated SQL: {sql_query}")
            
            # Execute the query
            results = self.db.execute_query(sql_query)
            
            # Have LLM format the final answer
            final_prompt = ChatPromptTemplate.from_messages([
                ("system", """You are a helpful assistant. Format the database query results into a clear, natural language answer to the user's question.

Query Results:
{results}

Provide a clear, concise answer based on these results. If no results were found, say so clearly."""),
                ("human", "Original question: {question}")
            ])
            
            final_chain = final_prompt | self.llm
            final_response = final_chain.invoke({
                "question": user_query,
                "results": results
            })
            
            return final_response.content
        else:
            # LLM didn't generate SQL - it might be answering directly from schema
            return response_text
    
    def handle_query(self, query: str) -> str:
        """Main entry point for handling queries."""
        logger.info(f"[Agent] Processing query: '{query}'")
        
        try:
            answer = self.query_with_llm(query)
            self.query_history.append({"query": query, "answer": answer})
            return answer
            
        except Exception as e:
            logger.error(f"[Agent] Error: {e}")
            return f"I encountered an error processing your query: {str(e)}. Please try rephrasing your question."

# ─── INITIALIZE ON STARTUP ───────────────────────────────────────

logger.info("=" * 70)
logger.info("[Startup] Initializing Intelligent Query System")
logger.info("=" * 70)

try:
    logger.info("[Startup] Creating in-memory database...")
    DB_STORE = IntelligentDataStore()
    
    logger.info("[Startup] Loading data into database...")
    for name, path in EMBEDDED_FILES.items():
        if path:
            DB_STORE.load_json_to_db(name, path)
    
    logger.info("[Startup] Initializing LLM-powered query agent...")
    AGENT = SmartQueryAgent(DB_STORE, llm)
    
    recognizer = sr.Recognizer()
    
    logger.info("=" * 70)
    logger.info("[Startup] ✓ System ready! (Fast startup, intelligent querying)")
    logger.info("=" * 70)
    
except Exception as e:
    logger.error("=" * 70)
    logger.error(f"[Startup] ✗ FATAL ERROR: {e}")
    logger.error("=" * 70)
    raise

# ─── FASTAPI APP ─────────────────────────────────────────────────

app = FastAPI(title="Intelligent Query System")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],
    allow_methods=["*"],
    allow_headers=["*"],
)

class ChatRequest(BaseModel):
    message: str

# ─── ENDPOINTS ────────────────────────────────────────────────────

@app.get("/sample-tiles")
def sample_tiles():
    return JSONResponse(TILE_QUESTIONS)

@app.post("/chat")
def chat(req: ChatRequest):
    q = req.message.strip()
    if not q:
        raise HTTPException(400, "Empty query")
    
    logger.info(f"[API] Query: '{q}'")
    
    try:
        answer = AGENT.handle_query(q)
        return {"response": answer}
    except Exception as e:
        logger.error(f"[API] Error: {e}")
        return {"response": "I encountered an error. Please try rephrasing your question."}

@app.post("/speech-to-text")
async def speech_to_text(file: UploadFile = File(...)):
    try:
        data = await file.read()
        audio = sr.AudioFile(io.BytesIO(data))
        with audio as src:
            audio_data = recognizer.record(src)
        text = recognizer.recognize_google(audio_data)
        return {"text": text}
    except Exception as e:
        logger.error(f"[API] STT error: {e}")
        raise HTTPException(500, str(e))

@app.get("/text-to-speech")
def text_to_speech(text: str):
    try:
        buf = io.BytesIO()
        gTTS(text).write_to_fp(buf)
        buf.seek(0)
        return StreamingResponse(buf, media_type="audio/mp3")
    except Exception as e:
        logger.error(f"[API] TTS error: {e}")
        raise HTTPException(500, str(e))

@app.get("/health")
def health():
    return {
        "status": "ok",
        "tables": list(DB_STORE.tables.keys()),
        "total_records": sum(len(df) for df in DB_STORE.tables.values()),
        "approach": "LLM-powered SQL generation"
    }

@app.get("/schema")
def get_schema():
    """Get database schema information."""
    return {
        "schema": DB_STORE.schema_info,
        "description": DB_STORE.get_schema_description()
    }

@app.get("/stats")
def stats():
    """Get detailed statistics."""
    stats_info = {}
    for table_name, df in DB_STORE.tables.items():
        stats_info[table_name] = {
            "total_records": len(df),
            "columns": list(df.columns),
            "sample_data": df.head(2).to_dict('records')
        }
    return stats_info
