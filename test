# Complete Dissolution Similarity Analyzer - Streamlit Application
# Integrates all backend modules for pharmaceutical dissolution testing

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from io import BytesIO
import warnings
warnings.filterwarnings('ignore')

# Import backend modules
from Similarity_analyzer_final_version import (
    main_function,
    dissolution_curve,
    dissolution_curve_interval,
    check_time_points,
    two_time_points,
    min15__check,
    check_cv,
    check_same_time_points
)

from sa_main import (
    main_f2,
    prepare_data,
    check_sample_units
)

from Recommended_time_points import check_cv_criteria

# Page configuration
st.set_page_config(
    page_title="Dissolution Similarity Analyzer",
    page_icon="üíä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS styling
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        padding: 1rem 0;
    }
    .sub-header {
        font-size: 1.5rem;
        font-weight: bold;
        color: #2ca02c;
        margin-top: 2rem;
    }
    .info-box {
        background-color: #e7f3ff;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #1f77b4;
        margin: 1rem 0;
    }
    .success-box {
        background-color: #d4edda;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #28a745;
    }
    .warning-box {
        background-color: #fff3cd;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #ffc107;
    }
    .error-box {
        background-color: #f8d7da;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #dc3545;
    }
    .metric-card {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 2rem;
    }
    .stTabs [data-baseweb="tab"] {
        padding: 1rem 2rem;
        font-size: 1.1rem;
    }
</style>
""", unsafe_allow_html=True)

# Session state initialization
if 'analysis_complete' not in st.session_state:
    st.session_state.analysis_complete = False
if 'results' not in st.session_state:
    st.session_state.results = None

def validate_data(df, name):
    """Validate uploaded data format"""
    errors = []

    if df is None or df.empty:
        errors.append(f"{name} dataframe is empty")
        return errors

    if df.shape[1] < 2:
        errors.append(f"{name} must have at least 2 columns (Time + at least 1 unit)")

    # Check if first column is numeric (time points)
    try:
        pd.to_numeric(df.iloc[:, 0])
    except:
        errors.append(f"{name} first column (Time) must be numeric")

    # Check if subsequent columns are numeric (dissolution values)
    for col_idx in range(1, df.shape[1]):
        try:
            pd.to_numeric(df.iloc[:, col_idx])
        except:
            errors.append(f"{name} column {col_idx+1} must be numeric")

    return errors

def display_validation_checks(ref_df, test_df, market):
    """Display validation checks in a nice format"""
    st.markdown('<div class="sub-header">üìã Validation Checks</div>', unsafe_allow_html=True)

    checks = {
        "Minimum 3 time points (excl. zero)":
            [check_time_points(ref_df), check_time_points(test_df)],
        "First two points ‚â§85% dissolution":
            [two_time_points(ref_df), two_time_points(test_df)],
        "No >85% dissolution in first 15 min":
            [not min15__check(ref_df), not min15__check(test_df)],
        "CV requirements met":
            [check_cv(ref_df), check_cv(test_df)],
        "‚â•12 individual units":
            [check_sample_units(ref_df), check_sample_units(test_df)],
        "Same time points for both products":
            [check_same_time_points(ref_df, test_df), check_same_time_points(ref_df, test_df)]
    }

    # Create dataframe for display
    check_df = pd.DataFrame({
        "Validation Check": list(checks.keys()),
        "Reference": ["‚úÖ Pass" if checks[k][0] else "‚ùå Fail" for k in checks.keys()],
        "Test": ["‚úÖ Pass" if checks[k][1] else "‚ùå Fail" for k in checks.keys()]
    })

    st.dataframe(check_df)

    # Check if all validations passed
    all_passed = all([all(v) for v in checks.values()])

    if all_passed:
        st.markdown('<div class="success-box">‚úÖ All validation checks passed!</div>', unsafe_allow_html=True)
    else:
        st.markdown('<div class="warning-box">‚ö†Ô∏è Some validation checks failed. Results should be interpreted with caution.</div>', unsafe_allow_html=True)

    return all_passed

def download_excel(dataframes_dict, filename="results.xlsx"):
    """Create downloadable Excel file with multiple sheets"""
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        for sheet_name, df in dataframes_dict.items():
            if df is not None and not df.empty:
                df.to_excel(writer, sheet_name=sheet_name, index=False)
    output.seek(0)
    return output

def main():
    # Header
    st.markdown('<div class="main-header">üíä Dissolution Similarity Analyzer</div>', unsafe_allow_html=True)
    st.markdown("---")

    # Sidebar
    with st.sidebar:
        st.markdown("## üìÅ Data Upload")

        # File uploaders
        ref_file = st.file_uploader(
            "Upload Reference Data (Excel)",
            type=['xlsx', 'xls'],
            help="Excel file with Time in first column, followed by unit columns"
        )

        test_file = st.file_uploader(
            "Upload Test Data (Excel)",
            type=['xlsx', 'xls'],
            help="Excel file with Time in first column, followed by unit columns"
        )

        st.markdown("---")
        st.markdown("## üåç Regulatory Market")

        market = st.selectbox(
            "Select Regulatory Agency",
            ["US FDA", "EMA/ICH/Canada/Australia", "CHINA", "ASEAN", "ANVISA", "WHO"],
            help="Different markets have different dissolution testing requirements"
        )

        st.markdown("---")
        st.markdown("## ‚öôÔ∏è Analysis Settings")

        include_bootstrap = st.checkbox(
            "Include Bootstrap Analysis",
            value=True,
            help="Run bootstrap simulations for confidence intervals (10,000 iterations)"
        )

        show_optimal_timepoints = st.checkbox(
            "Show Optimal Timepoint Predictions",
            value=True,
            help="Calculate optimal timepoint sequences using predictive algorithms"
        )

        st.markdown("---")

        # Analyze button
        analyze_button = st.button("üöÄ Run Analysis")

    # Main content area
    if not ref_file or not test_file:
        st.markdown('<div class="info-box">üëà Please upload both Reference and Test data files to begin analysis</div>', unsafe_allow_html=True)

        # Show example data format
        with st.expander("üìñ Expected Data Format"):
            st.markdown("""
            **Excel File Format:**
            - First column: Time points (e.g., 0, 5, 10, 15, 30, 45, 60 minutes)
            - Subsequent columns: Dissolution values for each unit (minimum 12 units recommended)
            - All values should be numeric
            - Header row is optional

            **Example:**
            ```
            Time  Unit1  Unit2  Unit3  ...  Unit12
            0     0      0      0      ...  0
            5     25     27     24     ...  26
            10    45     48     43     ...  46
            15    65     68     62     ...  66
            ...
            ```
            """)

        # Show market-specific requirements
        with st.expander("üåç Market-Specific Requirements"):
            st.markdown("""
            **US FDA:**
            - Both products must exceed 85% dissolution simultaneously
            - CV ‚â§20% at first non-zero timepoint, ‚â§10% thereafter
            - Minimum 12 units per product

            **EMA/ICH/Canada/Australia:**
            - Either product exceeds 85% dissolution
            - CV ‚â§20% up to 10 minutes, ‚â§10% after
            - Expected f2 preferred when CV criteria met

            **China/ASEAN:**
            - Similar to EMA requirements
            - Either 85% rule applies

            **ANVISA:**
            - Both 85% rule (similar to FDA)
            - CV ‚â§20% for first 40% of timepoints, ‚â§10% thereafter

            **WHO:**
            - Similar to EMA requirements
            - Either 85% rule applies
            """)

        return

    # Load data
    try:
        reference_df = pd.read_excel(ref_file, header=None)
        test_df = pd.read_excel(test_file, header=None)

        st.success(f"‚úÖ Files loaded successfully! Reference: {reference_df.shape}, Test: {test_df.shape}")

    except Exception as e:
        st.error(f"‚ùå Error loading files: {str(e)}")
        return

    # Validate data
    ref_errors = validate_data(reference_df, "Reference")
    test_errors = validate_data(test_df, "Test")

    if ref_errors or test_errors:
        st.markdown('<div class="error-box">‚ùå Data Validation Errors:</div>', unsafe_allow_html=True)
        for error in ref_errors + test_errors:
            st.error(error)
        return

    # Display data preview
    with st.expander("üëÄ Preview Uploaded Data", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**Reference Data**")
            st.dataframe(reference_df.head(10))
        with col2:
            st.markdown("**Test Data**")
            st.dataframe(test_df.head(10))

    # Display validation checks (outside of button click)
    validation_passed = display_validation_checks(reference_df, test_df, market)

    st.markdown("---")

    # Determine recommended methodologies based on CV criteria
    st.markdown('<div class="sub-header">üéØ Methodology Selection</div>', unsafe_allow_html=True)

    recommended_methods = check_cv_criteria(reference_df, test_df, market)

    # Show recommendations in an expander
    with st.expander("üìã View Recommended Methods (Based on CV Criteria)", expanded=True):
        st.info(f"**Based on CV criteria and market selection ({market}), our recommendations are:**")
        for method in recommended_methods:
            st.markdown(f"- {method}")
        st.caption("üí° These are suggestions only - you have full control to select any methods you prefer below.")

    # Allow user to choose selection mode
    st.markdown("---")
    selection_mode = st.radio(
        "How would you like to select methodologies?",
        ["Use Recommended Methods", "Custom Selection", "Run All Available Methods"],
        help="Choose whether to use our recommendations or select your own preferred methodologies"
    )

    # Prepare all available methods
    all_methods = [
        "Conventional F2",
        "Expected F2",
        "Bias-Corrected F2",
        "Conventional Bootstrap F2",
        "Expected Bootstrap F2",
        "Bias-Corrected Bootstrap F2"
    ]

    # Filter bootstrap methods based on user selection
    if not include_bootstrap:
        all_methods = [m for m in all_methods if "Bootstrap" not in m]

    # Determine default selection based on mode
    if selection_mode == "Use Recommended Methods":
        default_selection = recommended_methods
        st.success("‚úÖ Using recommended methods based on your data and market requirements")
    elif selection_mode == "Run All Available Methods":
        default_selection = all_methods
        st.success(f"‚úÖ Running all {len(all_methods)} available methodologies")
    else:  # Custom Selection
        default_selection = []
        st.info("üé® Select your preferred methodologies from the list below")

    selected_methods = st.multiselect(
        "Select methodologies to calculate:",
        all_methods,
        default=default_selection,
        help="You can add or remove any methods regardless of recommendations",
        disabled=(selection_mode == "Run All Available Methods")
    )

    if not selected_methods:
        st.warning("‚ö†Ô∏è Please select at least one methodology before running analysis")
    else:
        st.success(f"‚úÖ Ready to analyze with {len(selected_methods)} method(s): {', '.join(selected_methods)}")

    st.markdown("---")

    # Run analysis button and execution
    if analyze_button:
        if not selected_methods:
            st.error("‚ùå Cannot run analysis: Please select at least one methodology above")
        else:
            with st.spinner("üî¨ Running analysis... This may take a few minutes for bootstrap simulations."):
                try:
                    # Run main function analysis
                    st.markdown('<div class="sub-header">üìä Dissolution Profile Analysis</div>', unsafe_allow_html=True)

                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    status_text.text("Step 1/4: Preparing data and calculating conventional f2...")
                    progress_bar.progress(25)

                    # Prepare data - remove time zero before calculations
                    ref_prepared, test_prepared = prepare_data(reference_df, test_df)

                    # Call main_function from Similarity_analyzer_final_version.py
                    main_results = main_function(market, test_prepared, ref_prepared)

                    # Unpack results based on return values
                    if len(main_results) == 8:
                        conv_f2, fig1, fig2, seq_print, recom_f2, plotly_fig, cv_checks, ai_df = main_results
                    else:
                        st.error("Unexpected number of return values from main_function")
                        return

                    status_text.text("Step 2/4: Generating dissolution plots...")
                    progress_bar.progress(50)

                    # Display conventional f2 result
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric(
                            label="Conventional f2",
                            value=f"{conv_f2:.2f}" if isinstance(conv_f2, (int, float)) else "N/A",
                            delta="Similar" if isinstance(conv_f2, (int, float)) and conv_f2 >= 50 else "Not Similar"
                        )
                    with col2:
                        st.metric(
                            label="CV Criteria",
                            value="Pass" if cv_checks == "True" else "Fail"
                        )
                    with col3:
                        if recom_f2:
                            st.metric(
                                label="Recommended f2",
                                value=f"{recom_f2:.2f}" if isinstance(recom_f2, (int, float)) else "N/A"
                            )

                    # Display dissolution curves
                    st.plotly_chart(fig1)
                    st.plotly_chart(fig2)

                    # Display optimal profile if available
                    if plotly_fig and show_optimal_timepoints:
                        st.markdown('<div class="sub-header">üéØ Optimal Predicted Profile</div>', unsafe_allow_html=True)
                        st.plotly_chart(plotly_fig)

                        if ai_df is not None and not ai_df.empty:
                            st.markdown("**Predicted Dissolution Values:**")
                            st.dataframe(ai_df)

                    status_text.text("Step 3/4: Calculating point estimates...")
                    progress_bar.progress(75)

                    # Run bootstrap analysis if selected
                    if include_bootstrap and any("Bootstrap" in m for m in selected_methods):
                        st.markdown("---")
                        st.markdown('<div class="sub-header">üîÑ Bootstrap Analysis</div>', unsafe_allow_html=True)

                        status_text.text("Step 4/4: Running bootstrap simulations (10,000 iterations)...")

                        # Prepare data for bootstrap
                        ref_clean, test_clean = prepare_data(reference_df, test_df)

                        # Call main_f2 from sa_main.py
                        try:
                            results, bootstrap_results, qq_plots = main_f2(
                                ref_clean,
                                test_clean,
                                selected_methods,
                                conv_f2,
                                market
                            )

                            if results is None:
                                results = {}
                            if bootstrap_results is None:
                                bootstrap_results = {}
                            if qq_plots is None:
                                qq_plots = {}

                        except Exception as bootstrap_error:
                            st.error(f"‚ö†Ô∏è Bootstrap analysis encountered an error: {str(bootstrap_error)}")
                            st.info("Continuing with available results...")
                            results = {}
                            bootstrap_results = {}
                            qq_plots = {}

                        progress_bar.progress(100)
                        status_text.text("‚úÖ Analysis complete!")

                        # Display point estimates
                        if results:
                            st.markdown("### Point Estimates")

                            point_est_df = pd.DataFrame([
                                {"Method": k, "f2 Value": v}
                                for k, v in results.items()
                                if k not in ['cv_result_expected_f2']
                            ])

                            if not point_est_df.empty:
                                st.dataframe(point_est_df)

                        # Display bootstrap results
                        if bootstrap_results:
                            st.markdown("### Bootstrap Results")

                            # Create summary table with all bootstrap statistics
                            st.markdown("#### Summary Table (10,000 Iterations)")

                            bootstrap_summary = []
                            for method, boot_res in bootstrap_results.items():
                                if boot_res and isinstance(boot_res, dict):
                                    # Extract confidence interval values
                                    ci = boot_res.get("Confidence Interval", "")
                                    lower_5 = None
                                    upper_95 = None
                                    if ci and ci not in [None, "None", "N/A"] and isinstance(ci, str) and " - " in ci:
                                        try:
                                            parts = ci.split(" - ")
                                            lower_5 = float(parts[0])
                                            upper_95 = float(parts[1])
                                        except (ValueError, IndexError):
                                            pass

                                    bootstrap_summary.append({
                                        "Method": method,
                                        "Observed F2": boot_res.get("Observed F2", "N/A"),
                                        "Bootstrap Mean": boot_res.get("Mean", "N/A"),
                                        "Bootstrap Median": boot_res.get("Median", "N/A"),
                                        "5th Percentile": f"{lower_5:.2f}" if lower_5 is not None else "N/A",
                                        "95th Percentile": f"{upper_95:.2f}" if upper_95 is not None else "N/A",
                                        "Skewness": boot_res.get("Skewness", "N/A"),
                                        "Kurtosis": boot_res.get("Kurtosis", "N/A"),
                                        "5th %ile > 50": boot_res.get("Is 5% percentile > 50", "N/A"),
                                        "Similarity": boot_res.get("Similarity of R and T", "N/A")
                                    })

                            if bootstrap_summary:
                                bootstrap_df = pd.DataFrame(bootstrap_summary)
                                st.dataframe(bootstrap_df)

                                # Add download button for bootstrap table
                                csv = bootstrap_df.to_csv(index=False)
                                st.download_button(
                                    label="üì• Download Bootstrap Results (CSV)",
                                    data=csv,
                                    file_name=f"bootstrap_results_{market.replace('/', '_')}.csv",
                                    mime="text/csv"
                                )

                            st.markdown("---")
                            st.markdown("#### Detailed Results by Method")

                            for method, boot_res in bootstrap_results.items():
                                if not boot_res or not isinstance(boot_res, dict):
                                    st.warning(f"‚ö†Ô∏è {method}: No valid results available")
                                    continue

                                with st.expander(f"üìà {method}", expanded=True):
                                    col1, col2, col3, col4 = st.columns(4)

                                    with col1:
                                        obs_f2 = boot_res.get("Observed F2", "N/A")
                                        st.metric("Observed f2", str(obs_f2) if obs_f2 is not None else "N/A")
                                    with col2:
                                        mean_val = boot_res.get("Mean", "N/A")
                                        st.metric("Mean", str(mean_val) if mean_val not in [None, "None"] else "N/A")
                                    with col3:
                                        median_val = boot_res.get("Median", "N/A")
                                        st.metric("Median", str(median_val) if median_val not in [None, "None"] else "N/A")
                                    with col4:
                                        ci = boot_res.get("Confidence Interval", "N/A")
                                        st.metric("90% CI", str(ci) if ci not in [None, "None"] else "N/A")

                                    col5, col6, col7 = st.columns(3)
                                    with col5:
                                        skew_val = boot_res.get("Skewness", "N/A")
                                        st.metric("Skewness", str(skew_val) if skew_val not in [None, "None"] else "N/A")
                                    with col6:
                                        kurt_val = boot_res.get("Kurtosis", "N/A")
                                        st.metric("Kurtosis", str(kurt_val) if kurt_val not in [None, "None"] else "N/A")
                                    with col7:
                                        similarity = boot_res.get("Similarity of R and T", "N/A")
                                        st.metric("Similarity", str(similarity) if similarity not in [None, "None"] else "N/A")

                                    # Display histogram plot
                                    if "Hist Plot" in boot_res and boot_res["Hist Plot"]:
                                        st.plotly_chart(boot_res["Hist Plot"])
                                    else:
                                        st.info("Bootstrap profile plot not available")

                            # Display QQ plots
                            if qq_plots:
                                st.markdown("### QQ Plots (Normality Assessment)")

                                qq_cols = st.columns(min(len(qq_plots), 3))
                                for idx, (method, qq_fig) in enumerate(qq_plots.items()):
                                    with qq_cols[idx % 3]:
                                        st.markdown(f"**{method}**")
                                        st.plotly_chart(qq_fig)

                    else:
                        progress_bar.progress(100)
                        status_text.text("‚úÖ Analysis complete!")

                    st.markdown("---")

                    # Summary and interpretation
                    st.markdown('<div class="sub-header">üìù Summary & Interpretation</div>', unsafe_allow_html=True)

                    if isinstance(conv_f2, (int, float)):
                        if conv_f2 >= 50:
                            st.markdown(
                                '<div class="success-box">'
                                f'‚úÖ <b>Conclusion:</b> The test and reference products are considered <b>similar</b> '
                                f'based on conventional f2 value of {conv_f2:.2f} (‚â•50).'
                                '</div>',
                                unsafe_allow_html=True
                            )
                        else:
                            st.markdown(
                                '<div class="warning-box">'
                                f'‚ö†Ô∏è <b>Conclusion:</b> The test and reference products are <b>not similar</b> '
                                f'based on conventional f2 value of {conv_f2:.2f} (<50).'
                                '</div>',
                                unsafe_allow_html=True
                            )

                    # Bootstrap interpretation
                    if include_bootstrap and bootstrap_results:
                        st.markdown("**Bootstrap Interpretation:**")
                        for method, boot_res in bootstrap_results.items():
                            if not boot_res or not isinstance(boot_res, dict):
                                continue
                            ci = boot_res.get("Confidence Interval", "")
                            if ci and ci not in [None, "None", "N/A"] and isinstance(ci, str) and " - " in ci:
                                try:
                                    lower = float(ci.split(" - ")[0])
                                    if lower > 50:
                                        st.success(f"‚úÖ {method}: 5th percentile ({lower:.2f}) > 50, supporting similarity")
                                    else:
                                        st.warning(f"‚ö†Ô∏è {method}: 5th percentile ({lower:.2f}) ‚â§ 50, similarity not confirmed")
                                except (ValueError, IndexError) as e:
                                    st.info(f"‚ÑπÔ∏è {method}: Could not interpret confidence interval")
                            else:
                                st.info(f"‚ÑπÔ∏è {method}: Confidence interval not available")

                    st.markdown("---")

                    # Download results
                    st.markdown('<div class="sub-header">üíæ Download Results</div>', unsafe_allow_html=True)

                    # Prepare data for download
                    download_data = {
                        "Reference_Data": reference_df,
                        "Test_Data": test_df,
                    }

                    if ai_df is not None and not ai_df.empty:
                        download_data["Optimal_Timepoints"] = ai_df

                    if results:
                        results_df = pd.DataFrame([
                            {"Metric": k, "Value": v}
                            for k, v in results.items()
                        ])
                        download_data["Point_Estimates"] = results_df

                    if bootstrap_results:
                        boot_summary = []
                        for method, boot_res in bootstrap_results.items():
                            if boot_res and isinstance(boot_res, dict):
                                # Extract confidence interval values
                                ci = boot_res.get("Confidence Interval", "")
                                lower_5 = "N/A"
                                upper_95 = "N/A"
                                if ci and ci not in [None, "None", "N/A"] and isinstance(ci, str) and " - " in ci:
                                    try:
                                        parts = ci.split(" - ")
                                        lower_5 = float(parts[0])
                                        upper_95 = float(parts[1])
                                    except (ValueError, IndexError):
                                        pass

                                boot_summary.append({
                                    "Method": method,
                                    "Observed_f2": boot_res.get("Observed F2", "N/A"),
                                    "Bootstrap_Mean": boot_res.get("Mean", "N/A"),
                                    "Bootstrap_Median": boot_res.get("Median", "N/A"),
                                    "5th_Percentile": lower_5,
                                    "95th_Percentile": upper_95,
                                    "Skewness": boot_res.get("Skewness", "N/A"),
                                    "Kurtosis": boot_res.get("Kurtosis", "N/A"),
                                    "5th_Percentile_gt_50": boot_res.get("Is 5% percentile > 50", "N/A"),
                                    "Similarity": boot_res.get("Similarity of R and T", "N/A")
                                })
                        download_data["Bootstrap_Results"] = pd.DataFrame(boot_summary)

                    excel_file = download_excel(download_data)

                    st.download_button(
                        label="üì• Download Complete Results (Excel)",
                        data=excel_file,
                        file_name=f"dissolution_analysis_{market.replace('/', '_')}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )

                    st.success("‚úÖ Analysis completed successfully!")

                except Exception as e:
                    st.error(f"‚ùå An error occurred during analysis: {str(e)}")
                    st.exception(e)

if __name__ == "__main__":
    main()
