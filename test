import streamlit as st
import os
import pdfplumber  # For PDF handling
from io import BytesIO
from google.auth import default
from google.cloud import aiplatform
from langchain_google_vertexai import VertexAI
import time
import logging
import tempfile
import numpy as np
from PIL import Image
from paddleocr import PaddleOCR

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configuration
class Config:
    """
    Contains the configuration of the LLM.
    """
    credentials, project_id = default()
    llm = VertexAI(model_name="gemini-pro", temperature=0.2, max_output_tokens=1024)

config = Config()

# Initialize PaddleOCR with Chinese and English languages
ocr = PaddleOCR(use_angle_cls=True, lang='ch')

# Function to chunk text content
def chunk_text(text, chunk_size=500):
    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]

# Function to translate text using the Gemini API (LLM)
def translate_text(text, language):
    if language == "Chinese":
        prompt = f"Translate the following Chinese text to English:\n\n{text}"
    elif language == "Japanese":
        prompt = f"Translate the following Japanese text to English:\n\n{text}"
    
    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = config.llm.predict(prompt)
            logger.info(f"LLM translation successful for chunk of length {len(text)}")
            return response
        except Exception as e:
            logger.error(f"LLM translation attempt {attempt + 1} failed. Error: {str(e)}")
            if attempt < max_retries - 1:
                time.sleep(2)  # Wait for 2 seconds before retrying
            else:
                st.error(f"LLM translation failed after {max_retries} attempts. Error: {str(e)}")
                return ""

# Function to extract text from PDF using PaddleOCR
def extract_text_from_pdf(pdf_file):
    text = ""
    try:
        # Read the PDF with pdfplumber
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as temp_pdf:
            temp_pdf.write(pdf_file.getvalue())
            temp_pdf_path = temp_pdf.name
        
        with pdfplumber.open(temp_pdf_path) as pdf:
            for page in pdf.pages:
                # Extract image from the page
                img = page.to_image()
                img_array = np.array(img.original)
                # Convert the image to RGB mode for OCR
                img_rgb = Image.fromarray(img_array).convert('RGB')
                # OCR using PaddleOCR
                ocr_result = ocr.ocr(np.array(img_rgb), cls=True)
                # Collect extracted text
                for line in ocr_result:
                    text += " ".join([word[1][0] for word in line]) + "\n"

        os.unlink(temp_pdf_path)  # Remove the temporary file
        
        logger.info(f"Extracted {len(text)} characters from PDF using PaddleOCR")
        return text
    except Exception as e:
        logger.error(f"Error extracting text from PDF using PaddleOCR: {str(e)}")
        st.error(f"Error extracting text from PDF using PaddleOCR: {str(e)}")
        return ""

# Streamlit app
st.title("PDF Translator - Chinese & Japanese to English (OCR + LLM)")

# File uploader
uploaded_file = st.file_uploader("Upload PDF", type="pdf")

# Language selection
language = st.selectbox("Select language for translation", ["Chinese", "Japanese"])

if uploaded_file:
    # Extract text from uploaded PDF using OCR
    with st.spinner('Extracting text from PDF using PaddleOCR (this may take a while)...'):
        pdf_text = extract_text_from_pdf(uploaded_file)
    
    if pdf_text:
        st.info(f"Extracted {len(pdf_text)} characters from the PDF using PaddleOCR")
        
        # Display a sample of the extracted text
        st.subheader("Sample of Extracted Text (from OCR)")
        st.text_area("", value=pdf_text[:500], height=100)
        
        # Break large content into chunks
        chunks = chunk_text(pdf_text)
        total_chunks = len(chunks)
        
        # Progress bar
        progress_bar = st.progress(0)
        
        # Translate chunks using LLM
        translated_chunks = []
        for idx, chunk in enumerate(chunks):
            with st.spinner(f'Translating chunk {idx+1} of {total_chunks} using LLM...'):
                translated_chunk = translate_text(chunk, language)
                translated_chunks.append(translated_chunk)
            
            # Update progress bar
            progress_bar.progress((idx + 1) / total_chunks)
        
        # Combine all translated chunks
        translated_text = "\n\n".join(translated_chunks)
        
        # Display translated text
        st.subheader("Translated Text (from LLM)")
        st.text_area("", value=translated_text, height=300)
        
        # Export translated text to a text file
        st.download_button(
            label="Download Translated Text",
            data=translated_text.encode('utf-8'),
            file_name="translated_document.txt",
            mime="text/plain"
        )
    else:
        st.error("Failed to extract text from the PDF using PaddleOCR. Please check if the file is corrupted or try a different PDF.")
