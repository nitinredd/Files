import numpy as np
from scipy.interpolate import interp1d
from sklearn.gaussian_process.kernels import ConstantKernel, RBF, WhiteKernel
from sklearn.gaussian_process import GaussianProcessRegressor
import itertools

def interpolate_linear(df, new_times):
    """
    Simple linear interpolation (used for determining the candidate window).
    """
    df_sorted = df.sort_values(by=df.columns[0])
    known_times = df_sorted.iloc[:, 0].values.astype(float)
    known_values = df_sorted.iloc[:, 1].values.astype(float)
    f = interp1d(known_times, known_values, kind='linear', 
                 fill_value=(known_values[0], known_values[-1]), bounds_error=False)
    return f(new_times)

def determine_candidate_window(ref_df, test_df, step=1, initial_threshold=10):
    """
    Identify candidate window based on the actual time range in the data.
    """
    max_ref_time = ref_df.iloc[:, 0].max()
    max_test_time = test_df.iloc[:, 0].max()
    fixed_max = max(max_ref_time, max_test_time)
    fixed_min = 0

    times = np.arange(fixed_min, fixed_max + 1, step)
    ref_vals = interpolate_linear(ref_df, times)
    test_vals = interpolate_linear(test_df, times)
    diff = np.abs(ref_vals - test_vals)
    
    valid_times = times[diff <= initial_threshold]
    if len(valid_times) == 0:
        print(f"No time points found within {initial_threshold}% difference; trying threshold=20.")
        valid_times = times[diff <= 20]
        if len(valid_times) == 0:
            print("No candidate window found even with 20% threshold. Using full range.")
            return fixed_min, fixed_max
        else:
            window_max = valid_times[-1]
            print(f"Candidate window determined (threshold 20): {fixed_min} to {window_max}")
            return fixed_min, window_max
    else:
        window_max = valid_times[-1]
        print(f"Candidate window determined (threshold {initial_threshold}): {fixed_min} to {window_max}")
        return fixed_min, window_max

def interpolate_dissolution_curve(df, new_times, method='gpr'):
    """
    Predict dissolution values at new time points, clamping to observed time range.
    """
    df_sorted = df.sort_values(by=df.columns[0])
    known_times = df_sorted.iloc[:, 0].values.astype(float)
    known_values = df_sorted.iloc[:, 1].values.astype(float)
    
    new_times_clamped = np.clip(new_times, known_times.min(), known_times.max())
    
    if method == 'gpr':
        kernel = ConstantKernel(1.0, (1e-3, 1e3)) * RBF(length_scale=10.0, length_scale_bounds=(1e-2, 1e2)) + \
                 WhiteKernel(noise_level=1, noise_level_bounds=(1e-5, 1e1))
        gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5)
        gp.fit(known_times.reshape(-1, 1), known_values)
        y_pred = gp.predict(new_times_clamped.reshape(-1, 1))
        return y_pred
    else:
        if len(known_times) < 2:
            return np.full(len(new_times_clamped), known_values[0]) if len(known_values) > 0 else np.zeros(len(new_times_clamped))
        kind = 'cubic' if method=='cubic' and len(known_times)>=4 else 'linear'
        f = interp1d(known_times, known_values, kind=kind, 
                     fill_value=(known_values[0], known_values[-1]), bounds_error=False)
        return f(new_times_clamped)
######################################
def predictive_optimal_combinations_advanced(ref_df, test_df, regulation, 
                                             window_min, window_max, diff_threshold=None,
                                             interp_method='gpr', points_per_stratum=None):
    """
    Deterministic selection of candidate time points based on the following rules:
    
      - Use only times from the grid of 3- and 5-minute increments.
      - Define three dissolution strata (based on predicted reference values):
            0-30%: choose exactly 2 candidate points (excluding the starting time)
            30-60%: choose exactly 2 candidate points
            60-90%: choose exactly 2 candidate points, with at least one having both
                    reference and test predictions >=80%.
      - The final candidate combination is the union of these points along with the starting time (usually 0).
      - For FDA mode, append one extra candidate: the first time after the last candidate where both
        predicted values are >=85% (resulting in 7 points total).
      
      The function then computes the f2 value:
         f2 = 50 * log10(100 / (1 + sqrt(mean((test - ref)^2))))
      (with the starting point forced to 0%).
    """
    import numpy as np
    import math

    # 1. Build valid time grid (only 3- and 5-minute increments)
    valid_times = np.sort(np.unique(np.concatenate([
        np.arange(window_min, window_max+1, 3),
        np.arange(window_min, window_max+1, 5)
    ])))
    
    # 2. Build GP models using GPR.
    from sklearn.gaussian_process import GaussianProcessRegressor
    from sklearn.gaussian_process.kernels import ConstantKernel, RBF, WhiteKernel
    kernel = ConstantKernel(1.0) * RBF(length_scale=10.0) + WhiteKernel()
    ref_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5)
    test_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5)
    
    ref_clean = ref_df.dropna()
    test_clean = test_df.dropna()
    ref_model.fit(ref_clean.iloc[:, 0].values.reshape(-1, 1), ref_clean.iloc[:, 1].values.astype(float))
    test_model.fit(test_clean.iloc[:, 0].values.reshape(-1, 1), test_clean.iloc[:, 1].values.astype(float))
    
    # 3. Prediction function.
    def predict_diss(model, times):
        return model.predict(np.array(times).reshape(-1, 1)).flatten()
    
    # Precompute predictions on valid_times.
    all_ref_pred = predict_diss(ref_model, valid_times)
    all_test_pred = predict_diss(test_model, valid_times)
    
    # 4. Define strata based on predicted reference values.
    # Each stratum is [low, high) in percent.
    strata = {
        "0-30": (0, 30),
        "30-60": (30, 60),
        "60-90": (60, 90)
    }
    required_points = 2  # exactly two candidate points from each stratum (excluding starting point)
    
    def eligible_times_for_stratum(stratum_range):
        low, high = stratum_range
        # Exclude the starting time if present.
        return [t for t, pred in zip(valid_times, all_ref_pred) if t != window_min and low <= pred < high]
    
    candidate = []
    
    # 5. For each stratum, choose exactly 2 points deterministically:
    # We'll select the earliest and the latest eligible time.
    for key in ["0-30", "30-60", "60-90"]:
        eligible = eligible_times_for_stratum(strata[key])
        if len(eligible) < required_points:
            raise ValueError(f"Insufficient eligible times in stratum {key}.")
        # Deterministically select: the minimum and maximum eligible time.
        candidate_stratum = [min(eligible), max(eligible)]
        candidate.extend(candidate_stratum)
    
    candidate = sorted(list(set(candidate)))
    
    # Ensure starting time (window_min, usually 0) is included.
    if window_min not in candidate:
        candidate.insert(0, window_min)
    
    # 6. For the 60-90 stratum, enforce that at least one candidate has both ref and test >=80%.
    eligible_60_90 = eligible_times_for_stratum(strata["60-90"])
    # From the chosen candidates that fall into 60-90:
    cand_60_90 = [t for t in candidate if t in eligible_60_90]
    ok = False
    for t in cand_60_90:
        idx = int(np.where(valid_times == t)[0][0])
        if all_ref_pred[idx] >= 80 and all_test_pred[idx] >= 80:
            ok = True
            break
    if not ok:
        # Try to adjust: replace the later candidate with the earliest candidate in eligible_60_90 that meets the 80% threshold.
        meeting = [t for t in eligible_60_90 if (all_ref_pred[int(np.where(valid_times == t)[0][0])] >= 80 and 
                                                all_test_pred[int(np.where(valid_times == t)[0][0])] >= 80)]
        if not meeting:
            raise ValueError("No candidate in 60-90 stratum meets the >=80% threshold for both curves.")
        # Replace the maximum candidate from current 60-90 selection with the earliest meeting candidate.
        current_60_90 = sorted(cand_60_90)
        candidate = [t for t in candidate if t not in current_60_90]
        candidate.extend([current_60_90[0], meeting[0]])
        candidate = sorted(list(set(candidate)))
    
    # Now, we expect candidate to have exactly 6 points.
    expected_count = 6
    if regulation == "FDA":
        expected_count = 7
    
    # 7. For FDA: Append extra candidate—the first time after the last candidate
    # where both predicted values are >=85%.
    if regulation == "FDA":
        last_candidate = candidate[-1]
        post_times = [t for t in valid_times if t > last_candidate]
        extra_point = None
        for t in post_times:
            idx = int(np.where(valid_times == t)[0][0])
            if all_ref_pred[idx] >= 85 and all_test_pred[idx] >= 85:
                extra_point = t
                break
        if extra_point is None:
            raise ValueError("No valid extra candidate found for FDA mode.")
        candidate.append(extra_point)
        candidate = sorted(list(set(candidate)))
    
    if len(candidate) != expected_count:
        raise ValueError(f"Final candidate count ({len(candidate)}) does not equal expected count ({expected_count}).")
    
    # 8. Compute f2.
    ref_vals = predict_diss(ref_model, candidate)
    test_vals = predict_diss(test_model, candidate)
    # Force the starting point to 0%.
    if candidate[0] == window_min:
        ref_vals[0] = 0.0
        test_vals[0] = 0.0
    diff = test_vals - ref_vals
    f2 = 50 * math.log10(100 / (1 + math.sqrt(np.mean(diff**2))))
    
    result = {
        'sequence': candidate,
        'f2': round(f2, 2),
        'compliant': True,  # assume compliance check passes; you can call your function here.
        'reasons': [],
        'ref_vals': ref_vals.tolist(),
        'test_vals': test_vals.tolist()
    }
    return [result], [result]
#######################################
if run_predictive.lower() == 'yes':
    # Determine candidate window (using the helper function)
    window_min, window_max = determine_candidate_window(
        reference_mean_df,
        test_mean_df,
        step=5,
        initial_threshold=10
    )
    
    # Map regulation input.
    regulation_map = {1: "FDA", 2: "EMA", 3: "China", 4: "ASEAN", 5: "ANVISA"}
    selected_regulation = regulation_map.get(input1, "FDA")
    
    print(f"\nCandidate window for combination search: {window_min} to {window_max}")
    
    # This deterministic approach does not use random sampling, so we ignore user_points_per_stratum.
    results, all_results = predictive_optimal_combinations_advanced(
        reference_mean_df,
        test_mean_df,
        regulation=selected_regulation,
        window_min=window_min,
        window_max=window_max,
        diff_threshold=None,
        interp_method='gpr',
        points_per_stratum=None
    )
    
    # Convert candidate time points to ints.
    for cand in results:
        cand['sequence'] = [int(t) for t in cand['sequence']]
    
    overall_best = results[0] if results else None
    
    if overall_best:
        print("\n=== Optimal Predictive Combination ===")
        print(f"Time Points (best candidate): {overall_best['sequence']}")
        print(f"Length: {len(overall_best['sequence'])}")
        print(f"Predicted f2 Score: {overall_best['f2']}")
        if overall_best['reasons']:
            print(f"Compliance Issues: {', '.join(overall_best['reasons'])}")
        else:
            print("Regulatory Compliance: Passed")
        
        # Plot the predicted dissolution curves.
        import matplotlib.pyplot as plt
        plt.figure(figsize=(12, 6))
        time_points = overall_best['sequence']
        ref_diss = interpolate_dissolution_curve(reference_mean_df, np.array(time_points), method='gpr')
        test_diss = interpolate_dissolution_curve(test_mean_df, np.array(time_points), method='gpr')
        if time_points[0] == window_min:
            ref_diss[0] = 0.0
            test_diss[0] = 0.0
        plt.plot(time_points, ref_diss, 'bo-', label='Reference')
        plt.plot(time_points, test_diss, 'r*--', label='Test')
        plt.title(f"Optimal Profile: Predicted Dissolution (f2 = {overall_best['f2']})")
        plt.xlabel('Time (min)')
        plt.ylabel('Dissolution (%)')
        plt.legend()
        plt.grid(True)
        plt.show()
        
        print("\nPredicted Reference Dissolution Percentages:")
        for t, d in zip(time_points, ref_diss):
            print(f"Time {t} min: {d:.2f}%")
        print("\nPredicted Test Dissolution Percentages:")
        for t, d in zip(time_points, test_diss):
            print(f"Time {t} min: {d:.2f}%")
    else:
        print("❌ No candidate sequence was generated.")
    
    print("\n=== All Candidate Combination (Diverse) ===")
    for idx, cand in enumerate(results):
        seq_print = [int(t) for t in cand['sequence']]
        print(f"{idx+1:3d}. | Points: {seq_print} | Length: {len(seq_print)} | f2: {cand['f2']} | Compliant: {cand['compliant']}")
