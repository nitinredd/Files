import os
import io
import json
import faiss
import torch
import clip
import camelot
import tabula
import numpy as np
import pandas as pd
import streamlit as st
from PIL import Image
from PyPDF2 import PdfReader
import fitz  # PyMuPDF

from langchain_openai import AzureChatOpenAI
from langchain_openai import AzureOpenAIEmbeddings
from langchain.embeddings.cache import CacheBackedEmbeddings
from langchain.storage.file_system import LocalFileStore
from langchain.schema import Document, HumanMessage, SystemMessage

# --- STREAMLIT CONFIG -------------------------------------------------------

st.set_page_config(
    page_title="🔬 Reaction Database AI",
    layout="wide",
    initial_sidebar_state="expanded"
)
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

# --- AZURE & MODEL SETTINGS (explicit, like your original) -------------------

base_url        = ""  # your Azure endpoint
api_version     = "2024-02-15-preview"
api_key         = ""  # your Azure API key
deployment_name = "GPT4o"
model_name      = "GPT4o"

# Embedding model config
embed_model      = "text-embedding-ada-002"
embed_api_version= "2023-07-01-preview"
embed_deployment = "Def_data_qa"

# PDF processing & retrieval
PDF_CHUNK_SIZE = 5000
TOP_K_TEXT     = 5
TOP_K_IMAGES   = 3

# --- YOUR REACTION FOLDERS --------------------------------------------------

embedded_folders = {
    'C-N_Bond_Formation': r"C:\Users\Desktop\C-N_Bond_Formation",
    # add more as needed
}

# --- LOAD & CACHE MODELS ----------------------------------------------------

@st.cache_resource(show_spinner=False)
def load_clip_model():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model, preprocess = clip.load("ViT-B/32", device=device)
    return model, preprocess, device

clip_model, clip_preprocess, clip_device = load_clip_model()

@st.cache_resource(show_spinner=False)
def get_text_embedder():
    file_store = LocalFileStore('langchain-embeddings')
    base = AzureOpenAIEmbeddings(
        model=embed_model,
        api_version=embed_api_version,
        azure_endpoint=base_url,
        api_key=api_key,
        azure_deployment=embed_deployment
    )
    return CacheBackedEmbeddings.from_bytes_store(base, file_store, namespace=base.model)

text_embedder = get_text_embedder()

@st.cache_resource(show_spinner=False)
def get_chat_model():
    return AzureChatOpenAI(
        azure_deployment=deployment_name,
        model=model_name,
        api_version=api_version,
        api_key=api_key,
        azure_endpoint=base_url
    )

chat_model = get_chat_model()

# --- UTILITIES --------------------------------------------------------------

def chunk_text(text: str, max_chars: int):
    return [text[i:i+max_chars] for i in range(0, len(text), max_chars)]

def extract_tables_from_pdf(pdf_path: str):
    tables = []
    try:
        tables += [t.df for t in camelot.read_pdf(pdf_path, pages="all", flavor="stream")]
    except Exception:
        pass
    try:
        tables += tabula.read_pdf(pdf_path, pages="all", multiple_tables=True)
    except Exception:
        pass
    return tables

def extract_images_and_schemes(pdf_path: str):
    out = []
    doc = fitz.open(pdf_path)
    for p in range(len(doc)):
        blocks = doc[p].get_text("blocks")
        # detect "scheme" captions
        for b in blocks:
            if "scheme" in b[4].lower():
                out.append({"type":"caption", "page": p+1})
                break
        # extract images
        for img_idx, img_obj in enumerate(doc[p].get_images(full=True)):
            xref = img_obj[0]
            img_bytes = doc.extract_image(xref)["image"]
            img = Image.open(io.BytesIO(img_bytes)).convert("RGB")
            inp = clip_preprocess(img).unsqueeze(0).to(clip_device)
            with torch.no_grad():
                emb = clip_model.encode_image(inp).cpu().numpy().reshape(-1)
            out.append({"type":"image", "page":p+1, "img":img, "emb":emb})
    return out

def build_faiss_index(embs: np.ndarray):
    dim = embs.shape[1]
    idx = faiss.IndexFlatL2(dim)
    idx.add(embs.astype("float32"))
    return idx

# --- BUILD INDICES (CACHED) -----------------------------------------------

@st.cache_data(show_spinner=True)
def initialize_indices():
    text_idxs, text_docs = {}, {}
    img_idxs, img_meta    = {}, {}

    for cls, folder in embedded_folders.items():
        txt_embs, docs = [], []
        img_embs, meta  = [], []

        for fname in sorted(os.listdir(folder)):
            if not fname.lower().endswith(".pdf"):
                continue
            path = os.path.join(folder, fname)

            # TEXT
            reader = PdfReader(path)
            raw = "\n".join(p.extract_text() or "" for p in reader.pages)
            chunks = chunk_text(raw, PDF_CHUNK_SIZE)
            docs.extend([Document(page_content=c, metadata={"source":fname, "chunk":i})
                         for i,c in enumerate(chunks)])
            txt_embs.extend(text_embedder.embed_documents(chunks))

            # TABLES
            for tbl in extract_tables_from_pdf(path):
                csv = tbl.to_csv(index=False)
                docs.append(Document(page_content=csv, metadata={"source":fname, "chunk":"table"}))
                txt_embs.append(text_embedder.embed_documents([csv])[0])

            # IMAGES & SCHEMES
            for item in extract_images_and_schemes(path):
                if item["type"] == "image":
                    img_embs.append(item["emb"])
                    meta.append({"source":fname, "page":item["page"], "type":"image"})
                else:
                    dim = img_embs[0].shape[0] if img_embs else 512
                    img_embs.append(np.zeros(dim))
                    meta.append({"source":fname, "page":item["page"], "type":"caption"})

        text_idxs[cls]  = build_faiss_index(np.vstack(txt_embs))
        text_docs[cls]  = docs
        img_idxs[cls]   = build_faiss_index(np.vstack(img_embs))
        img_meta[cls]   = meta

    return text_idxs, text_docs, img_idxs, img_meta

text_idxs, text_ds, img_idxs, img_meta = initialize_indices()

# --- RETRIEVAL ---------------------------------------------------------------

def retrieve_text_chunks(cls: str, q: str, k: int):
    q_emb = text_embedder.embed_query(q).reshape(1,-1).astype("float32")
    D, I = text_idxs[cls].search(q_emb, k)
    return [ text_ds[cls][i] for i in I[0] ]

def retrieve_image_hits(cls: str, q: str, k: int):
    tok = clip.tokenize([q]).to(clip_device)
    with torch.no_grad():
        q_emb = clip_model.encode_text(tok).cpu().numpy().reshape(1,-1)
    D, I = img_idxs[cls].search(q_emb.astype("float32"), k)
    return [ img_meta[cls][i] for i in I[0] ]

# --- STREAMLIT UI -----------------------------------------------------------

st.sidebar.title("⚙️ Settings")
reaction_class = st.sidebar.selectbox("Reaction Chemistry", list(embedded_folders.keys()))
user_query     = st.text_input("Ask about this reaction:")

if user_query:
    st.header("📝 Procedures, Yields & Tables")
    chunks = retrieve_text_chunks(reaction_class, user_query, TOP_K_TEXT)
    for doc in chunks:
        st.markdown(f"**Source:** {doc.metadata['source']} — Chunk `{doc.metadata['chunk']}`")
        content = doc.page_content
        if content.strip().startswith(("sep=",)) or content.count(",")>3:
            df = pd.read_csv(io.StringIO(content))
            st.dataframe(df)
        else:
            st.text_area("", content, height=200)

    st.header("🔎 Schemes & Figures")
    hits = retrieve_image_hits(reaction_class, user_query, TOP_K_IMAGES)
    for m in hits:
        if m["type"] == "caption":
            st.markdown(f"*📑 Synthetic Scheme caption on page {m['page']} of {m['source']}*")
        else:
            pdf = fitz.open(os.path.join(embedded_folders[reaction_class], m["source"]))
            img_obj = pdf[m["page"]-1].get_images(full=True)[0]
            xref = img_obj[0]
            img = Image.open(io.BytesIO(pdf.extract_image(xref)["image"]))
            st.image(img, caption=f"{m['source']} — page {m['page']}", use_column_width=True)

    st.header("🤖 AI Summary")
    system_msg = SystemMessage(
        content="You are an expert synthetic chemist. Summarize and correlate the retrieved procedures, yields, tables, and schemes."
    )
    human_msg = HumanMessage(content=user_query)
    answer = chat_model([system_msg, human_msg])
    st.write(answer.content)
