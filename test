def run_summit_optimization(domain, lhs_df: pd.DataFrame, nobj: int):
    """Run Summit optimization with improved column mapping."""
    
    print(f"Starting optimization with {len(lhs_df)} existing rows")
    print(f"Domain has {len([v for v in domain.variables if not v.is_objective])} input vars, {len([v for v in domain.variables if v.is_objective])} objectives")
    
    # Get domain variable names
    domain_var_names = [var.name for var in domain.variables if not var.is_objective]
    domain_obj_names = [var.name for var in domain.variables if var.is_objective]
    
    print(f"Domain input variables: {domain_var_names}")
    print(f"Domain objectives: {domain_obj_names}")
    print(f"Original DataFrame columns: {list(lhs_df.columns)}")
    print(f"DataFrame shape: {lhs_df.shape}")
    
    # FIXED: Better column name normalization function
    def normalize_col_name(name):
        """Normalize column names for matching."""
        return str(name).strip().replace(" ", "_").replace("(", "").replace(")", "").replace("-", "_").lower()
    
    # Create mapping from normalized domain names to original DataFrame columns
    df_col_map = {}
    normalized_df_cols = {normalize_col_name(col): col for col in lhs_df.columns}
    
    print(f"\nNormalized DataFrame columns: {list(normalized_df_cols.keys())}")
    
    # Create clean DataFrame with proper column alignment
    lhs_clean = pd.DataFrame()
    
    # Map input variables
    for var_name in domain_var_names:
        var_name_normalized = normalize_col_name(var_name)
        
        if var_name_normalized in normalized_df_cols:
            original_col = normalized_df_cols[var_name_normalized]
            lhs_clean[var_name] = lhs_df[original_col].copy()
            print(f"✓ Mapped input: {original_col} -> {var_name}")
        else:
            print(f"✗ WARNING: Could not find DataFrame column for variable '{var_name}'")
            print(f"  Tried normalized name: '{var_name_normalized}'")
            # Don't add NaN column - this will cause issues
            continue
    
    # Map objective variables  
    for obj_name in domain_obj_names:
        obj_name_normalized = normalize_col_name(obj_name)
        
        if obj_name_normalized in normalized_df_cols:
            original_col = normalized_df_cols[obj_name_normalized]
            lhs_clean[obj_name] = lhs_df[original_col].copy()
            print(f"✓ Mapped objective: {original_col} -> {obj_name}")
        else:
            # Objectives might not exist yet in early phases
            lhs_clean[obj_name] = np.nan
            print(f"○ No data for objective '{obj_name}', using NaN")
    
    print(f"\nClean DataFrame shape: {lhs_clean.shape}")
    print(f"Clean DataFrame columns: {list(lhs_clean.columns)}")
    
    # FIXED: Better validation - check that we have SOME input columns
    if len(lhs_clean.columns) == 0:
        print("ERROR: No columns were successfully mapped!")
        print("Generating random suggestion as fallback...")
        return generate_random_suggestion(domain)
    
    # Check for rows with at least SOME valid input data (not all NaN)
    input_cols_in_clean = [col for col in lhs_clean.columns if col in domain_var_names]
    
    if len(input_cols_in_clean) == 0:
        print("ERROR: No input variable columns found in clean DataFrame!")
        return generate_random_suggestion(domain)
    
    print(f"Input columns in clean df: {input_cols_in_clean}")
    
    # FIXED: More lenient validation - keep rows with ANY valid input data
    input_vars_df = lhs_clean[input_cols_in_clean]
    # Keep rows where at least 50% of input columns have valid data
    min_valid_cols = max(1, len(input_cols_in_clean) // 2)
    valid_rows = input_vars_df.notna().sum(axis=1) >= min_valid_cols
    lhs_clean_valid = lhs_clean[valid_rows].copy()
    
    print(f"Valid rows for optimization: {len(lhs_clean_valid)} (required {min_valid_cols}/{len(input_cols_in_clean)} non-NaN columns)")
    
    if len(lhs_clean_valid) == 0:
        print("WARNING: No valid data rows found after filtering")
        print("Checking raw data:")
        print(lhs_df.head())
        print("\nGeneration random suggestion as fallback...")
        return generate_random_suggestion(domain)
    
    # Show sample of valid data
    print(f"\nSample of valid data (first row):")
    for col in lhs_clean_valid.columns[:10]:  # Show first 10 columns
        print(f"  {col}: {lhs_clean_valid[col].iloc[0]}")
    
    # Create DataSet for Summit
    try:
        print("\nCreating DataSet...")
        lhs_ds = DataSet.from_df(lhs_clean_valid)
        print(f"✓ DataSet created successfully with {len(lhs_ds)} rows")
    except Exception as e:
        print(f"✗ Failed to create DataSet: {e}")
        import traceback
        traceback.print_exc()
        return generate_random_suggestion(domain)
    
    # Run optimization
    if nobj > 1:
        try:
            print("Trying TSEMO optimization...")
            strat = TSEMO(domain, random_rate=0.00, n_spectral_points=min(4000, len(lhs_clean_valid) * 100))
            out = strat.suggest_experiments(1, lhs_ds, use_spectral_sample=True, pop_size=50, iterations=50)
            print("✓ TSEMO optimization successful")
        except Exception as e:
            print(f"✗ TSEMO failed: {e}")
            print("Falling back to SNOBFIT...")
            try:
                strat = SNOBFIT(domain)
                out = strat.suggest_experiments(1, lhs_ds)
                print("✓ SNOBFIT optimization successful")
            except Exception as e2:
                print(f"✗ SNOBFIT also failed: {e2}")
                return generate_random_suggestion(domain)
    else:
        try:
            print("Using SNOBFIT optimization...")
            strat = SNOBFIT(domain)
            out = strat.suggest_experiments(1, lhs_ds)
            print("✓ SNOBFIT optimization successful")
        except Exception as e:
            print(f"✗ SNOBFIT failed: {e}")
            return generate_random_suggestion(domain)
    
    # Clean up output
    if "strategy" in out.columns:
        out = out.drop(columns=["strategy"])
    
    print(f"\nFinal optimization output shape: {out.shape}")
    print(f"Final optimization output columns: {list(out.columns)}")
    
    # Handle MultiIndex columns
    if isinstance(out.columns, pd.MultiIndex):
        print("Flattening MultiIndex columns...")
        new_columns = []
        for col in out.columns:
            if isinstance(col, tuple):
                name = next((str(x) for x in col if str(x).strip() and str(x) != 'nan'), str(col[0]))
                new_columns.append(name)
            else:
                new_columns.append(str(col))
        out.columns = new_columns
        print(f"Flattened columns: {list(out.columns)}")
    
    # Show sample output
    if len(out) > 0:
        sample_dict = {}
        for col in out.columns[:5]:
            sample_dict[col] = out[col].iloc[0]
        print(f"Sample output data: {sample_dict}")
    
    return out


def generate_random_suggestion(domain):
    """Generate random suggestion within domain bounds as fallback."""
    print("Generating random suggestion within domain bounds...")
    out = pd.DataFrame()
    for var in domain.variables:
        if not var.is_objective:
            low, high = var.bounds
            random_val = np.random.uniform(low, high)
            out[var.name] = [random_val]
            print(f"  {var.name}: {random_val:.4f} (bounds: [{low:.2f}, {high:.2f}])")
    return out
#######
def suggest_experiments_and_append(num_suggestions: int, objectives: List[Dict[str, Any]], lhs):
    """Generate experiment suggestions with better error handling."""
    
    # Helper function for column name normalization
    def normalize_col_name(name):
        return str(name).strip().replace(" ", "_").replace("(", "").replace(")", "").replace("-", "_").lower()
    
    try:
        print("\n=== Building domain ===")
        print(f"Input DataFrame shape: {lhs.shape}")
        print(f"Input DataFrame columns: {list(lhs.columns)}")
        
        # Check that we have numeric data
        numeric_cols = lhs.select_dtypes(include=[np.number]).columns.tolist()
        print(f"Numeric columns: {numeric_cols}")
        
        if len(numeric_cols) == 0:
            raise ValueError("No numeric columns found in DataFrame")
        
        domain = build_domain_from_df(lhs, objectives)
        print(f"✓ Domain created successfully")
        
        input_vars = [v.name for v in domain.variables if not v.is_objective]
        obj_vars = [v.name for v in domain.variables if v.is_objective]
        print(f"Input variables ({len(input_vars)}): {input_vars}")
        print(f"Objective variables ({len(obj_vars)}): {obj_vars}")

    except Exception as e:
        print(f"✗ Domain build failed: {e}")
        import traceback
        traceback.print_exc()
        raise RuntimeError(f"Domain build failed: {e}")

    # Generate ONE suggestion
    print(f"\n=== Generating 1 suggestion ===")

    try:
        out = run_summit_optimization(domain, lhs, len(objectives) or 1)
        print(f"Optimization returned DataFrame with shape: {out.shape}")

        if isinstance(out, pd.DataFrame) and out.shape[0] >= 1 and out.shape[1] > 0:
            suggested = out.iloc[0].to_dict()
            print(f"Got {len(suggested)} suggestions")
        else:
            print("WARNING: Empty optimization output")
            suggested = {}

        # Create new row with better column mapping
        new_row = {}
        print("\nMapping suggestions to original columns:")
        
        # Create normalized mapping
        suggested_normalized = {normalize_col_name(k): v for k, v in suggested.items()}
        
        for col in lhs.columns:
            col_normalized = normalize_col_name(col)
            
            # Try to find matching suggestion
            if col_normalized in suggested_normalized:
                new_row[col] = suggested_normalized[col_normalized]
                print(f"  ✓ {col} = {suggested_normalized[col_normalized]}")
            elif col in suggested:
                new_row[col] = suggested[col]
                print(f"  ✓ {col} = {suggested[col]}")
            else:
                # Check if this is an objective column
                is_objective = any(normalize_col_name(obj.get("name", "")) == col_normalized for obj in objectives)
                if is_objective:
                    new_row[col] = ""  # Empty string for objectives to be filled
                    print(f"  ○ {col} = '' (objective - will be filled)")
                else:
                    new_row[col] = np.nan
                    print(f"  ✗ {col} = NaN (no suggestion)")

        print(f"\nNew row created with {len(new_row)} columns")
        lhs_updated = pd.concat([lhs, pd.DataFrame([new_row])], ignore_index=True)
        print(f"✓ Successfully added suggestion, total rows: {len(lhs_updated)}")

        return lhs_updated

    except Exception as e:
        print(f"✗ ERROR generating suggestion: {e}")
        import traceback
        traceback.print_exc()

        # Fallback: create row with NaN for inputs, empty for objectives
        print("Using fallback row...")
        new_row = {}
        for col in lhs.columns:
            col_normalized = normalize_col_name(col)
            is_objective = any(normalize_col_name(obj.get("name", "")) == col_normalized for obj in objectives)
            new_row[col] = "" if is_objective else np.nan
        
        lhs_updated = pd.concat([lhs, pd.DataFrame([new_row])], ignore_index=True)
        return lhs_updated
