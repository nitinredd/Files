import pandas as pd
import numpy as np
from summit.domain import Domain, ContinuousVariable
from typing import List, Dict , Any
from summit.strategies import TSEMO,Random, SNOBFIT
from summit.utils.dataset import DataSet

def HPLC_data_read_csv(file_path: str) -> np.ndarray:
    """
    Reads HPLC data from a CSV file.
    Assumes the CSV has 'Area' and 'RT' columns.
    Returns a NumPy array with [Area, RT].
    """
    try:
        data = pd.read_csv(file_path)
        data_final = pd.DataFrame()
        data_final['Peak_Area'] = data['Area']
        data_final['RT'] = data['RT']
        return data_final.to_numpy()
    except Exception as e:
        print(f"Error reading HPLC CSV file {file_path}: {e}")
        return np.array([]) # Return empty array on error

def impurity_response_csv(data_np: np.ndarray, IminRT: float, ImaxRT: float, areaISO: float) -> float:
    """
    Calculates impurity response based on peak area within a given RT range.
    data_np: NumPy array with [Area, RT]
    IminRT, ImaxRT: Retention time range for the impurity
    areaISO: Isocratic peak area for normalization
    """
    areaB = 0
    for i in range(data_np.shape[0]):
        if IminRT <= data_np[i, 1] <= ImaxRT:
            areaB += data_np[i, 0]
    return areaB / areaISO if areaISO != 0 else 0.0

def response_HPLC_csv(
    data_np: np.ndarray,
    YminRT: float, YmaxRT: float,
    IminRT_list: List[float], ImaxRT_list: List[float],
    minRTISO: float, maxRTISO: float,
    nobj: int
) -> List[float]:
    """
    Computes yield and impurity responses from HPLC data.
    data_np: NumPy array with [Area, RT]
    YminRT, YmaxRT: RT range for the main product (yield)
    IminRT_list, ImaxRT_list: Lists of RT ranges for multiple impurities
    minRTISO, maxRTISO: RT range for the internal standard (isocratic)
    nobj: Number of objectives (including yield and impurities)
    """
    if data_np.size == 0:
        # Return default values if data is empty
        return [float('inf')] * nobj

    areaA = 0
    for i in range(data_np.shape[0]):
        if YminRT <= data_np[i, 1] <= YmaxRT:
            areaA += data_np[i, 0]

    areaISO = 0
    for i in range(data_np.shape[0]):
        if minRTISO <= data_np[i, 1] <= maxRTISO:
            areaISO += data_np[i, 0]

    response = []
    # Yield calculation (negative log for minimization)
    yield_result = areaA / areaISO if areaISO != 0 else 0.0
    response.append(-np.log(yield_result) if yield_result > 0 else float('inf')) # Handle log(0)

    # Impurities calculation
    # nobj includes yield, so iterate for nobj-1 impurities
    for i in range(nobj - 1):
        if i < len(IminRT_list) and i < len(ImaxRT_list):
            impurities_result = impurity_response_csv(data_np, IminRT_list[i], ImaxRT_list[i], areaISO)
            response.append(impurities_result)
        else:
            response.append(0.0) # Default if impurity range is missing

    return response

def monitor_folder_creation1_csv(
    file_path: str,
    nobj: List,
    YminRT: float, YmaxRT: float,
    IminRT: float, ImaxRT: float,
    minRTISO: float, maxRTISO: float
) -> Dict[str, Dict[str, List[float]]]:
    """
    Processes a single HPLC CSV file and returns the calculated responses.
    This function wraps the HPLC data reading and response calculation.
    filepath = new file path (excel file path)
    nobj = Objective data objectives names 
    """
    data = HPLC_data_read_csv(file_path)
    response = response_HPLC_csv(data,YminRT,YmaxRT,IminRT,ImaxRT,minRTISO,maxRTISO,nobj)
    return response

def process_hplc_and_fill(filename: str, data_np: np.ndarray,lhs: pd.DataFrame,objectives: list,nobj,hplc_params: dict):
    """Process HPLC data and update results."""
    nobj = max(1, len(objectives))
    # Calculate response
    resp = response_HPLC_csv(
        data_np,
        hplc_params.get("YminRT", 2.0),
        hplc_params.get("YmaxRT", 4.0),
        hplc_params.get("IminRT_list", [0.5]),
        hplc_params.get("ImaxRT_list", [1.0]),
        hplc_params.get("minRTISO", 10.0),
        hplc_params.get("maxRTISO", 12.0),
        nobj
    )

    return resp

def process_uploaded_csv_file(full_path_uploaded_csv,
                              df,
                              minRTISO,
                              maxRTISO,
                              YminRT,
                              YmaxRT,
                              IminRT_list,
                              ImaxRT_list,
                              transformed_objectives,
                              lhs ):
    if 'Area' in df.columns and 'RT' in df.columns:
            data_np = df[['Area', 'RT']].to_numpy()
    else:
        cols_lower = {c.lower(): c for c in df.columns}
        if 'area' in cols_lower and 'rt' in cols_lower:
            data_np = df[[cols_lower['area'], cols_lower['rt']]].to_numpy()
    hplc_params = {}
    if YminRT is not None: hplc_params['YminRT'] = YminRT
    if YmaxRT is not None: hplc_params['YmaxRT'] = YmaxRT
    if IminRT_list is not None:
        hplc_params['IminRT_list'] = [float(x) for x in IminRT_list if str(x).strip() != '']

    if ImaxRT_list is not None:
        hplc_params['ImaxRT_list'] = [float(x) for x in ImaxRT_list if str(x).strip() != '']

    if minRTISO is not None: hplc_params['minRTISO'] = float(minRTISO)
    if maxRTISO is not None: hplc_params['maxRTISO'] = float(maxRTISO)

    resp = process_hplc_and_fill(filename = full_path_uploaded_csv, 
                                 data_np = data_np,
                                 lhs = lhs,
                                 objectives = transformed_objectives,
                                 nobj = len(transformed_objectives),
                                 hplc_params = hplc_params)
    return resp

def build_domain_from_df(df: pd.DataFrame, objectives: List[Dict[str, Any]]):
    """Build optimization domain from DataFrame."""
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    domain = Domain()
    if len(numeric_cols) == 0:
        raise ValueError("No numeric columns to build domain.")

    # Get objective column names to exclude them from input variables
    objective_names = [obj.get("name", "").replace(" ", "_") for obj in objectives]
    
    # Add ALL numeric columns as input variables (except objectives)
    for col in numeric_cols:
        sanitized_name = str(col).replace(" ", "_")  # Replace spaces with underscores
        
        # Skip if this column is an objective
        if sanitized_name in objective_names:
            continue
            
        # Calculate bounds from existing data
        col_data = df[col].dropna()  # Remove NaN values for bound calculation
        if len(col_data) > 0:
            lb = float(col_data.min())
            ub = float(col_data.max())
            if lb == ub:
                lb -= 1e-6
                ub += 1e-6
        else:
            # Default bounds if no data available
            lb, ub = 0.0, 1.0
            
        domain += ContinuousVariable(name=sanitized_name, description=str(col), bounds=[lb, ub])

    # Add objectives
    for obj in objectives:
        obj_name = obj.get("name", "obj").replace(" ", "_")  # Sanitize objective name
        maximize = bool(obj.get("maximize", False))
        domain += ContinuousVariable(
            name=obj_name,
            description=obj_name,
            bounds=[0, 100],
            is_objective=True,
            maximize=maximize
        )
    return domain

def clean_dataframe_for_summit(df: pd.DataFrame) -> pd.DataFrame:
    """Clean DataFrame to avoid Summit/TSEMO column overlap issues."""
    df_clean = df.copy()
    
    # Handle MultiIndex columns
    if isinstance(df_clean.columns, pd.MultiIndex):
        new_columns = []
        for col in df_clean.columns:
            if isinstance(col, tuple):
                # Join tuple elements, filter out 'DATA' and empty strings
                parts = [str(x) for x in col if str(x).upper() != 'DATA' and str(x).strip()]
                if parts:
                    col_name = "_".join(parts)
                else:
                    col_name = f"col_{len(new_columns)}"
            else:
                col_name = str(col)
            
            # Remove special characters that might cause issues
            col_name = col_name.replace(' ', '_').replace('(', '').replace(')', '').replace('-', '_')
            
            # Ensure uniqueness
            counter = 1
            original_name = col_name
            while col_name in new_columns:
                col_name = f"{original_name}_{counter}"
                counter += 1
            new_columns.append(col_name)
        
        df_clean.columns = new_columns
    else:
        # Clean regular column names
        new_columns = []
        for col in df_clean.columns:
            col_name = str(col).replace(' ', '_').replace('(', '').replace(')', '').replace('-', '_')
            # Ensure uniqueness
            counter = 1
            original_name = col_name
            while col_name in new_columns:
                col_name = f"{original_name}_{counter}"
                counter += 1
            new_columns.append(col_name)
        df_clean.columns = new_columns
    
    return df_clean

def run_summit_optimization(domain, lhs_df: pd.DataFrame, nobj: int):
    """Run Summit optimization."""
    
    print(f"Starting optimization with {len(lhs_df)} existing rows")
    print(f"Domain has {len([v for v in domain.variables if not v.is_objective])} input vars, {len([v for v in domain.variables if v.is_objective])} objectives")
    
    # Prepare DataFrame for Summit - ensure proper column alignment
    domain_var_names = [var.name for var in domain.variables if not var.is_objective]
    domain_obj_names = [var.name for var in domain.variables if var.is_objective]
    
    print(f"Domain input variables: {domain_var_names}")
    print(f"Domain objectives: {domain_obj_names}")
    print(f"Original DataFrame columns: {list(lhs_df.columns)}")
    
    # Create a clean DataFrame with only the columns that match domain variables
    lhs_clean = pd.DataFrame()
    
    # Map input variables
    for var_name in domain_var_names:
        # Try to find matching column in original DataFrame
        found = False
        for col in lhs_df.columns:
            col_clean = str(col).replace(" ", "_").replace("(", "").replace(")", "").replace("-", "_")
            if col_clean == var_name or str(col) == var_name:
                lhs_clean[var_name] = lhs_df[col]
                found = True
                print(f"Mapped {col} -> {var_name}")
                break
        
        if not found:
            print(f"WARNING: Could not find column for variable {var_name}")
            # If no matching column found, fill with NaN (this shouldn't happen with proper domain building)
            lhs_clean[var_name] = np.nan
    
    # Map objective variables  
    for obj_name in domain_obj_names:
        found = False
        for col in lhs_df.columns:
            col_clean = str(col).replace(" ", "_").replace("(", "").replace(")", "").replace("-", "_")
            if col_clean == obj_name or str(col) == obj_name:
                lhs_clean[obj_name] = lhs_df[col]
                found = True
                print(f"Mapped objective {col} -> {obj_name}")
                break
        
        if not found:
            # For objectives, we might not have data yet
            lhs_clean[obj_name] = np.nan
            print(f"No data for objective {obj_name}, using NaN")
    
    print(f"Clean DataFrame shape: {lhs_clean.shape}")
    print(f"Clean DataFrame columns: {list(lhs_clean.columns)}")
    
    # Remove rows where ALL input variables are NaN (these can't be used for optimization)
    input_vars_df = lhs_clean[domain_var_names]
    valid_rows = ~input_vars_df.isna().all(axis=1)
    lhs_clean_valid = lhs_clean[valid_rows].copy()
    
    print(f"Valid rows for optimization: {len(lhs_clean_valid)}")
    
    # Ensure we have some valid data
    if len(lhs_clean_valid) == 0:
        print("WARNING: No valid data rows found for optimization - generating random suggestion")
        # Return a random suggestion based on domain bounds
        out = pd.DataFrame()
        for var in domain.variables:
            if not var.is_objective:
                # Generate random value within bounds
                low, high = var.bounds
                random_val = np.random.uniform(low, high)
                out[var.name] = [random_val]
                print(f"Random suggestion for {var.name}: {random_val} (bounds: {low}-{high})")
        print(f"Generated random suggestion: {out.to_dict('records')[0]}")
        return out
    
    # Create DataSet for Summit
    try:
        print("Creating DataSet...")
        lhs_ds = DataSet.from_df(lhs_clean_valid)
        print(f"DataSet created successfully with {len(lhs_ds)} rows")
    except Exception as e:
        print(f"Failed to create DataSet: {e}")
        print("Generating random fallback...")
        # Fallback to random suggestion
        out = pd.DataFrame()
        for var in domain.variables:
            if not var.is_objective:
                low, high = var.bounds
                random_val = np.random.uniform(low, high)
                out[var.name] = [random_val]
        return out
    
    # Run optimization
    if nobj > 1:
        try:
            print("Trying TSEMO optimization...")
            strat = TSEMO(domain, random_rate=0.00, n_spectral_points=min(4000, len(lhs_clean_valid) * 100))
            out = strat.suggest_experiments(1, lhs_ds, use_spectral_sample=True, pop_size=50, iterations=50)
            print("TSEMO optimization successful")
        except Exception as e:
            print(f"TSEMO failed with error: {e}")
            print("Falling back to SNOBFIT...")
            try:
                strat = SNOBFIT(domain)
                out = strat.suggest_experiments(1, lhs_ds)
                print("SNOBFIT optimization successful")
            except Exception as e2:
                print(f"SNOBFIT also failed: {e2}")
                print("Using random fallback...")
                # Final fallback to random
                out = pd.DataFrame()
                for var in domain.variables:
                    if not var.is_objective:
                        low, high = var.bounds
                        random_val = np.random.uniform(low, high)
                        out[var.name] = [random_val]
                print(f"Random fallback generated: {out.to_dict('records')[0] if len(out) > 0 else 'EMPTY'}")
                return out
    else:
        try:
            print("Using SNOBFIT optimization...")
            strat = SNOBFIT(domain)
            out = strat.suggest_experiments(1, lhs_ds)
            print("SNOBFIT optimization successful")
        except Exception as e:
            print(f"SNOBFIT failed: {e}")
            print("Using random fallback...")
            # Fallback to random
            out = pd.DataFrame()
            for var in domain.variables:
                if not var.is_objective:
                    low, high = var.bounds
                    random_val = np.random.uniform(low, high)
                    out[var.name] = [random_val]
            return out
    
    # Clean up output
    if "strategy" in out.columns:
        out = out.drop(columns=["strategy"])
    
    print(f"Final optimization output shape: {out.shape}")
    print(f"Final optimization output: {out.to_dict('records')[0] if len(out) > 0 else 'EMPTY'}")
    
    return out

def suggest_experiments_and_append(num_suggestions: int, objectives: List[Dict[str, Any]], lhs):
    try:
        print("Building domain...")
        domain = build_domain_from_df(lhs, objectives)
        print(f"Domain created successfully")
        print(f"Domain has {len([v for v in domain.variables if not v.is_objective])} input variables and {len([v for v in domain.variables if v.is_objective])} objectives")
        
        # Print domain details
        input_vars = [v.name for v in domain.variables if not v.is_objective]
        obj_vars = [v.name for v in domain.variables if v.is_objective]
        print(f"Input variables: {input_vars}")
        print(f"Objective variables: {obj_vars}")
        
    except Exception as e:
        raise RuntimeError(f"Domain build failed: {e}")
    
    suggestions = []
    for i in range(num_suggestions):
        print(f"\n=== Generating suggestion {i+1}/{num_suggestions} ===")
        try:
            out = run_summit_optimization(domain, lhs, len(objectives) or 1)
            print(f"Optimization returned: {type(out)}, shape: {out.shape if hasattr(out, 'shape') else 'N/A'}")
            
            if isinstance(out, pd.DataFrame) and out.shape[0] >= 1:
                suggested = out.iloc[0].to_dict()
                print(f"Raw suggestions from optimization: {suggested}")
            else:
                suggested = {}
                print("WARNING: No suggestions returned from optimization, using empty dict")

            # Create new row with proper column mapping
            new_row = {}
            print("Mapping suggestions to original columns:")
            
            for col in lhs.columns:
                # Check if we have a suggestion for this column
                col_clean = str(col).replace(" ", "_").replace("(", "").replace(")", "").replace("-", "_")
                
                if col_clean in suggested:
                    new_row[col] = suggested[col_clean]
                    print(f"  {col} <- {col_clean} = {suggested[col_clean]}")
                elif col in suggested:
                    new_row[col] = suggested[col]
                    print(f"  {col} = {suggested[col]}")
                else:
                    # For objective columns or unmapped columns, use NaN
                    new_row[col] = np.nan
                    print(f"  {col} = NaN (no suggestion)")
            
            print(f"Final new row: {new_row}")
            suggestions.append(new_row)
            lhs = pd.concat([lhs, pd.DataFrame([new_row])], ignore_index=True)
            print(f"Successfully added suggestion {i+1}, total rows: {len(lhs)}")
            
        except Exception as e:
            print(f"ERROR generating suggestion {i+1}: {e}")
            import traceback
            traceback.print_exc()
            
            # Create a row with all NaN values as fallback
            new_row = {c: np.nan for c in lhs.columns}
            print(f"Using fallback row with all NaN: {new_row}")
            suggestions.append(new_row)
            lhs = pd.concat([lhs, pd.DataFrame([new_row])], ignore_index=True)
    
    print(f"\n=== Final result: {len(suggestions)} suggestions added ===")
    return lhs
