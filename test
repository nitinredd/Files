import os
import time
import logging
import json

import google.auth
import pandas as pd
import streamlit as st
from rapidfuzz import process, fuzz
from vertexai.preview.generative_models import (
    GenerativeModel,
    SafetySetting,
    HarmCategory,
    HarmBlockThreshold,
)

# ---------- Logging ----------
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

# ---------- Configuration ----------
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "D:/datascience-254609-genai.json"
credentials, project_id = google.auth.default()

# Use multimodal Gemini 2.5 Pro
model = GenerativeModel("gemini-2.0-flash-thinking-exp-01-21")

safety_config = [
    SafetySetting(category=HarmCategory.HARM_CATEGORY_UNSPECIFIED, threshold=HarmBlockThreshold.BLOCK_NONE),
    SafetySetting(category=HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold=HarmBlockThreshold.BLOCK_NONE),
    SafetySetting(category=HarmCategory.HARM_CATEGORY_HARASSMENT, threshold=HarmBlockThreshold.BLOCK_NONE),
    SafetySetting(category=HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold=HarmBlockThreshold.BLOCK_NONE),
    SafetySetting(category=HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold=HarmBlockThreshold.BLOCK_NONE),
]

# ---------- Safe LLM Call ----------
def safe_gemini_text_call(prompt: str, max_retries: int = 3, delay: float = 2.0) -> str:
    for attempt in range(1, max_retries + 1):
        try:
            logger.debug(f"Gemini call attempt {attempt} | prompt length={len(prompt)}")
            resp = model.generate_content([prompt], safety_settings=safety_config)
            if hasattr(resp, "text") and resp.text:
                return resp.text.strip()
            if "blocked" in str(resp).lower():
                raise ValueError("Blocked by safety filter")
            raise ValueError("Empty response from Gemini")
        except Exception as e:
            logger.warning(f"Attempt {attempt} failed: {e}")
            if attempt < max_retries:
                time.sleep(delay)
            else:
                logger.error("Max retries reached, aborting.")
                raise
    raise RuntimeError("safe_gemini_text_call unexpected exit")

# ---------- Agents ----------
class Agent:
    def __init__(self, name: str): self.name = name
    def handle(self, *args, **kwargs):
        raise NotImplementedError

class QueryUnderstandingAgent(Agent):
    def __init__(self): super().__init__("QueryUnderstandingAgent")
    def handle(self, query: str) -> dict:
        prompt = (
            "Extract the values for equipment, plant, and parameter from the user question. "
            "Output JSON with keys: equipment, plant, parameter.\n"
            f"Question: {query}\n"
        )
        resp = safe_gemini_text_call(prompt)
        try:
            data = json.loads(resp)
            return {k: data.get(k) for k in ("equipment","plant","parameter")}
        except Exception:
            # fallback simple regex
            import re
            eq = re.search(r"equipment\s+(\w+)", query, re.I)
            pl = re.search(r"plant\s+(\w+)", query, re.I)
            param = query
            for w in [eq.group(1) if eq else None, pl.group(1) if pl else None]:
                if w: param = param.replace(w, "")
            return {"equipment": eq.group(1) if eq else None,
                    "plant": pl.group(1) if pl else None,
                    "parameter": param.strip()}

class SchemaRetrievalAgent(Agent):
    def __init__(self, reader):
        super().__init__("SchemaRetrievalAgent")
        self.reader = reader
    def handle(self, intent: dict) -> dict:
        # gather all sheet/column names
        schema = {}
        for sheet, df in self.reader.sheets.items():
            schema[sheet] = df.columns.tolist()
        prompt = (
            "Given available sheets and their columns, choose the best sheet and columns for the parameter. "
            "Output JSON: {sheet: [col1, col2,...]}.\n"
        )
        for sheet, cols in schema.items():
            prompt += f"Sheet: {sheet}, Columns: {cols}\n"
        prompt += f"Parameter to match: {intent['parameter']}\n"
        resp = safe_gemini_text_call(prompt)
        try:
            return json.loads(resp)
        except Exception:
            # fallback: fuzzy match across all
            from rapidfuzz import process, fuzz
            best = {}
            for sheet, cols in schema.items():
                matches = process.extract(intent['parameter'], cols, scorer=fuzz.token_set_ratio, score_cutoff=60)
                if matches:
                    best[sheet] = [m[0] for m in matches]
            return best

class DataExtractionAgent(Agent):
    def __init__(self, reader):
        super().__init__("DataExtractionAgent")
        self.reader = reader
    def handle(self, intent: dict, schema_map: dict) -> dict:
        results = {}
        for sheet, cols in schema_map.items():
            df = self.reader.sheets.get(sheet)
            if df is None: continue
            sub = df.copy()
            if intent.get("equipment"):
                eq_col = process.extractOne("equipment", sub.columns, scorer=fuzz.token_set_ratio)[0]
                sub = sub[sub[eq_col].astype(str).str.contains(intent["equipment"], case=False, regex=False)]
            if intent.get("plant"):
                pl_col = process.extractOne("plant", sub.columns, scorer=fuzz.token_set_ratio)[0]
                sub = sub[sub[pl_col].astype(str).str.contains(intent["plant"], case=False, regex=False)]
            if sub.empty: continue
            # select only requested columns
            selected = [c for c in cols if c in sub.columns]
            results[sheet] = sub[selected]
        return results

class ResponseGenerationAgent(Agent):
    def __init__(self): super().__init__("ResponseGenerationAgent")
    def handle(self, intent: dict, extracted: dict) -> str:
        # Format tables
        text = f"Results for `{intent['parameter']}` on equipment `{intent['equipment']}` in plant `{intent['plant']}`:\n"
        for sheet, df in extracted.items():
            text += f"\nSheet: {sheet}\n" + df.to_markdown(index=False) + "\n"
        return text

class CoordinatorAgent(Agent):
    def __init__(self, reader):
        super().__init__("Coordinator")
        self.understander = QueryUnderstandingAgent()
        self.schema_ret   = SchemaRetrievalAgent(reader)
        self.extractor    = DataExtractionAgent(reader)
        self.generator    = ResponseGenerationAgent()
    def handle(self, query: str):
        intent = self.understander.handle(query)
        schema_map = self.schema_ret.handle(intent)
        extracted = self.extractor.handle(intent, schema_map)
        if not extracted:
            return None, None
        resp = self.generator.handle(intent, extracted)
        return resp, extracted

# ---------- Excel Reader ----------
class ExcelReaderAgent(Agent):
    def __init__(self, files):
        super().__init__("ExcelReader")
        self.sheets = {}
        for f in files:
            xl = pd.ExcelFile(f)
            for s in xl.sheet_names:
                self.sheets[s] = xl.parse(s)

# ---------- Streamlit UI ----------
st.set_page_config(page_title="Excel Chatbot", layout="wide")

if 'agents' not in st.session_state:
    files = ['formula master_osd.xlsx', 'masterlist osd equipments.xlsx']
    reader      = ExcelReaderAgent(files)
    coordinator = CoordinatorAgent(reader)
    st.session_state['agents'] = {'reader': reader, 'coordinator': coordinator}

reader      = st.session_state['agents']['reader']
coordinator = st.session_state['agents']['coordinator']

st.title("Agentic Excel Chatbot")
query = st.text_input("Enter your question:")
if st.button("Ask") and query:
    with st.spinner("Thinking..."):
        try:
            answer, extracted = coordinator.handle(query)
            if not extracted:
                st.error("No matching data found.")
            else:
                st.markdown(answer)
        except Exception as e:
            logger.exception("Error in pipeline")
            st.error(f"Failed: {e}")
