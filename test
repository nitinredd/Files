import os
import subprocess
import json
import streamlit as st
from langchain.chat_models import AzureChatOpenAI
from langchain.schema import SystemMessage, HumanMessage
from pydantic import BaseModel, Field

# === Azure config exactly as provided ===
base_url        = ""
api_version     = "2024-02-15-preview"
api_key         = ""
deployment_name = "GPT4o"
model_name      = "GPT4o"

chat_model = AzureChatOpenAI(
    azure_deployment=deployment_name,
    model=model_name,
    api_version=api_version,
    api_key=api_key,
    azure_endpoint=base_url
)

# === Python executor function ===
def execute_python(code: str) -> str:
    script = f"""
import sys
def safe_exec():
{code.replace(chr(10), chr(10) + '    ')}
if __name__ == "__main__":
    safe_exec()
"""
    proc = subprocess.run(
        ["python3", "-c", script],
        capture_output=True,
        text=True,
        timeout=10
    )
    if proc.returncode != 0:
        return f"Error:\\n{proc.stderr}"
    return proc.stdout.strip()

# === Function schema ===
class ExecutePythonSchema(BaseModel):
    code: str = Field(..., description="Python code snippet printing or populating `result`.")

function_def = {
    "name": "execute_python",
    "description": "Executes Python code in a sandbox and returns stdout.",
    "parameters": {
        "type": "object",
        "properties": ExecutePythonSchema.schema()["properties"],
        "required": ["code"]
    }
}

# === Streamlit UI ===
st.set_page_config(page_title="Azure GPT4o + Python Sandbox", layout="wide")
st.title("Azure GPT4o + Generic Python Tool")

prompt = st.text_area("Enter your prompt (math, tables, data, etc):", height=150)

if st.button("Submit"):
    system_msg = SystemMessage(content=(
        "You are an assistant. For any math, data processing, plotting, or table generation, "
        "call the function `execute_python` with a code snippet that prints or defines `result`. "
        "If no function needed, just answer normally."
    ))
    user_msg = HumanMessage(content=prompt)

    # Send messages and tools
    resp = chat_model(
        [system_msg, user_msg],
        tools=[function_def],
        tool_choice="auto"
    )

    # LangChain returns a BaseMessage object
    # Function calls appear in resp.additional_kwargs["tool_calls"]
    tool_calls = resp.additional_kwargs.get("tool_calls", [])
    if tool_calls:
        first_call = tool_calls[0]
        code = json.loads(first_call["function"]["arguments"])["code"]

        with st.expander("üîç View generated Python code", expanded=False):
            st.code(code, language="python")
        output = execute_python(code)
        st.markdown("**Execution Result:**")
        st.text(output)
    else:
        st.markdown("**Response:**")
        st.write(resp.content)
