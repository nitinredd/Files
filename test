import os
import streamlit as st
import pandas as pd
import google.auth
from vertexai.preview.generative_models import GenerativeModel, HarmCategory, HarmBlockThreshold, SafetySetting
from typing import Dict, List, Optional, Tuple

# Configure Gemini
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "D:/datascience-254609-genai.json"
credentials, project_id = google.auth.default()

safety_config = [
    SafetySetting(
        category=HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
        threshold=HarmBlockThreshold.BLOCK_NONE,
    ),
]

model = GenerativeModel("gemini-2.0-flash-thinking-exp-01-21")

# Column mapping configuration
SHEET_CONFIG = {
    "RMG": {
        "columns": {
            "equipment": "Make",
            "plant": "Plant",
            "impeller speed range": ["impeller speed range min", "impeller speed range max"],
            "capacity": "Capacity",
            "literature sources": "Literature Sources"
        },
        "key_columns": ["Make", "Plant"]
    },
    "FTO-2": {
        "columns": {
            "equipment": "Equipment Name",
            "specification": "Technical Specifications",
            "plant": "Location"
        },
        "key_columns": ["Equipment Name", "Location"]
    }
}

class ExcelAnalyzer:
    def __init__(self):
        self.data: Dict[str, Dict[str, pd.DataFrame]] = {}
        
    def load_excel(self, file_path: str) -> None:
        """Load Excel files with standardized column names"""
        try:
            xls = pd.ExcelFile(file_path)
            self.data[file_path] = {}
            for sheet_name in xls.sheet_names:
                df = xls.parse(sheet_name)
                # Clean column names
                df.columns = df.columns.str.strip().str.lower()
                self.data[file_path][sheet_name] = df
        except Exception as e:
            st.error(f"Error loading {file_path}: {str(e)}")
            st.stop()

class QueryProcessor:
    def __init__(self, analyzer: ExcelAnalyzer):
        self.analyzer = analyzer
    
    def _parse_query(self, query: str) -> Dict[str, str]:
        """Structured query parsing using Gemini"""
        prompt = f"""Analyze this equipment query and extract:
        1. Equipment name (manufacturer/model)
        2. Specification type (e.g., speed range, capacity)
        3. Plant location (e.g., FTO-2)
        4. Sheet/RMG type
        Return as JSON: {{"equipment": "", "specification": "", "plant": "", "sheet": ""}}"""
        
        try:
            response = model.generate_content(prompt + "\nQuery: " + query)
            return eval(response.text.replace("```json", "").replace("```", "").strip())
        except:
            return {}

    def _search_sheet(self, sheet_name: str, params: dict) -> Optional[pd.DataFrame]:
        """Precision search in specific sheet with column mapping"""
        sheet_config = SHEET_CONFIG.get(sheet_name, {})
        if not sheet_config:
            return None

        results = []
        for file in self.analyzer.data.values():
            if sheet_name in file:
                df = file[sheet_name]
                mask = pd.Series([True]*len(df))
                
                # Apply filters for key columns
                for key in sheet_config["key_columns"]:
                    if key.lower() in params:
                        mask &= df[key.strip().lower()].str.contains(params[key.lower()], case=False, na=False)
                
                # If we have matches, add specification columns
                if mask.any():
                    result_cols = sheet_config["key_columns"] + sheet_config["columns"].get(params.get("specification", ""), [])
                    return df.loc[mask, result_cols].dropna(how='all')
        return None

    def execute_search(self, query: str) -> List[Tuple[str, pd.DataFrame]]:
        """Structured search execution"""
        params = self._parse_query(query)
        if not params:
            return []
        
        target_sheet = params.get("sheet", "RMG")  # Default to RMG
        result = self._search_sheet(target_sheet, params)
        return [(target_sheet, result)] if result is not None else []

class ResponseGenerator:
    @staticmethod
    def format_response(results: List[Tuple[str, pd.DataFrame]], query: str) -> str:
        """Generate precise technical responses"""
        if not results:
            return "No matching specifications found in documents"
        
        response = []
        for sheet_name, df in results:
            # Handle range specifications
            if "range min" in df.columns and "range max" in df.columns:
                ranges = df.iloc[0]
                response.append(
                    f"In {sheet_name}: {ranges['Make']} at {ranges['Plant']} has "
                    f"{ranges['impeller speed range min']}-{ranges['impeller speed range max']} RPM"
                )
            else:
                response.append(f"**{sheet_name} Data:**\n{df.to_markdown(index=False)}")
        
        return "\n\n".join(response)

# Streamlit App
def main():
    st.title("üè≠ Precision Equipment Specs Finder")
    
    # Initialize system
    if "system" not in st.session_state:
        st.session_state.system = {
            "analyzer": ExcelAnalyzer(),
            "processor": None,
            "messages": []
        }
        st.session_state.system["analyzer"].load_excel("formula master_osd.xlsx")
        st.session_state.system["analyzer"].load_excel("masterlist osd equipments.xlsx")
        st.session_state.system["processor"] = QueryProcessor(st.session_state.system["analyzer"])

    # Chat interface
    for msg in st.session_state.system["messages"]:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # Sample questions
    sample_queries = [
        "What is the impeller speed range in RMG for the Equipment Glatt in FTO 2?",
        "Show me the capacity specifications for Tapasya equipment in FTO-3",
        "What literature sources are referenced for RMG processes?"
    ]
    
    if not st.session_state.system["messages"]:
        with st.chat_message("assistant"):
            st.markdown("**Technical Specifications Assistant Ready**\n\nSample queries:")
            for q in sample_queries:
                st.code(q, language="sql")

    # Process queries
    if prompt := st.chat_input("Enter technical query..."):
        st.session_state.system["messages"].append({"role": "user", "content": prompt})
        
        # Execute search
        with st.spinner("üî¨ Analyzing technical specs..."):
            results = st.session_state.system["processor"].execute_search(prompt)
        
        # Generate response
        response = ResponseGenerator.format_response(results, prompt)
        st.session_state.system["messages"].append({"role": "assistant", "content": response})
        
        # Rerun to update UI
        st.rerun()

if __name__ == "__main__":
    main()
