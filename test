import numpy as np
import math
import pandas as pd

def calculate_mean_profile(df):
    """Calculate mean dissolution profile from raw data"""
    times = df.iloc[:, 0].astype(float).values
    values = df.iloc[:, 1:].astype(float)
    means = values.mean(axis=1).values
    return pd.DataFrame({'Time': times, 'Mean': means})

def create_monotonic_profile(times, values, grid):
    """Create monotonic profile with proper interpolation"""
    # Insert 0h point if missing
    if times[0] != 0.0:
        times = np.insert(times, 0, 0.0)
        values = np.insert(values, 0, 0.0)
    
    # Create fine grid for interpolation
    grid = np.unique(np.sort(np.concatenate([
        grid,
        np.array(times)
    ])))
    
    # Linear interpolation
    interp_values = np.interp(grid, times, values, left=0.0, right=np.nan)
    
    # Ensure monotonicity
    return np.maximum.accumulate(interp_values), grid

def select_unique_points(profile, grid, tolerance=0.1):
    """Select points with unique values accounting for tolerance"""
    selected = [0]
    last_value = profile[0]
    
    for i in range(1, len(profile)):
        if abs(profile[i] - last_value) > tolerance:
            selected.append(i)
            last_value = profile[i]
    return selected

def find_85_point(ref_profile, test_profile, grid, regulation):
    """Find appropriate 85% dissolution point"""
    for i in range(len(grid)):
        ref_ok = ref_profile[i] >= 85
        test_ok = test_profile[i] >= 85
        
        if regulation in ("FDA", "ANVISA") and ref_ok and test_ok:
            return i
        elif ref_ok or test_ok:
            return i
    return None

def predictive_optimal_combinations_monotonic(reference_df, test_df,
                                            regulation, window_max=12,
                                            step_hours=0.25):
    # Calculate mean profiles
    ref_mean = calculate_mean_profile(reference_df)
    test_mean = calculate_mean_profile(test_df)

    # Create interpolation grid
    base_grid = np.arange(0.0, window_max + 1e-8, step_hours)
    
    # Generate monotonic profiles
    ref_mon, grid = create_monotonic_profile(
        ref_mean['Time'].values,
        ref_mean['Mean'].values,
        base_grid
    )
    test_mon, _ = create_monotonic_profile(
        test_mean['Time'].values,
        test_mean['Mean'].values,
        base_grid
    )

    # Initial point selection
    seq_indices = select_unique_points(ref_mon, grid)
    
    # Find 85% point
    eighty_five_idx = find_85_point(ref_mon, test_mon, grid, regulation)
    if eighty_five_idx and eighty_five_idx not in seq_indices:
        seq_indices.append(eighty_five_idx)
    
    # Final selection and formatting
    seq_indices = sorted(np.unique(seq_indices))
    times = [float(grid[i]) for i in seq_indices]
    
    # Convert to percentages
    ref_values = [float(ref_mon[i]) for i in seq_indices]
    test_values = [float(test_mon[i]) for i in seq_indices]
    
    # Calculate f2 score
    diffs = np.array(test_values[1:]) - np.array(ref_values[1:])
    f2 = 50 * math.log10(100/(1 + np.sqrt(np.mean(diffs**2)))) if diffs.size > 0 else 0

    # Clean time formatting
    clean_times = []
    for t in times:
        if abs(t - round(t)) < 1e-4:
            clean_times.append(int(round(t)))
        else:
            clean_times.append(round(t, 2))
    
    return [{
        'sequence': clean_times,
        'f2': round(f2, 2),
        'compliant': f2 >= 50,
        'reasons': [],
        'ref_vals': [round(v, 2) for v in ref_values],
        'test_vals': [round(v, 2) for v in test_values]
    }], None
