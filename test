import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as stats
from scipy.stats import norm
from sklearn.utils import resample
import warnings
import os
from matplotlib.ticker import MaxNLocator

# Initialize global array for bootstrap results
arrayboot = []

def process_data_for_regulation(regulation, reference_df, test_df):
    """Process data according to specific regulatory requirements"""
    ref_df = reference_df.copy()
    test = test_df.copy()
    
    # Remove zero time point if exists
    if ref_df.iloc[0, 0] == 0 or ref_df.iloc[0, 0] == '0':
        ref_df = ref_df.iloc[1:].reset_index(drop=True)
    if test.iloc[0, 0] == 0 or test.iloc[0, 0] == '0':
        test = test.iloc[1:].reset_index(drop=True)
    
    # Regulatory-specific processing
    if regulation == "FDA":
        # FDA: Use both >= 85% criteria
        ref_index = next((i for i, val in enumerate(ref_df.iloc[:, 1:].mean(axis=1)) if val >= 85, len(ref_df)-1)
        test_index = next((i for i, val in enumerate(test.iloc[:, 1:].mean(axis=1)) if val >= 85, len(test)-1)
        final_index = max(ref_index, test_index)
    else:
        # EMA/WHO/Canada/ANVISA: Use either > 85% criteria
        ref_index = next((i for i, val in enumerate(ref_df.iloc[:, 1:].mean(axis=1)) if val > 85, len(ref_df)-1)
        test_index = next((i for i, val in enumerate(test.iloc[:, 1:].mean(axis=1)) if val > 85, len(test)-1)
        final_index = min(ref_index, test_index)
    
    return ref_df.iloc[:final_index+1], test.iloc[:final_index+1]

def calculate_f2(reference, test):
    """Calculate conventional f2 similarity metric"""
    ref_means = reference.iloc[:, 1:].mean(axis=1)
    test_means = test.iloc[:, 1:].mean(axis=1)
    diff_sqr = ((test_means - ref_means) ** 2).sum()
    p = len(reference)
    return 50 if diff_sqr == 0 else 100 - 25 * np.log10(1 + (1/p) * diff_sqr)

def calculate_expected_f2(reference, test):
    """Calculate expected f2 metric with variance adjustment"""
    ref_means = reference.iloc[:, 1:].mean(axis=1)
    test_means = test.iloc[:, 1:].mean(axis=1)
    diff_sqr = ((test_means - ref_means) ** 2).sum()
    
    ref_var = reference.iloc[:, 1:].var(axis=1, ddof=1)
    test_var = test.iloc[:, 1:].var(axis=1, ddof=1)
    sum_var = (ref_var + test_var).sum()
    
    n = reference.shape[1] - 1  # Number of units
    p = len(reference)
    return 100 - 25 * np.log10(1 + (1/p) * (diff_sqr + (1/n) * sum_var))

def calculate_bias_corrected_f2(reference, test):
    """Calculate bias-corrected f2 metric"""
    ref_means = reference.iloc[:, 1:].mean(axis=1)
    test_means = test.iloc[:, 1:].mean(axis=1)
    diff_sqr = ((test_means - ref_means) ** 2).sum()
    
    ref_var = reference.iloc[:, 1:].var(axis=1, ddof=1)
    test_var = test.iloc[:, 1:].var(axis=1, ddof=1)
    sum_var = (ref_var + test_var).sum()
    
    n = reference.shape[1] - 1
    p = len(reference)
    left_side = (1/n) * sum_var
    right_side = diff_sqr + p
    
    if left_side >= right_side:
        return 100 - 25 * np.log10(1 + (1/p) * (diff_sqr - left_side))
    return None  # Can't be calculated

def bootstrap_f2(reference, test, metric_func, n_iterations=10000):
    """Perform bootstrap resampling for f2 confidence intervals"""
    results = []
    n_units = reference.shape[1] - 1
    
    for _ in range(n_iterations):
        # Resample with replacement
        ref_sample = reference.iloc[:, 0].to_frame()
        test_sample = test.iloc[:, 0].to_frame()
        
        for col in range(1, reference.shape[1]):
            ref_col = reference.iloc[:, col].sample(n=len(reference), replace=True).reset_index(drop=True)
            test_col = test.iloc[:, col].sample(n=len(test), replace=True).reset_index(drop=True)
            ref_sample = pd.concat([ref_sample, ref_col], axis=1)
            test_sample = pd.concat([test_sample, test_col], axis=1)
        
        # Calculate metric
        results.append(metric_func(ref_sample, test_sample))
    
    return np.array(results)

def generate_plots(results, regulation, metric_name):
    """Generate diagnostic plots for bootstrap results"""
    plt.figure(figsize=(12, 5))
    
    # Histogram
    plt.subplot(121)
    sns.histplot(results, kde=True, bins=20)
    plt.title(f"{regulation} {metric_name} Distribution")
    plt.xlabel("f2 Value")
    
    # QQ Plot
    plt.subplot(122)
    stats.probplot(results, dist="norm", plot=plt)
    plt.title(f"{regulation} {metric_name} QQ Plot")
    
    plt.tight_layout()
    plt.savefig(f"{regulation}_{metric_name}_bootstrap.png")
    plt.close()

def calculate_confidence_interval(results, alpha=0.1):
    """Calculate percentile-based confidence interval"""
    lower = np.percentile(results, alpha/2 * 100)
    upper = np.percentile(results, (1 - alpha/2) * 100)
    return lower, upper

def calculate_bca_interval(results, original, alpha=0.1):
    """Calculate bias-corrected accelerated confidence interval"""
    # Bias correction
    z0 = norm.ppf(np.mean(results < original))
    
    # Acceleration
    jk_estimates = []
    n = len(results)
    for i in range(n):
        jk_sample = np.delete(results, i)
        jk_estimates.append(np.mean(jk_sample))
    
    jk_mean = np.mean(jk_estimates)
    num = np.sum((jk_mean - jk_estimates) ** 3)
    den = 6 * (np.sum((jk_mean - jk_estimates) ** 2) ** 1.5)
    a = num / den if den != 0 else 0
    
    # Corrected percentiles
    z_alpha = norm.ppf(alpha/2)
    z_1alpha = norm.ppf(1 - alpha/2)
    
    alpha1 = norm.cdf(z0 + (z0 + z_alpha) / (1 - a * (z0 + z_alpha)))
    alpha2 = norm.cdf(z0 + (z0 + z_1alpha) / (1 - a * (z0 + z_1alpha)))
    
    return np.percentile(results, alpha1 * 100), np.percentile(results, alpha2 * 100)

def run_regulatory_analysis(regulation, reference_df, test_df):
    """Full analysis pipeline for a single regulation"""
    print(f"\n{'='*40}")
    print(f"Analyzing for {regulation} guidelines")
    print(f"{'='*40}")
    
    # Process data according to regulation
    ref_processed, test_processed = process_data_for_regulation(regulation, reference_df, test_df)
    
    # Calculate point estimates
    conv_f2 = calculate_f2(ref_processed, test_processed)
    exp_f2 = calculate_expected_f2(ref_processed, test_processed)
    bc_f2 = calculate_bias_corrected_f2(ref_processed, test_processed)
    
    print(f"\nPoint Estimates:")
    print(f"Conventional f2: {conv_f2:.2f}")
    print(f"Expected f2: {exp_f2:.2f}")
    print(f"Bias-Corrected f2: {bc_f2 if bc_f2 is not None else 'N/A'}")
    
    # Bootstrap analysis
    print("\nBootstrapping...")
    
    # Conventional f2
    conv_results = bootstrap_f2(ref_processed, test_processed, calculate_f2, 1000)
    conv_lower, conv_upper = calculate_confidence_interval(conv_results)
    conv_bca_lower, conv_bca_upper = calculate_bca_interval(conv_results, conv_f2)
    generate_plots(conv_results, regulation, "Conventional_f2")
    
    # Expected f2
    exp_results = bootstrap_f2(ref_processed, test_processed, calculate_expected_f2, 1000)
    exp_lower, exp_upper = calculate_confidence_interval(exp_results)
    exp_bca_lower, exp_bca_upper = calculate_bca_interval(exp_results, exp_f2)
    generate_plots(exp_results, regulation, "Expected_f2")
    
    # Bias-Corrected f2 (if applicable)
    if bc_f2 is not None:
        bc_results = bootstrap_f2(ref_processed, test_processed, calculate_bias_corrected_f2, 1000)
        bc_results = bc_results[~np.isnan(bc_results)]  # Remove invalid calculations
        if len(bc_results) > 0:
            bc_lower, bc_upper = calculate_confidence_interval(bc_results)
            bc_bca_lower, bc_bca_upper = calculate_bca_interval(bc_results, bc_f2)
            generate_plots(bc_results, regulation, "BiasCorrected_f2")
        else:
            bc_lower, bc_upper, bc_bca_lower, bc_bca_upper = np.nan, np.nan, np.nan, np.nan
    else:
        bc_results = np.array([])
        bc_lower, bc_upper, bc_bca_lower, bc_bca_upper = np.nan, np.nan, np.nan, np.nan
    
    # Print results
    print("\nBootstrap Results (90% Confidence Intervals):")
    print(f"{'Metric':<20} | {'Point Estimate':<15} | {'Percentile CI':<20} | {'BCa CI':<20}")
    print(f"{'-'*70}")
    print(f"{'Conventional f2':<20} | {conv_f2:15.2f} | ({conv_lower:.2f}, {conv_upper:.2f}) | ({conv_bca_lower:.2f}, {conv_bca_upper:.2f})")
    print(f"{'Expected f2':<20} | {exp_f2:15.2f} | ({exp_lower:.2f}, {exp_upper:.2f}) | ({exp_bca_lower:.2f}, {exp_bca_upper:.2f})")
    
    if bc_f2 is not None and len(bc_results) > 0:
        print(f"{'Bias-Corrected f2':<20} | {bc_f2:15.2f} | ({bc_lower:.2f}, {bc_upper:.2f}) | ({bc_bca_lower:.2f}, {bc_bca_upper:.2f})")
    else:
        print(f"{'Bias-Corrected f2':<20} | {'N/A':<15} | {'N/A':<20} | {'N/A':<20}")
    
    # Save numerical results
    results_df = pd.DataFrame({
        'Regulation': [regulation],
        'Conventional_f2': [conv_f2],
        'Conv_Percentile_CI_Lower': [conv_lower],
        'Conv_Percentile_CI_Upper': [conv_upper],
        'Conv_BCa_CI_Lower': [conv_bca_lower],
        'Conv_BCa_CI_Upper': [conv_bca_upper],
        'Expected_f2': [exp_f2],
        'Exp_Percentile_CI_Lower': [exp_lower],
        'Exp_Percentile_CI_Upper': [exp_upper],
        'Exp_BCa_CI_Lower': [exp_bca_lower],
        'Exp_BCa_CI_Upper': [exp_bca_upper],
        'BiasCorrected_f2': [bc_f2 if bc_f2 is not None else np.nan],
        'BC_Percentile_CI_Lower': [bc_lower if bc_f2 is not None else np.nan],
        'BC_Percentile_CI_Upper': [bc_upper if bc_f2 is not None else np.nan],
        'BC_BCa_CI_Lower': [bc_bca_lower if bc_f2 is not None else np.nan],
        'BC_BCa_CI_Upper': [bc_bca_upper if bc_f2 is not None else np.nan]
    })
    
    return results_df

def R_all_Regulation(file_path):
    """Python implementation of all regulatory analyses"""
    # Load data
    reference_df = pd.read_excel(file_path, sheet_name=0)
    test_df = pd.read_excel(file_path, sheet_name=1)
    
    # Run analyses for all regulations
    regulations = ["EMA", "FDA", "WHO", "Canada", "ANVISA"]
    all_results = []
    
    for regulation in regulations:
        try:
            results_df = run_regulatory_analysis(regulation, reference_df, test_df)
            all_results.append(results_df)
        except Exception as e:
            print(f"Error processing {regulation}: {str(e)}")
    
    # Combine and save results
    if all_results:
        final_results = pd.concat(all_results, ignore_index=True)
        final_results.to_excel("All_Regulatory_Results.xlsx", index=False)
        print("\nAll regulatory analyses completed successfully!")
        print("Results saved to All_Regulatory_Results.xlsx")
        print("Diagnostic plots saved as PNG files")
    else:
        print("No valid results generated")

# Example usage
if __name__ == "__main__":
    file_path = r"C:\Users\p00095189\Desktop\WORK\Formulations\Similarity_Analyzer\SIMILARITY_ANALYZER\SIMILARITY_ANALYZER\Phase3_Validation\70-80\70-80_Test2_vs_ref4.xlsx"
    R_all_Regulation(file_path)
