def on_created(self, event):
    if not event.is_directory:
        full_path_uploaded_csv = event.src_path
        object_id = ObjectId(self.id)
        experiment = collection.find_one({"_id": object_id})
        
        # Get Objectives and RT parameters from the database
        optimization = experiment.get("optimization_target", {})
        raw_objectives = optimization.get("objectives", {})
        
        # CORRECTED: Extract RT parameters properly from UI input
        objectives_rtmin = raw_objectives.get('RTMin', [])
        objectives_rtmax = raw_objectives.get('RTMax', [])
        
        print(f"Raw RT Min from UI: {objectives_rtmin}")
        print(f"Raw RT Max from UI: {objectives_rtmax}")
        
        if len(objectives_rtmin) != len(objectives_rtmax):
            raise ValueError(f"RTMin and RTMax arrays must have same length: {len(objectives_rtmin)} vs {len(objectives_rtmax)}")
        
        # Method 1: Assume first RT pair is yield, rest are impurities
        YminRT = float(objectives_rtmin[0])  
        YmaxRT = float(objectives_rtmax[0])  
        
        # Impurity RT ranges from remaining pairs
        IminRT_list = []
        ImaxRT_list = []
        
        for i in range(1, len(objectives_rtmin)):
            if str(objectives_rtmin[i]).strip() != '' and str(objectives_rtmax[i]).strip() != '':
                IminRT_list.append(float(objectives_rtmin[i]))
                ImaxRT_list.append(float(objectives_rtmax[i]))
        
        # Internal Standard RT range from separate UI fields
        minRTISO = float(optimization.get("rtMinIso", 0))
        maxRTISO = float(optimization.get("rtMaxIso", 0))
        
        print(f"CORRECTED RT parameters:")
        print(f"  Yield RT: [{YminRT}-{YmaxRT}]")
        print(f"  Impurity RT ranges: {list(zip(IminRT_list, ImaxRT_list))}")
        print(f"  Internal Standard RT: [{minRTISO}-{maxRTISO}]")
        
        # Validate RT parameters
        if YminRT >= YmaxRT:
            raise ValueError(f"Invalid yield RT range: {YminRT} >= {YmaxRT}")
        if minRTISO >= maxRTISO:
            raise ValueError(f"Invalid internal standard RT range: {minRTISO} >= {maxRTISO}")
        if len(IminRT_list) != len(ImaxRT_list):
            raise ValueError(f"Impurity RT min/max lists length mismatch: {len(IminRT_list)} vs {len(ImaxRT_list)}")
        
        # Check for range overlaps (warning only)
        all_ranges = [("Yield", YminRT, YmaxRT), ("ISO", minRTISO, maxRTISO)]
        for i, (imin, imax) in enumerate(zip(IminRT_list, ImaxRT_list)):
            all_ranges.append((f"Impurity{i+1}", imin, imax))
        
        print("Checking for range overlaps:")
        for i, (name1, min1, max1) in enumerate(all_ranges):
            for j, (name2, min2, max2) in enumerate(all_ranges[i+1:], i+1):
                if not (max1 <= min2 or max2 <= min1):  # Ranges overlap
                    print(f"WARNING: {name1} [{min1}-{max1}] overlaps with {name2} [{min2}-{max2}]")
        
        # ✅ CRITICAL FIX: Transform objectives BEFORE using it
        transformed_objectives = []
        for i, name in enumerate(raw_objectives.get("Objectives", [])):
            obj = {
                "name": name,
                "maximize": raw_objectives.get("Condition", [])[i].lower() == "maximize"
            }
            if i < len(raw_objectives.get("Property", [])):
                obj["Property"] = raw_objectives["Property"][i]
            transformed_objectives.append(obj)
        
        print(f"\nTransformed objectives: {transformed_objectives}")
        
        # NOW we can use transformed_objectives to prepare the DataFrame
        lhs = experiment.get('final_result')
        df_experiment = pd.DataFrame(lhs[1:], columns=lhs[0])

        # ✅ CRITICAL FIX: Convert ALL columns to numeric
        print(f"\n{'='*60}")
        print("PREPARING DATAFRAME FOR OPTIMIZATION")
        print(f"{'='*60}")
        print(f"Original DataFrame shape: {df_experiment.shape}")
        print(f"Original DataFrame columns: {list(df_experiment.columns)}")
        print(f"Original DataFrame dtypes:\n{df_experiment.dtypes}")

        # Get objective names
        objective_names = [obj.get("name", "") for obj in transformed_objectives]
        print(f"\nObjective columns: {objective_names}")

        # Convert ALL columns to numeric
        df_numeric = pd.DataFrame()
        for col in df_experiment.columns:
            original_dtype = df_experiment[col].dtype
            original_sample = df_experiment[col].iloc[0] if len(df_experiment) > 0 else None
            
            # Convert to numeric, coerce errors (like empty strings) to NaN
            df_numeric[col] = pd.to_numeric(df_experiment[col], errors='coerce')
            
            new_dtype = df_numeric[col].dtype
            new_sample = df_numeric[col].iloc[0] if len(df_numeric) > 0 else None
            non_null_count = df_numeric[col].notna().sum()
            
            print(f"  {col:30s}: {original_dtype} -> {new_dtype}")
            print(f"    Sample: {original_sample} -> {new_sample} ({non_null_count}/{len(df_numeric)} valid)")

        llm_response_with_objective_columns = df_numeric

        print(f"\nConverted DataFrame dtypes:\n{llm_response_with_objective_columns.dtypes}")
        print(f"\nSample data (first row):")
        if len(llm_response_with_objective_columns) > 0:
            for col in llm_response_with_objective_columns.columns:
                val = llm_response_with_objective_columns[col].iloc[0]
                print(f"  {col:30s}: {val} (type: {type(val).__name__})")

        # Read and process the uploaded HPLC CSV file
        try:
            df_hplc = pd.read_csv(full_path_uploaded_csv)
            print(f"HPLC file loaded: {full_path_uploaded_csv}")
            print(f"HPLC file columns: {list(df_hplc.columns)}")
            print(f"HPLC file shape: {df_hplc.shape}")
            
            # Display first few rows for debugging
            if len(df_hplc) > 0:
                print(f"Sample HPLC data:")
                print(df_hplc.head())
                if 'RT' in df_hplc.columns:
                    print(f"RT range in file: {df_hplc['RT'].min():.3f} - {df_hplc['RT'].max():.3f}")
            
        except Exception as e:
            print(f"Error reading HPLC file: {e}")
            for ws, _ in self.websocket_clients:
                asyncio.run_coroutine_threadsafe(ws.send_text(f"Error reading HPLC file: {e}"), self.loop)
            return
        
        # Get experiment status
        full_path = optimization.get("hplcPath", "")
        completed_experiments = int(experiment.get('completed', 0))
        count_of_lhs = int(experiment.get('lhs_response', {}).get('no_of_LHS', 0))
        user_sor_iterations = int(experiment.get('optimization_target', {}).get('iterations', 1))
        sys_sor_iterations = int(experiment.get('sor_iterations', 1))
        
        print(f"\nExperiment Status:")
        print(f"  Completed: {completed_experiments}/{count_of_lhs} LHS")
        print(f"  SOR Iterations: {sys_sor_iterations-1}/{user_sor_iterations}")
        
        # Process the HPLC file with corrected RT filtering
        try:
            resp = utils.process_uploaded_csv_file(
                full_path_uploaded_csv,
                df_hplc,
                minRTISO,
                maxRTISO,
                YminRT,
                YmaxRT,
                IminRT_list,
                ImaxRT_list,
                transformed_objectives,
                llm_response_with_objective_columns
            )
            print(f"HPLC processing completed. Response: {resp}")
            
        except Exception as e:
            print(f"Error processing HPLC data: {e}")
            import traceback
            traceback.print_exc()
            for ws, _ in self.websocket_clients:
                asyncio.run_coroutine_threadsafe(ws.send_text(f"Error processing HPLC data: {e}"), self.loop)
            return
        
        excel_path = os.path.join(full_path, "optimization.xlsx")
        
        # Phase-based processing logic
        try:
            if completed_experiments < count_of_lhs:
                # LHS Phase: Just update the current row with results
                updated_df = merge_and_save_final_result(excel_path, object_id, resp)
                message = f"LHS experiment {completed_experiments + 1}/{count_of_lhs} completed. Upload next HPLC file."

            elif completed_experiments == count_of_lhs:
                # Transition from LHS to SOR: Process last LHS experiment and generate FIRST SOR row
                updated_df = merge_and_save_final_result(excel_path, object_id, resp)

                # Generate FIRST SOR row based on all LHS rows (with optimized inputs, empty objectives)
                print(f"Generating first SOR row based on {len(updated_df)} completed LHS experiments...")
                sor_response_new_row = utils.generate_multiple_sor_rows(1, transformed_objectives, updated_df)

                # Update final_result with the first SOR row
                final_result = [sor_response_new_row.columns.tolist()] + sor_response_new_row.values.tolist()
                collection.update_one(
                    {"_id": object_id},
                    {
                        "$set": {"final_result": final_result},
                        "$inc": {"sor_iterations": 1}
                    }
                )

                # Save updated Excel with first SOR row
                sor_response_new_row.to_excel(excel_path, index=False)

                message = f"LHS phase completed. Generated SOR iteration 1/{user_sor_iterations} based on {count_of_lhs} LHS rows. Upload HPLC file to fill objectives."

            else:
                # SOR Phase: Fill objectives for current row, then generate next row if needed
                current_sor_iteration = sys_sor_iterations - 1  # Adjust for 0-based indexing

                if current_sor_iteration <= user_sor_iterations:
                    # Fill objectives for current SOR row
                    updated_df = merge_and_save_final_result(excel_path, object_id, resp)

                    if current_sor_iteration < user_sor_iterations:
                        # Generate next SOR row based on all previous rows (LHS + completed SOR)
                        print(f"Generating SOR iteration {current_sor_iteration + 1}/{user_sor_iterations} based on {len(updated_df)} completed experiments...")
                        sor_response_new_row = utils.generate_multiple_sor_rows(1, transformed_objectives, updated_df)

                        # Update final_result with the new SOR row
                        final_result = [sor_response_new_row.columns.tolist()] + sor_response_new_row.values.tolist()
                        collection.update_one(
                            {"_id": object_id},
                            {
                                "$set": {"final_result": final_result},
                                "$inc": {"sor_iterations": 1}
                            }
                        )

                        # Save updated Excel with new SOR row
                        sor_response_new_row.to_excel(excel_path, index=False)

                        message = f"SOR iteration {current_sor_iteration}/{user_sor_iterations} objectives filled. Generated SOR iteration {current_sor_iteration + 1}/{user_sor_iterations} based on {len(updated_df)} rows. Upload HPLC file."
                    else:
                        # Last SOR iteration completed - no more rows to generate
                        collection.update_one(
                            {"_id": object_id},
                            {"$set": {"current_phase": "completed"}}
                        )
                        message = f"SOR iteration {current_sor_iteration}/{user_sor_iterations} completed. All experiments finished!"
                else:
                    # All SOR iterations completed
                    message = "All SOR iterations completed. Optimization finished!"
                    collection.update_one(
                        {"_id": object_id},
                        {"$set": {"current_phase": "completed"}}
                    )
            
        except Exception as e:
            print(f"Error in phase processing: {e}")
            import traceback
            traceback.print_exc()
            message = f"Error processing experiment: {e}"
        
        # Send message to WebSocket clients
        for ws, _ in self.websocket_clients:
            asyncio.run_coroutine_threadsafe(ws.send_text(message), self.loop)
