def predictive_optimal_combinations_advanced(ref_df, test_df, regulation, 
                                             window_min, window_max, 
                                             time_range_points, 
                                             diff_threshold=None,
                                             interp_method='gpr'):
    """
    Stratified dissolution-based sampling with strict pruning using user-defined time ranges.
    
    Parameters:
      ref_df, test_df: DataFrames where the first column is time and the second is dissolution percentage.
      regulation: regulatory guideline (e.g. "FDA")
      window_min, window_max: overall time window boundaries.
      time_range_points: dict with keys as (start, end) time ranges and values as number of desired points.
      diff_threshold: (optional) difference threshold parameter.
      interp_method: interpolation method to use ('gpr' uses GaussianProcessRegressor).
    
    Returns:
      Two lists containing the result dictionary.
    """
    import random
    import numpy as np

    # Generate valid time points using a mix of intervals
    valid_times = np.unique(np.concatenate([
        np.arange(window_min, window_max+1, 3),
        np.arange(window_min, window_max+1, 5),
        np.arange(window_min, window_max+1, 1)
    ]))
    valid_times = valid_times[(valid_times >= window_min) & (valid_times <= window_max)]
    
    # Setup interpolation models
    from sklearn.gaussian_process import GaussianProcessRegressor
    from sklearn.gaussian_process.kernels import ConstantKernel as C, RBF, WhiteKernel
    kernel = C(1.0, (1e-3, 1e3)) * RBF(length_scale=10.0) + WhiteKernel()
    
    # Extract time and dissolution data
    ref_times_arr = ref_df.iloc[:, 0].values.astype(float)
    ref_diss = ref_df.iloc[:, 1].values.astype(float)
    test_times_arr = test_df.iloc[:, 0].values.astype(float)
    test_diss = test_df.iloc[:, 1].values.astype(float)
    
    # Remove NaN entries
    ref_mask = ~np.isnan(ref_times_arr) & ~np.isnan(ref_diss)
    test_mask = ~np.isnan(test_times_arr) & ~np.isnan(test_diss)
    
    # Interpolation setup
    if interp_method == 'gpr':
        def safe_gp_interpolator(x, y):
            from sklearn.gaussian_process import GaussianProcessRegressor
            gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=3)
            valid = ~np.isnan(x) & ~np.isnan(y)
            X = x[valid].reshape(-1, 1)
            gp.fit(X, y[valid])
            return gp
        ref_model = safe_gp_interpolator(ref_times_arr, ref_diss)
        test_model = safe_gp_interpolator(test_times_arr, test_diss)
        def ref_interp(x): 
            return ref_model.predict(np.array(x).reshape(-1, 1))
        def test_interp(x): 
            return test_model.predict(np.array(x).reshape(-1, 1))
    else:
        from scipy.interpolate import interp1d
        kind = interp_method if interp_method in ['linear', 'nearest', 'slinear', 'quadratic', 'cubic'] else 'linear'
        ref_interp = interp1d(ref_times_arr[ref_mask], ref_diss[ref_mask], kind=kind, bounds_error=False, fill_value=np.nan)
        test_interp = interp1d(test_times_arr[test_mask], test_diss[test_mask], kind=kind, bounds_error=False, fill_value=np.nan)
    
    # Build candidate points from user-defined time ranges
    candidate = set()
    diversity = True  # Will check if each time range meets the required count
    # For each provided time range, select candidate points from valid_times that lie within that range.
    for t_range, req in time_range_points.items():
        t_low, t_high = t_range
        times_in_range = [t for t in valid_times if t_low <= t < t_high]
        if len(times_in_range) < req:
            diversity = False
            selected = times_in_range  # not enough points â€“ take all available
        else:
            selected = random.sample(times_in_range, req)
        candidate.update(selected)
    
    # Ensure that window_min is included
    candidate.add(window_min)
    candidate = sorted(candidate)
    
    # Compute predictions for candidate times
    candidate_array = np.array(candidate).reshape(-1, 1)
    ref_pred_vals = ref_interp(candidate_array).flatten()
    test_pred_vals = test_interp(candidate_array).flatten()
    
    # Strict pruning: for candidates (except window_min) that are both >80%, keep only the earliest one.
    above_80_indices = [i for i in range(1, len(candidate))
                        if ref_pred_vals[i] > 80 and test_pred_vals[i] > 80]
    if len(above_80_indices) > 1:
        keep_idx = min(above_80_indices, key=lambda i: candidate[i])
        new_candidate = [candidate[0]]  # always keep the window_min
        for i in range(1, len(candidate)):
            if i == keep_idx or not (ref_pred_vals[i] > 80 and test_pred_vals[i] > 80):
                new_candidate.append(candidate[i])
        candidate = sorted(set(new_candidate))
        candidate_array = np.array(candidate).reshape(-1, 1)
        ref_pred_vals = ref_interp(candidate_array).flatten()
        test_pred_vals = test_interp(candidate_array).flatten()
    
    # FDA-specific rule: ensure last candidate has both predictions >=85%
    if regulation == "FDA":
        last_time = candidate[-1]
        last_ref = ref_interp(last_time)[0]
        last_test = test_interp(last_time)[0]
        if last_ref < 85 or last_test < 85:
            # Look for the next valid time in valid_times that meets criteria
            search_times = [t for t in valid_times if t > last_time]
            found = False
            for t in search_times:
                r = ref_interp(t)[0]
                te = test_interp(t)[0]
                if r >= 85 and te >= 85:
                    candidate.append(t)
                    found = True
                    break
            if not found:
                candidate.append(window_max)
            candidate = sorted(set(candidate))
            candidate_array = np.array(candidate).reshape(-1, 1)
            ref_pred_vals = ref_interp(candidate_array).flatten()
            test_pred_vals = test_interp(candidate_array).flatten()
    
    # Force the first candidate (window_min) to be 0% dissolution for both curves
    if candidate[0] == window_min:
        ref_pred_vals[0] = 0.0
        test_pred_vals[0] = 0.0

    # Calculate F2 value
    diff = test_pred_vals - ref_pred_vals
    p_val = len(candidate)
    # Using the given F2 formula: (adjust parenthesis as needed)
    f2 = 100 - 25 * np.log10(1 + (np.sum(diff**2) / p_val))
    
    # Regulatory compliance check (assume check_regulatory_compliance is defined)
    compliant, reasons = check_regulatory_compliance(
        candidate, regulation,
        {t: ref_pred_vals[i] for i, t in enumerate(candidate)},
        {t: test_pred_vals[i] for i, t in enumerate(candidate)}
    )
    
    result = {
        'sequence': candidate,
        'f2': round(f2, 2),
        'compliant': compliant,
        'reasons': reasons,
        'length': len(candidate),
        'diverse': diversity,
        'ref_vals': ref_pred_vals.tolist(),
        'test_vals': test_pred_vals.tolist()
    }
    return [result], [result]


####################################
# Updated run_predictive block using time-based stratification

if run_predictive.lower() == 'yes':
    # Determine candidate window (assumes determine_candidate_window is defined elsewhere)
    window_min, window_max = determine_candidate_window(
        reference_mean_df, test_mean_df, step=5, initial_threshold=10
    )
    
    # Map regulation from input
    regulation_map = {1: "FDA", 2: "EMA", 3: "China", 4: "ASEAN", 5: "ANVISA"}
    selected_regulation = regulation_map.get(input1, "FDA")
    
    print(f"\nCandidate window: {window_min} to {window_max}")
    
    # Define desired time ranges and the required number of points in each interval.
    # For example, (0-10):2, (10-20):2, (20-30):2, (40-50):2.
    time_range_points = {(0, 10): 2, (10, 20): 2, (20, 30): 2, (40, 50): 2}
    
    # Run predictive analysis using the updated time-based stratification.
    results, all_results = predictive_optimal_combinations_advanced(
        reference_mean_df, test_mean_df, selected_regulation,
        window_min, window_max, time_range_points,
        interp_method='gpr'
    )
    
    # Convert time points to integers for clarity
    for cand in results:
        cand['sequence'] = [int(t) for t in cand['sequence']]
    
    overall_best = results[0] if results else None
    
    if overall_best:
        print("\n=== Optimal Predictive Combination ===")
        print(f"Time Points: {overall_best['sequence']}")
        print(f"Number of Points: {overall_best['length']}")
        print(f"Predicted F2: {overall_best['f2']}")
        print(f"Compliant: {overall_best['compliant']}")
        if overall_best['reasons']:
            print(f"Issues: {', '.join(overall_best['reasons'])}")
        # (Optional: Insert plotting code here)
    else:
        print("No valid candidates generated.")
