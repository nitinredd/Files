import numpy as np
import pandas as pd
import time
from tqdm import tqdm
from scipy.interpolate import interp1d
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, WhiteKernel, ConstantKernel as C
import warnings
import concurrent.futures
import itertools

# -------------------------------
# Dummy placeholder for regulatory check.
# Replace this with your actual compliance logic.
def check_regulatory_compliance(seq, regulation, ref_dict, test_dict):
    # For demonstration purposes, assume all sequences are compliant.
    return True, []
# -------------------------------

def process_sample(seq_length, valid_times, window_max, use_gpr, ref_obj, test_obj, regulation):
    """
    Generates a single combination and computes the F2 score.
    Returns a dictionary with the combination details or None on failure.
    """
    try:
        # Choose valid mid points (exclude 0 and window_max)
        valid_subset = valid_times[(valid_times > 0) & (valid_times < window_max)]
        mid_points = np.random.choice(valid_subset, size=seq_length - 2, replace=False)
        seq = np.sort(np.concatenate(([0], mid_points, [window_max])))
        
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            if use_gpr:
                # For GPR, call the model's predict method
                ref_vals = ref_obj.predict(np.array(seq).reshape(-1, 1))
                test_vals = test_obj.predict(np.array(seq).reshape(-1, 1))
            else:
                # For standard interpolation
                ref_vals = ref_obj(seq)
                test_vals = test_obj(seq)
                
        diff = test_vals - ref_vals
        if not np.isnan(diff).any():
            sum_sq = np.sum(diff**2)
            p = len(seq)
            f2 = 100 - 25 * np.log10(1 + (sum_sq / p))
            compliant, reasons = check_regulatory_compliance(
                seq, regulation,
                dict(zip(seq, ref_vals)),
                dict(zip(seq, test_vals))
            )
            return {
                'sequence': seq.tolist(),
                'f2': round(f2, 2),
                'compliant': compliant,
                'reasons': reasons,
                'length': len(seq)
            }
    except Exception as e:
        # In case of an error (e.g. not enough valid times), return None.
        return None

def predictive_optimal_combinations_advanced(ref_df, test_df, regulation, 
                                             window_min, window_max, diff_threshold=None,
                                             interp_method='linear', num_samples=1000000):
    """
    Updated version with parallel processing for increased speed and improved robustness.
    
    Parameters:
      - ref_df, test_df: DataFrames whose first column is time and second column is dissolution.
      - regulation: Regulatory criteria (used in the compliance check).
      - window_min, window_max: Time window boundaries.
      - interp_method: 'linear' (default) or 'gpr' for Gaussian Process Regression.
      - num_samples: Number of random combinations to generate (default 1e6).
    
    Returns:
      A dictionary with:
        - "top_results": Top 500 combinations (sorted descending by F2 score).
        - "best_result": The single best result (highest F2 score).
        - "all_results": List of all valid combinations computed.
    
    Note:
      The error you encountered (using a string index on a list) is typically due to treating a list as a dictionary.
      Here, the best result is extracted from a list of dictionaries, so ensure you index it (e.g. best_result = results[0]).
    """
    start_time = time.time()
    
    # Setup kernel for Gaussian Process Regression if needed
    kernel = C(1.0, (1e-3, 1e3)) * RBF(length_scale=10.0) + WhiteKernel()
    
    # Convert DataFrame columns to numpy arrays
    ref_times = ref_df.iloc[:, 0].values
    ref_diss = ref_df.iloc[:, 1].values
    test_times = test_df.iloc[:, 0].values
    test_diss = test_df.iloc[:, 1].values
    
    # ===== Interpolation Setup =====
    time_grid = np.arange(window_min, window_max + 1)
    
    use_gpr = (interp_method == 'gpr')
    if use_gpr:
        # Create and fit Gaussian Process models
        ref_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5)
        ref_model.fit(ref_times.reshape(-1, 1), ref_diss)
        test_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5)
        test_model.fit(test_times.reshape(-1, 1), test_diss)
        ref_obj = ref_model
        test_obj = test_model
    else:
        # Use interpolation (interp1d) for both reference and test data
        ref_interp = interp1d(ref_times, ref_diss, kind=interp_method, bounds_error=False, fill_value="extrapolate")
        test_interp = interp1d(test_times, test_diss, kind=interp_method, bounds_error=False, fill_value="extrapolate")
        ref_obj = ref_interp
        test_obj = test_interp
    
    # ===== Time Points Generation =====
    if use_gpr:
        # For GPR, use the model's predict method
        max_ref = np.nanmax(ref_obj.predict(time_grid.reshape(-1, 1)))
        max_test = np.nanmax(test_obj.predict(time_grid.reshape(-1, 1)))
    else:
        max_ref = np.nanmax(ref_obj(time_grid))
        max_test = np.nanmax(test_obj(time_grid))
    max_diss = max(max_ref, max_test)
    
    if max_diss <= 60:
        valid_times = np.unique(np.concatenate([
            np.arange(0, window_max + 1, 3),
            np.arange(0, window_max + 1, 5)
        ]))
    else:
        valid_times = np.arange(0, window_max + 1, 5)
    valid_times = valid_times[(valid_times >= window_min) & (valid_times <= window_max)]
    
    # ===== Generate Random Sequence Lengths =====
    # Each sequence will have a length between 3 and 6 (inclusive)
    seq_lengths = np.random.randint(3, 7, num_samples)
    
    # ===== Parallel Processing of Combinations =====
    results_list = []
    with concurrent.futures.ProcessPoolExecutor() as executor:
        tasks = executor.map(
            process_sample,
            seq_lengths,
            itertools.repeat(valid_times),
            itertools.repeat(window_max),
            itertools.repeat(use_gpr),
            itertools.repeat(ref_obj),
            itertools.repeat(test_obj),
            itertools.repeat(regulation),
            chunksize=1000
        )
        # Use tqdm to display progress
        for res in tqdm(tasks, total=num_samples, desc="Processing combinations"):
            if res is not None:
                results_list.append(res)
    
    # ===== Format and Return Results =====
    # Sort by F2 score descending
    results_list.sort(key=lambda x: -x['f2'])
    top_results = results_list[:500]
    best_result = results_list[0] if results_list else None
    
    elapsed_time = time.time() - start_time
    print(f"\nProcessed {num_samples} combinations in {elapsed_time:.2f} seconds")
    
    return {
        "top_results": top_results,
        "best_result": best_result,
        "all_results": results_list
    }
