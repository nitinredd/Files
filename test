import numpy as np
import pandas as pd
from scipy.stats import norm
import matplotlib.pyplot as plt
from sklearn.utils import resample
import warnings
warnings.filterwarnings('ignore')

# --------------------------
# Core Calculation Functions
# --------------------------

def calculate_f2_metrics(ref_data, test_data):
    """Calculate all three f2 variants for given datasets"""
    # Mean calculations
    ref_means = ref_data.iloc[:, 1:].mean(axis=1)
    test_means = test_data.iloc[:, 1:].mean(axis=1)
    
    # Difference calculations
    diff_squared = (test_means - ref_means)**2
    sum_diff_sq = diff_squared.sum()
    p = len(ref_data)
    
    # Variance calculations
    ref_var = ref_data.iloc[:, 1:].var(axis=1, ddof=1)
    test_var = test_data.iloc[:, 1:].var(axis=1, ddof=1)
    sum_var = (ref_var + test_var).sum()
    n = ref_data.shape[1] - 1  # Number of units
    
    # Conventional f2
    conventional = 100 - 25 * np.log10(1 + sum_diff_sq/p)
    
    # Expected f2
    expected = 100 - 25 * np.log10(1 + (sum_diff_sq + sum_var/n)/p)
    
    # Bias-corrected f2
    left_side = sum_var/n
    right_side = sum_diff_sq + p
    if left_side >= right_side:
        bias_corrected = 100 - 25 * np.log10(1 + (sum_diff_sq - left_side)/p)
    else:
        bias_corrected = None
    
    return {
        'conventional': conventional,
        'expected': expected,
        'bias_corrected': bias_corrected
    }

# ----------------------------
# Regulatory Processing Logic
# ----------------------------

def process_fda_subset(ref_sub, test_sub):
    """FDA-specific processing: truncate when either reaches ≥85%"""
    ref_means = ref_sub.iloc[:, 1:].mean(axis=1)
    test_means = test_sub.iloc[:, 1:].mean(axis=1)
    
    trunc_idx = None
    for i in range(len(ref_means)):
        if ref_means.iloc[i] >= 85 or test_means.iloc[i] >= 85:
            trunc_idx = i
            break
    
    if trunc_idx is not None:
        return (ref_sub.iloc[:trunc_idx+1], 
                test_sub.iloc[:trunc_idx+1],
                f"Truncated at {ref_sub.iloc[trunc_idx,0]}min (FDA ≥85%)")
    return ref_sub, test_sub, "No truncation needed"

def process_ema_subset(ref_sub, test_sub):
    """EMA/ICH-specific processing: truncate when either exceeds 85%"""
    ref_means = ref_sub.iloc[:, 1:].mean(axis=1)
    test_means = test_sub.iloc[:, 1:].mean(axis=1)
    
    trunc_idx = None
    for i in range(len(ref_means)):
        if ref_means.iloc[i] > 85 or test_means.iloc[i] > 85:
            trunc_idx = i
            break
    
    if trunc_idx is not None:
        return (ref_sub.iloc[:trunc_idx+1], 
                test_sub.iloc[:trunc_idx+1],
                f"Truncated at {ref_sub.iloc[trunc_idx,0]}min (EMA >85%)")
    return ref_sub, test_sub, "No truncation needed"

# ------------------------
# Validation & Subsetting
# ------------------------

def validate_subset(ref_sub, test_sub):
    """Check if subset meets basic requirements"""
    # Check matching time points
    if not ref_sub.iloc[:,0].equals(test_sub.iloc[:,0]):
        return False
    
    # Check minimum time points (≥3)
    if len(ref_sub) < 3:
        return False
    
    # Check sample units (≥12)
    if (ref_sub.shape[1] < 13) or (test_sub.shape[1] < 13):
        return False
    
    # Check CV requirements
    def check_cv(df):
        cv = df.iloc[:,1:].std(axis=1) / df.iloc[:,1:].mean(axis=1) * 100
        first_cv = cv.iloc[0]
        rest_cv = cv.iloc[1:]
        return (first_cv < 20) and (rest_cv < 10).all()
    
    return check_cv(ref_sub) and check_cv(test_sub)

def generate_subsets(df, regulation):
    """Generate valid time windows based on regulation"""
    time_points = df.iloc[:,0]
    subsets = []
    
    # FDA requires excluding initial zero if present
    if regulation == 1 and time_points.iloc[0] in (0, '0'):
        min_points = 3
        start_idx = 1
    else:
        min_points = 3
        start_idx = 0
    
    # Generate all possible consecutive windows
    for window_size in range(min_points, len(time_points)+1):
        for start in range(start_idx, len(time_points) - window_size + 1):
            end = start + window_size
            subsets.append( (start, end) )
    
    return subsets

# ------------------
# Main Analysis Flow
# ------------------

def analyze_profiles(reference_df, test_df, regulation):
    """Main analysis function with detailed comparison"""
    results = []
    
    # Generate all valid time windows
    subsets = generate_subsets(reference_df, regulation)
    
    for start, end in subsets:
        # Extract subset
        ref_sub = reference_df.iloc[start:end]
        test_sub = test_df.iloc[start:end]
        
        # Apply regulation-specific processing
        if regulation == 1:
            p_ref, p_test, trunc_reason = process_fda_subset(ref_sub, test_sub)
        else:
            p_ref, p_test, trunc_reason = process_ema_subset(ref_sub, test_sub)
        
        # Validate processed subset
        if validate_subset(p_ref, p_test):
            # Calculate metrics
            metrics = calculate_f2_metrics(p_ref, p_test)
            results.append({
                'original_window': ref_sub.iloc[:,0].tolist(),
                'processed_window': p_ref.iloc[:,0].tolist(),
                'truncation_reason': trunc_reason,
                'conventional': metrics['conventional'],
                'expected': metrics['expected'],
                'bias_corrected': metrics['bias_corrected']
            })
    
    # Sort results by conventional f2 score
    results.sort(key=lambda x: x['conventional'], reverse=True)
    return results

def format_results(results):
    """Generate formatted output with comparison table"""
    # Find best conventional score
    best_score = max(r['conventional'] for r in results) if results else 0
    
    # Print detailed comparison
    print("\nTime Window Analysis Results:")
    print(f"{'Original Time Points':<25} | {'Processed Points':<20} | {'Conventional':<10} | {'Expected':<10} | {'Bias Corrected':<15} | Best")
    print("-"*110)
    
    for res in results:
        # Format time points
        orig_times = ', '.join(map(str, res['original_window']))
        proc_times = ', '.join(map(str, res['processed_window']))
        
        # Format scores
        conv = f"{res['conventional']:.2f}"
        exp = f"{res['expected']:.2f}"
        bias = f"{res['bias_corrected']:.2f}" if res['bias_corrected'] else "N/A"
        
        # Best marker
        best_flag = "★" if res['conventional'] == best_score else ""
        
        print(f"{orig_times:<25} | {proc_times:<20} | {conv:<10} | {exp:<10} | {bias:<15} | {best_flag}")

    # Print optimal scenario
    if results:
        best = next(r for r in results if r['conventional'] == best_score)
        print("\nOptimal Scenario:")
        print(f"- Time Points: {best['processed_window']}")
        print(f"- Conventional f2: {best['conventional']:.2f}")
        print(f"- Truncation Reason: {best['truncation_reason']}")
    else:
        print("\nNo valid time windows found meeting requirements")

# ----------------
# Execution Flow
# ----------------

# Load data
file_path = "your_data.xlsx"
reference_df = pd.read_excel(file_path, sheet_name=0)
test_df = pd.read_excel(file_path, sheet_name=1)

# User input
print("Select Regulation:")
print("1: FDA\n2: EMA/ICH\n3: WHO\n4: Canada\n5: ANVISA")
regulation = int(input("Enter choice (1-5): "))

# Perform analysis
analysis_results = analyze_profiles(reference_df, test_df, regulation)

# Display results
format_results(analysis_results)

# Generate plots
dissolution_curve(reference_df, test_df)
dissolution_curve_interval(reference_df, test_df)
