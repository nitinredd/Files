def predictive_optimal_combinations_advanced(ref_df, test_df, regulation, 
                                             window_min, window_max, diff_threshold=None,
                                             interp_method='gpr', points_per_stratum=None):
    """
    Deterministic selection of candidate time points as follows:
      - Use only times from the grid of 3- and 5-minute increments.
      - Split the candidate window into three dissolution strata (based on predicted reference values):
            * 0-30: select exactly 2 candidate times (deterministically, as the minimum and maximum time in the stratum)
            * 30-60: select exactly 2 candidate times
            * 60-90: select exactly 2 candidate times, with the additional rule that at least one candidate in 60-90 must
                     have both reference and test predictions >=80%.
      - The final candidate combination is the union of these selections (totaling 6 points).
      - For FDA mode, append one extra candidate: the first time (after the last candidate) where both predictions are >=85%,
        yielding 7 points.
      - Compute f2:
            f2 = 50 * log10(100 / (1 + sqrt(mean((test - ref)^2))))
      (No fallback mechanism is included; errors are raised if constraints are not met.)
    """
    import numpy as np
    import math
    from sklearn.gaussian_process import GaussianProcessRegressor
    from sklearn.gaussian_process.kernels import ConstantKernel, RBF, WhiteKernel

    # 1. Build the valid time grid (3- and 5-minute increments)
    valid_times = np.sort(np.unique(np.concatenate([
        np.arange(window_min, window_max+1, 3),
        np.arange(window_min, window_max+1, 5)
    ])))
    
    # 2. Build GP models.
    kernel = ConstantKernel(1.0) * RBF(length_scale=10.0) + WhiteKernel()
    ref_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5)
    test_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5)
    
    ref_clean = ref_df.dropna()
    test_clean = test_df.dropna()
    ref_model.fit(ref_clean.iloc[:, 0].values.reshape(-1, 1), 
                  ref_clean.iloc[:, 1].values.astype(float))
    test_model.fit(test_clean.iloc[:, 0].values.reshape(-1, 1), 
                   test_clean.iloc[:, 1].values.astype(float))
    
    # 3. Prediction function.
    def predict_diss(model, times):
        return model.predict(np.array(times).reshape(-1, 1)).flatten()
    
    # Precompute predictions on valid_times.
    all_ref_pred = predict_diss(ref_model, valid_times)
    all_test_pred = predict_diss(test_model, valid_times)
    
    # 4. Define the dissolution strata based on predicted reference values.
    strata = {
        "0-30": (0, 30),
        "30-60": (30, 60),
        "60-90": (60, 90)
    }
    required_points = 2  # exactly two points per stratum
    
    def eligible_times_for_stratum(stratum_range):
        low, high = stratum_range
        # Only consider times from the valid grid.
        return [t for t, pred in zip(valid_times, all_ref_pred) if low <= pred < high]
    
    # 5. For each stratum, select exactly two candidate times deterministically.
    candidate = []
    for key in ["0-30", "30-60", "60-90"]:
        eligible = eligible_times_for_stratum(strata[key])
        if len(eligible) < required_points:
            raise ValueError(f"Insufficient eligible times in stratum {key}.")
        # Deterministically choose the minimum and maximum time.
        candidate_stratum = [min(eligible), max(eligible)]
        candidate.extend(candidate_stratum)
    
    candidate = sorted(list(set(candidate)))
    
    # (Now candidate should have exactly 6 points; if duplicates occur, that is an error.)
    if len(candidate) != 6:
        raise ValueError(f"Final candidate count ({len(candidate)}) is not equal to 6 as required.")
    
    # 6. Enforce the 60-90 stratum rule: at least one candidate in the 60-90 stratum must have both ref and test >=80%.
    eligible_60_90 = eligible_times_for_stratum(strata["60-90"])
    cand_60_90 = [t for t in candidate if t in eligible_60_90]
    has_80 = False
    for t in cand_60_90:
        idx = int(np.where(valid_times == t)[0][0])
        if all_ref_pred[idx] >= 80 and all_test_pred[idx] >= 80:
            has_80 = True
            break
    if not has_80:
        raise ValueError("No candidate in the 60-90 stratum meets the >=80% threshold for both curves.")
    
    # 7. For FDA mode: Append one extra candidate—the first time (after the last candidate) with both >=85%.
    if regulation == "FDA":
        expected_count = 7
        last_candidate = candidate[-1]
        post_times = [t for t in valid_times if t > last_candidate]
        extra_point = None
        for t in post_times:
            idx = int(np.where(valid_times == t)[0][0])
            if all_ref_pred[idx] >= 85 and all_test_pred[idx] >= 85:
                extra_point = t
                break
        if extra_point is None:
            raise ValueError("No valid extra candidate found for FDA mode.")
        candidate.append(extra_point)
        candidate = sorted(list(set(candidate)))
        if len(candidate) != expected_count:
            raise ValueError(f"Final candidate count ({len(candidate)}) does not equal expected count ({expected_count}).")
    else:
        if len(candidate) != 6:
            raise ValueError(f"Non-FDA candidate count ({len(candidate)}) is not equal to 6.")
    
    # 8. Compute f2.
    ref_vals = predict_diss(ref_model, candidate)
    test_vals = predict_diss(test_model, candidate)
    # (No forced zero here because we are not automatically adding the starting time.)
    diff = test_vals - ref_vals
    f2 = 50 * math.log10(100 / (1 + math.sqrt(np.mean(diff**2))))
    
    result = {
        'sequence': candidate,
        'f2': round(f2, 2),
        'compliant': True,   # Assume regulatory compliance passes; adjust if needed.
        'reasons': [],
        'ref_vals': ref_vals.tolist(),
        'test_vals': test_vals.tolist()
    }
    return [result], [result]
#################333
if run_predictive.lower() == 'yes':
    # Determine candidate window using the helper function.
    window_min, window_max = determine_candidate_window(
        reference_mean_df,
        test_mean_df,
        step=5,
        initial_threshold=10
    )
    
    # Map regulation input.
    regulation_map = {1: "FDA", 2: "EMA", 3: "China", 4: "ASEAN", 5: "ANVISA"}
    selected_regulation = regulation_map.get(input1, "FDA")
    
    print(f"\nCandidate window for combination search: {window_min} to {window_max}")
    
    # Run the deterministic predictive analysis.
    results, all_results = predictive_optimal_combinations_advanced(
        reference_mean_df,
        test_mean_df,
        regulation=selected_regulation,
        window_min=window_min,
        window_max=window_max,
        diff_threshold=None,
        interp_method='gpr',
        points_per_stratum=None
    )
    
    # Convert candidate time points to integers.
    for cand in results:
        cand['sequence'] = [int(t) for t in cand['sequence']]
    
    overall_best = results[0] if results else None
    
    if overall_best:
        print("\n=== Optimal Predictive Combination ===")
        print(f"Time Points (best candidate): {overall_best['sequence']}")
        print(f"Length: {len(overall_best['sequence'])}")
        print(f"Predicted f2 Score: {overall_best['f2']}")
        if overall_best['reasons']:
            print(f"Compliance Issues: {', '.join(overall_best['reasons'])}")
        else:
            print("Regulatory Compliance: Passed")
        
        # Plot the predicted dissolution curves.
        import matplotlib.pyplot as plt
        plt.figure(figsize=(12, 6))
        time_points = overall_best['sequence']
        ref_diss = interpolate_dissolution_curve(reference_mean_df, np.array(time_points), method='gpr')
        test_diss = interpolate_dissolution_curve(test_mean_df, np.array(time_points), method='gpr')
        plt.plot(time_points, ref_diss, 'bo-', label='Reference')
        plt.plot(time_points, test_diss, 'r*--', label='Test')
        plt.title(f"Optimal Profile: Predicted Dissolution (f2 = {overall_best['f2']})")
        plt.xlabel('Time (min)')
        plt.ylabel('Dissolution (%)')
        plt.legend()
        plt.grid(True)
        plt.show()
        
        print("\nPredicted Reference Dissolution Percentages:")
        for t, d in zip(time_points, ref_diss):
            print(f"Time {t} min: {d:.2f}%")
        print("\nPredicted Test Dissolution Percentages:")
        for t, d in zip(time_points, test_diss):
            print(f"Time {t} min: {d:.2f}%")
    else:
        print("❌ No candidate sequence was generated.")
    
    print("\n=== All Candidate Combination (Diverse) ===")
    for idx, cand in enumerate(results):
        seq_print = [int(t) for t in cand['sequence']]
        print(f"{idx+1:3d}. | Points: {seq_print} | Length: {len(seq_print)} | f2: {cand['f2']} | Compliant: {cand['compliant']}")
