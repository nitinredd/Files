from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

# 1) In build_product_vector_store(), chunk the text:
def build_product_vector_store(product):
    text = extract_pdf_text(product["pdf_path"])
    if not text or len(text.strip()) < 100:
        return None

    # split into ~1.5k‑char chunks with 200 overlap
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1500,
        chunk_overlap=200
    )
    chunks = splitter.split_text(text)
    docs = [
        Document(page_content=chunk, metadata={
            "product_id": product["id"],
            "product_name": product["name"],
            "reaction_type": product["reaction_type"],
            "source": product["pdf_path"]
        })
        for chunk in chunks
    ]
    return FAISS.from_documents(docs, cached_embeddings)

# 2) When you create your QA chain, switch to map_reduce and bump k:
def process_product_query(product):
    # … after you have vector_store …
    retriever = vector_store.as_retriever(search_kwargs={"k": 5})

    qa_chain = RetrievalQA.from_chain_type(
        llm=chat_model,
        chain_type="map_reduce",             # ← aggregate multiple chunks
        retriever=retriever,
        chain_type_kwargs={
            "prompt": PROMPT,                # your existing “stuff” prompt
            # Optionally supply a shorter “reduce” prompt if you want finer control
            # "reduce_prompt": REDUCE_PROMPT
        },
        return_source_documents=False
    )
    response = qa_chain.invoke({"query": "Extract API Name, Reaction Chemistry, Yield, Procedure, and Tabular Data"})["result"]
    st.session_state.product_details[product["id"]] = response
    return response, None
