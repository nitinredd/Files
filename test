import pandas as pd
import numpy as np
from summit.domain import Domain, ContinuousVariable
from typing import List, Dict , Any
from summit.strategies import TSEMO,Random, SNOBFIT
from summit.utils.dataset import DataSet

def HPLC_data_read_csv(file_path: str) -> np.ndarray:
    """
    Reads HPLC data from a CSV file.
    Assumes the CSV has 'Area' and 'RT' columns.
    Returns a NumPy array with [Area, RT].
    """
    try:
        data = pd.read_csv(file_path)
        data_final = pd.DataFrame()
        data_final['Peak_Area'] = data['Area']
        data_final['RT'] = data['RT']
        return data_final.to_numpy()
    except Exception as e:
        print(f"Error reading HPLC CSV file {file_path}: {e}")
        return np.array([]) # Return empty array on error

def impurity_response_csv(data_np: np.ndarray, IminRT: float, ImaxRT: float, areaISO: float) -> float:
    """
    Calculates impurity response based on peak area within a given RT range.
    data_np: NumPy array with [Area, RT]
    IminRT, ImaxRT: Retention time range for the impurity
    areaISO: Isocratic peak area for normalization
    """
    areaB = 0
    for i in range(data_np.shape[0]):
        if IminRT <= data_np[i, 1] <= ImaxRT:
            areaB += data_np[i, 0]
    return areaB / areaISO if areaISO != 0 else 0.0

def response_HPLC_csv(
    data_np: np.ndarray,
    YminRT: float, YmaxRT: float,
    IminRT_list: List[float], ImaxRT_list: List[float],
    minRTISO: float, maxRTISO: float,
    nobj: int
) -> List[float]:
    """
    Computes yield and impurity responses from HPLC data.
    data_np: NumPy array with [Area, RT]
    YminRT, YmaxRT: RT range for the main product (yield)
    IminRT_list, ImaxRT_list: Lists of RT ranges for multiple impurities
    minRTISO, maxRTISO: RT range for the internal standard (isocratic)
    nobj: Number of objectives (including yield and impurities)
    """
    if data_np.size == 0:
        # Return default values if data is empty
        return [float('inf')] * nobj

    areaA = 0
    for i in range(data_np.shape[0]):
        if YminRT <= data_np[i, 1] <= YmaxRT:
            areaA += data_np[i, 0]

    areaISO = 0
    for i in range(data_np.shape[0]):
        if minRTISO <= data_np[i, 1] <= maxRTISO:
            areaISO += data_np[i, 0]

    response = []
    # Yield calculation (negative log for minimization)
    yield_result = areaA / areaISO if areaISO != 0 else 0.0
    response.append(-np.log(yield_result) if yield_result > 0 else float('inf')) # Handle log(0)

    # Impurities calculation
    # nobj includes yield, so iterate for nobj-1 impurities
    for i in range(nobj - 1):
        if i < len(IminRT_list) and i < len(ImaxRT_list):
            impurities_result = impurity_response_csv(data_np, IminRT_list[i], ImaxRT_list[i], areaISO)
            response.append(impurities_result)
        else:
            response.append(0.0) # Default if impurity range is missing

    return response

def monitor_folder_creation1_csv(
    file_path: str,
    nobj: List,
    YminRT: float, YmaxRT: float,
    IminRT: float, ImaxRT: float,
    minRTISO: float, maxRTISO: float
) -> Dict[str, Dict[str, List[float]]]:
    """
    Processes a single HPLC CSV file and returns the calculated responses.
    This function wraps the HPLC data reading and response calculation.
    filepath = new file path (excel file path)
    nobj = Objective data objectives names 
    """
    data = HPLC_data_read_csv(file_path)
    response = response_HPLC_csv(data,YminRT,YmaxRT,IminRT,ImaxRT,minRTISO,maxRTISO,nobj)
    return response

def process_hplc_and_fill(filename: str, data_np: np.ndarray,lhs: pd.DataFrame,objectives: list,nobj,hplc_params: dict):
    """Process HPLC data and update results."""
    nobj = max(1, len(objectives))
    # Calculate response
    resp = response_HPLC_csv(
        data_np,
        hplc_params.get("YminRT", 2.0),
        hplc_params.get("YmaxRT", 4.0),
        hplc_params.get("IminRT_list", [0.5]),
        hplc_params.get("ImaxRT_list", [1.0]),
        hplc_params.get("minRTISO", 10.0),
        hplc_params.get("maxRTISO", 12.0),
        nobj
    )

    return resp

def process_uploaded_csv_file(full_path_uploaded_csv,
                              df,
                              minRTISO,
                              maxRTISO,
                              YminRT,
                              YmaxRT,
                              IminRT_list,
                              ImaxRT_list,
                              transformed_objectives,
                              lhs ):
    if 'Area' in df.columns and 'RT' in df.columns:
            data_np = df[['Area', 'RT']].to_numpy()
    else:
        cols_lower = {c.lower(): c for c in df.columns}
        if 'area' in cols_lower and 'rt' in cols_lower:
            data_np = df[[cols_lower['area'], cols_lower['rt']]].to_numpy()
    hplc_params = {}
    if YminRT is not None: hplc_params['YminRT'] = YminRT
    if YmaxRT is not None: hplc_params['YmaxRT'] = YmaxRT
    if IminRT_list is not None:
        hplc_params['IminRT_list'] = [float(x) for x in IminRT_list if str(x).strip() != '']

    if ImaxRT_list is not None:
        hplc_params['ImaxRT_list'] = [float(x) for x in ImaxRT_list if str(x).strip() != '']

    if minRTISO is not None: hplc_params['minRTISO'] = float(minRTISO)
    if maxRTISO is not None: hplc_params['maxRTISO'] = float(maxRTISO)

    resp = process_hplc_and_fill(filename = full_path_uploaded_csv, 
                                 data_np = data_np,
                                 lhs = lhs,
                                 objectives = transformed_objectives,
                                 nobj = len(transformed_objectives),
                                 hplc_params = hplc_params)
    return resp

def build_domain_from_df(df: pd.DataFrame, objectives: List[Dict[str, Any]]):
    """Build optimization domain from DataFrame."""
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    domain = Domain()
    if len(numeric_cols) == 0:
        raise ValueError("No numeric columns to build domain.")

    for col in numeric_cols[:5]:
        sanitized_name = str(col).replace(" ", "_")  # Replace spaces with underscores
        lb = float(df[col].min())
        ub = float(df[col].max())
        if lb == ub:
            lb -= 1e-6
            ub += 1e-6
        domain += ContinuousVariable(name=sanitized_name, description=str(col), bounds=[lb, ub])

    # Add objectives
    for obj in objectives:
        obj_name = obj.get("name", "obj").replace(" ", "_")  # Sanitize objective name
        maximize = bool(obj.get("maximize", False))
        domain += ContinuousVariable(
            name=obj_name,
            description=obj_name,
            bounds=[0, 100],
            is_objective=True,
            maximize=maximize
        )
    return domain

def run_summit_optimization(domain, lhs_df: pd.DataFrame, nobj: int):
    """Run Summit optimization."""
    
    if nobj > 1:
        strat = TSEMO(domain, random_rate=0.00, n_spectral_points=4000)
        lhs_ds = DataSet.from_df(lhs_df)
        
        # Create a copy of lhs_df to avoid modifying original
        lhs_df_clean = lhs_df.copy()
        
        # Flatten MultiIndex columns if they exist
        if isinstance(lhs_df_clean.columns, pd.MultiIndex):
            # Create simple column names to avoid overlap issues
            new_columns = []
            for col in lhs_df_clean.columns:
                if isinstance(col, tuple):
                    # Join tuple elements with underscore, handling potential duplicates
                    col_name = "_".join(str(x) for x in col)
                else:
                    col_name = str(col)
                # Ensure uniqueness
                counter = 1
                original_name = col_name
                while col_name in new_columns:
                    col_name = f"{original_name}_{counter}"
                    counter += 1
                new_columns.append(col_name)
            lhs_df_clean.columns = new_columns
            
            # Recreate DataSet with flattened columns
            lhs_ds = DataSet.from_df(lhs_df_clean)
        
        try:
            out = strat.suggest_experiments(1, lhs_ds, use_spectral_sample=True, pop_size=100, iterations=100)
        except ValueError as e:
            if "columns overlap but no suffix specified" in str(e):
                # If we still have overlap issues, try with reduced parameters
                print("Warning: Column overlap detected, retrying with simpler parameters")
                try:
                    out = strat.suggest_experiments(1, lhs_ds, use_spectral_sample=False, pop_size=50, iterations=50)
                except:
                    # Fallback to SNOBFIT if TSEMO continues to fail
                    print("Warning: TSEMO failed, falling back to SNOBFIT")
                    strat = SNOBFIT(domain)
                    out = strat.suggest_experiments(1, lhs_ds)
            else:
                raise e
    else:
        strat = SNOBFIT(domain)
        lhs_ds = DataSet.from_df(lhs_df)
        out = strat.suggest_experiments(1, lhs_ds)
    
    # Clean up column names in output
    try:
        if isinstance(out.columns, pd.MultiIndex):
            out.columns = [col[0] if isinstance(col, tuple) else col for col in out.columns]
    except Exception:
        pass
    
    if "strategy" in out.columns:
        out = out.drop(columns={"strategy"})
    
    # Find common columns between original lhs_df and output
    original_columns = lhs_df.columns
    if isinstance(original_columns, pd.MultiIndex):
        # For MultiIndex, we need to compare with the flattened names
        common = [c for c in lhs_df_clean.columns if c in out.columns]
        if len(common) > 0:
            out = out[common]
            # Map back to original column structure if needed
            column_mapping = dict(zip(lhs_df_clean.columns, original_columns))
            out.columns = [column_mapping.get(c, c) for c in out.columns]
    else:
        common = [c for c in original_columns if c in out.columns]
        if len(common) > 0:
            out = out[common]
    
    return out

def suggest_experiments_and_append(num_suggestions: int, objectives: List[Dict[str, Any]],lhs):
    try:
        print("In Domain")
        domain = build_domain_from_df(lhs, objectives)
        print("Out Domain")
    except Exception as e:
        raise RuntimeError(f"Domain build failed: {e}")
    suggestions = []
    for _ in range(num_suggestions):
        print("in run optimization")
        out = run_summit_optimization(domain, lhs, len(objectives) or 1)
        print("out run optimization")
        if isinstance(out, pd.DataFrame) and out.shape[0] >= 1:
            suggested = out.iloc[0].to_dict()
        else:
            suggested = {}

        new_row = {c: (np.nan if c not in suggested else suggested[c]) for c in lhs.columns}
        suggestions.append(new_row)
        lhs = pd.concat([lhs, pd.DataFrame([new_row])], ignore_index=True)
    return lhs
