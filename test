// src/components/OpenWebUILoader.jsx
import React from 'react'
import { motion } from 'framer-motion'

/**
 * OpenWebUILoader
 * - lines: number of skeleton rows to render
 * - compact: if true, renders slimmer rows (for tighter UI)
 * - variant: 'dark' | 'muted' (controls color mood)
 */
export default function OpenWebUILoader({ lines = 4, compact = false, variant = 'dark' }) {
  const rowHeight = compact ? 10 : 14
  const gap = compact ? 8 : 12

  // staggered animation config
  const container = {
    hidden: { opacity: 1 },
    show: {
      opacity: 1,
      transition: {
        staggerChildren: 0.10
      }
    }
  }

  const item = {
    hidden: { opacity: 0.18, y: 4, scale: 0.995 },
    show: i => ({
      opacity: [0.18, 0.48, 0.28],
      y: [4, 0, 2],
      scale: [0.995, 1.002, 0.998],
      transition: {
        duration: 1.1,
        ease: 'easeInOut',
        repeat: Infinity,
        repeatDelay: 0.3,
        delay: i * 0.07
      }
    })
  }

  // row widths for more organic look
  const widths = [0.92, 0.78, 0.86, 0.62, 0.74, 0.9]

  const baseClass = variant === 'dark' ? 'owu-skel-dark' : 'owu-skel-muted'

  return (
    <motion.div
      className={`w-full flex flex-col gap-${gap}`}
      variants={container}
      initial="hidden"
      animate="show"
      style={{ display: 'flex', flexDirection: 'column', gap: gap }}
      aria-hidden="true"
    >
      {Array.from({ length: lines }).map((_, i) => (
        <motion.div
          key={i}
          custom={i}
          variants={item}
          className={`${baseClass} owu-skel-row rounded-md`}
          style={{
            height: rowHeight,
            width: `${Math.round((widths[i % widths.length]) * 100)}%`,
            alignSelf: i % 2 === 0 ? 'flex-start' : 'flex-end'
          }}
        />
      ))}
    </motion.div>
  )
}
################################333
/* OpenWebUI-like skeleton styles */
.owu-skel-row {
  position: relative;
  overflow: hidden;
  background-clip: padding-box;
  box-shadow: inset 0 -1px 0 rgba(255,255,255,0.02);
}

/* dark mood (low & deep) */
.owu-skel-dark {
  background: linear-gradient(90deg, rgba(18,20,25,0.86) 0%, rgba(28,30,38,0.92) 50%, rgba(18,20,25,0.86) 100%);
  border: 1px solid rgba(255,255,255,0.02);
  box-shadow: 0 6px 18px rgba(2,6,23,0.28);
}

/* muted mood (lighter) */
.owu-skel-muted {
  background: linear-gradient(90deg, rgba(230,230,235,0.9) 0%, rgba(240,240,245,0.95) 50%, rgba(230,230,235,0.9) 100%);
  border: 1px solid rgba(0,0,0,0.04);
}

/* shimmer overlay */
.owu-skel-row::after {
  content: "";
  position: absolute;
  inset: 0;
  background-image: linear-gradient(90deg, rgba(255,255,255,0) 0%, rgba(255,255,255,0.06) 45%, rgba(255,255,255,0.12) 50%, rgba(255,255,255,0.06) 55%, rgba(255,255,255,0) 100%);
  transform: translateX(-120%);
  animation: owu-shimmer 1.4s linear infinite;
  will-change: transform;
  pointer-events: none;
}

/* subtle dark flash (pulse) — sits behind shimmer to create low/dim flash */
@keyframes owu-shimmer {
  0% { transform: translateX(-120%); opacity: 0.9; }
  50% { transform: translateX(20%); opacity: 1; }
  100% { transform: translateX(120%); opacity: 0.9; }
}

/* smaller responsive gaps for compact mode (tailwind-like fallback if necessary) */
.gap-8 { gap: 8px; }
.gap-12 { gap: 12px; }

/* rounded subtleness */
.rounded-md { border-radius: 10px; }

/* optional: reduce motion for users who prefer reduced motion */
@media (prefers-reduced-motion: reduce) {
  .owu-skel-row::after { animation: none; }
  .owu-skel-row { transition: none; }
}
########################
// src/components/ChatWidget.jsx
import React, { useEffect, useRef, useState } from 'react'
import { motion } from 'framer-motion'
import {
  FiMessageCircle,
  FiX,
  FiMic,
  FiSend,
  FiChevronDown
} from 'react-icons/fi'
import Message from './Message'
import PromptModal from './PromptModal'
import FileUploader from './FileUploader'
import OpenWebUILoader from './OpenWebUILoader'
import { chatRequest, speechToTextUpload, textToSpeechUrl } from '../api'

/**
 * ChatWidget - Complete, production-ready chat widget.
 * - centered modal (non-resizable)
 * - prompts button opens PromptModal (auto-send on pick)
 * - file uploader -> calls /upload-document and shows friendly agent message
 * - STT: records, converts to PCM WAV and uploads to /speech-to-text
 * - inline skeleton loader (OpenWebUILoader) while loading
 * - typing suggestions that render small "table-like" prompt cards; click to send
 */

const TILE_QUESTIONS = {
  "Product A": ["What is the API used?", "What is the batch size?", "Who is the manufacturer?"],
  "Line B": ["What is the speed range?", "What equipment is used?", "What is the pressure limit?"],
  "Formulation Z": ["List excipients used", "Describe dissolution method"],
  "Process Y": ["Steps in granulation?", "Drying temperature?"],
  "Machine Q": ["Model number details?", "Maintenance interval?"]
}

export default function ChatWidget() {
  const [open, setOpen] = useState(false)
  const [promptOpen, setPromptOpen] = useState(false)
  const [messages, setMessages] = useState([])
  const [input, setInput] = useState('')
  const [loading, setLoading] = useState(false)
  const [recording, setRecording] = useState(false)
  const [suggests, setSuggests] = useState([])

  const recorderRef = useRef(null)
  const audioChunksRef = useRef([])
  const scrollRef = useRef(null)
  const typingTimeout = useRef(null)

  // keep scroll bottom in view
  useEffect(() => {
    try { scrollRef.current?.scrollIntoView({ behavior: 'smooth', block: 'end' }) } catch (e) {}
  }, [messages, loading])

  function appendMsg(from, text) {
    setMessages(prev => [...prev, { id: crypto?.randomUUID?.() ?? Date.now(), from, text }])
  }

  async function send(promptToSend = null) {
    const q = (promptToSend !== null) ? String(promptToSend).trim() : input.trim()
    if (!q) return
    appendMsg('user', q)
    setInput('')
    setLoading(true)
    try {
      const resp = await chatRequest(q)
      const ans = resp?.response ?? 'Oops! No relevant information found.'
      // replace skeleton with actual response by appending
      appendMsg('agent', ans)
    } catch (e) {
      appendMsg('agent', 'Error calling backend — ' + String(e.message ?? e))
    } finally {
      setLoading(false)
      setTimeout(() => {
        try { scrollRef.current?.scrollIntoView({ behavior: 'smooth', block: 'end' }) } catch (e) {}
      }, 120)
    }
  }

  // Prompt pick: set input then auto-send
  function onPromptPick(p) {
    setInput(p)
    // brief delay so user sees the input populated
    setTimeout(() => send(p), 260)
  }

  // Typing suggestions (simple heuristics)
  useEffect(() => {
    clearTimeout(typingTimeout.current)
    const val = (input || '').toLowerCase()
    typingTimeout.current = setTimeout(() => {
      const list = []
      if (val.includes('capacity') || val.includes('capacities')) {
        list.push({
          title: 'Capacities table',
          prompt: 'Provide a table with columns: Line | Max Capacity (kg/h) | Typical Batch Size (kg). Return only a markdown table.'
        })
      }
      if (val.includes('dissolution')) {
        list.push({
          title: 'Dissolution conditions table',
          prompt: 'Provide a table with columns: Method | Medium | RPM | Temperature. Return only a markdown table.'
        })
      }
      if (val.includes('excipients') || val.includes('excip')) {
        list.push({
          title: 'Excipients list',
          prompt: 'Return a markdown table with columns: Exipient | Function | Typical % w/w'
        })
      }
      setSuggests(list)
    }, 220)
    return () => clearTimeout(typingTimeout.current)
  }, [input])

  // when user clicks a suggestion card
  function onSuggestionClick(item) {
    setInput(item.prompt)
    setTimeout(() => send(item.prompt), 200)
  }

  // --- Recording + conversion to WAV (PCM16) -------------------------------------------------
  async function startRecording() {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
      const mr = new MediaRecorder(stream)
      recorderRef.current = mr
      audioChunksRef.current = []
      mr.ondataavailable = (e) => audioChunksRef.current.push(e.data)
      mr.onstop = async () => {
        try {
          const blob = new Blob(audioChunksRef.current, { type: audioChunksRef.current[0]?.type || 'audio/webm' })
          const wavBlob = await convertBlobToWav(blob)
          const r = await speechToTextUpload(wavBlob)
          const text = r?.text ?? ''
          if (text) setInput(text)
        } catch (err) {
          appendMsg('agent', 'STT Error: ' + String(err.message ?? err))
        }
      }
      mr.start()
      setRecording(true)
    } catch (e) {
      appendMsg('agent', 'Mic access denied: ' + (e.message || e))
    }
  }

  function stopRecording() {
    const mr = recorderRef.current
    if (mr && mr.state !== 'inactive') mr.stop()
    setRecording(false)
  }

  // decode audio to PCM and build WAV (PCM16) blob
  async function convertBlobToWav(blob) {
    const arrayBuffer = await blob.arrayBuffer()
    const audioCtx = new (window.AudioContext || window.webkitAudioContext)()
    const audioBuffer = await audioCtx.decodeAudioData(arrayBuffer)
    const numChannels = audioBuffer.numberOfChannels
    const sampleRate = audioBuffer.sampleRate

    // interleave channels
    let interleaved
    if (numChannels === 1) {
      interleaved = audioBuffer.getChannelData(0)
    } else {
      const chData = []
      for (let i = 0; i < numChannels; i++) chData.push(audioBuffer.getChannelData(i))
      const len = chData[0].length
      interleaved = new Float32Array(len * numChannels)
      let idx = 0
      for (let i = 0; i < len; i++) {
        for (let c = 0; c < numChannels; c++) {
          interleaved[idx++] = chData[c][i]
        }
      }
    }

    const wavView = encodeWAV(interleaved, numChannels, sampleRate)
    return new Blob([wavView], { type: 'audio/wav' })
  }

  function encodeWAV(samples, numChannels, sampleRate) {
    const bytesPerSample = 2
    const blockAlign = numChannels * bytesPerSample
    const buffer = new ArrayBuffer(44 + samples.length * bytesPerSample)
    const view = new DataView(buffer)

    function writeString(view, offset, str) {
      for (let i = 0; i < str.length; i++) view.setUint8(offset + i, str.charCodeAt(i))
    }

    function floatTo16BitPCM(output, offset, input) {
      for (let i = 0; i < input.length; i++, offset += 2) {
        let s = Math.max(-1, Math.min(1, input[i]))
        s = s < 0 ? s * 0x8000 : s * 0x7FFF
        output.setInt16(offset, s, true)
      }
    }

    writeString(view, 0, 'RIFF')
    view.setUint32(4, 36 + samples.length * bytesPerSample, true)
    writeString(view, 8, 'WAVE')
    writeString(view, 12, 'fmt ')
    view.setUint32(16, 16, true)
    view.setUint16(20, 1, true)
    view.setUint16(22, numChannels, true)
    view.setUint32(24, sampleRate, true)
    view.setUint32(28, sampleRate * blockAlign, true)
    view.setUint16(32, blockAlign, true)
    view.setUint16(34, 16, true)
    writeString(view, 36, 'data')
    view.setUint32(40, samples.length * bytesPerSample, true)
    floatTo16BitPCM(view, 44, samples)
    return view
  }
  // -----------------------------------------------------------------------------------------

  // read aloud helper
  function readAloud(text) {
    const url = textToSpeechUrl(text)
    const audio = new Audio(url)
    audio.play()
  }

  // file uploaded callback
  function onFileUploaded(data) {
    if (data?.filename) appendMsg('agent', `Uploaded: ${data.filename} — indexed and available for querying.`)
    else appendMsg('agent', `Upload result: ${JSON.stringify(data)}`)
  }

  // UI rendering
  return (
    <>
      {/* Floating open button */}
      <div className="fixed bottom-6 right-6 z-50">
        <motion.button
          whileHover={{ scale: 1.05 }}
          whileTap={{ scale: 0.96 }}
          onClick={() => setOpen(true)}
          className="w-16 h-16 rounded-full shadow-glow bg-gradient-to-br from-primary to-indigo-500 flex items-center justify-center text-white text-2xl"
          aria-label="Open chat"
        >
          <FiMessageCircle />
        </motion.button>
      </div>

      {/* Centered Chat Modal */}
      {open && (
        <div className="fixed inset-0 z-60 flex items-center justify-center p-4">
          <div onClick={() => setOpen(false)} className="absolute inset-0 bg-black/40 backdrop-blur-sm" />

          <motion.div
            initial={{ opacity: 0, scale: 0.98 }}
            animate={{ opacity: 1, scale: 1 }}
            className="relative chat-modal bg-white rounded-2xl shadow-2xl overflow-hidden"
            style={{ height: 'min(760px,86vh)', width: 'min(1100px,94vw)' }}
            role="dialog"
            aria-modal="true"
          >
            {/* Header */}
            <div className="flex items-center justify-between px-6 py-4 border-b">
              <div className="flex items-center gap-3">
                <div className="w-11 h-11 rounded-lg bg-gradient-to-br from-primary to-indigo-400 flex items-center justify-center text-white font-bold">SP</div>
                <div>
                  <div className="font-semibold text-lg">Scaleup Predictor</div>
                  <div className="text-xs text-gray-500">Ask your documents & dataset</div>
                </div>
              </div>

              <div className="flex items-center gap-3">
                <button onClick={() => setPromptOpen(true)} className="px-3 py-2 rounded bg-white border flex items-center gap-2">
                  <FiChevronDown /> Prompts
                </button>

                <FileUploader onUploaded={onFileUploaded} />

                <button onClick={() => setOpen(false)} className="p-2 rounded hover:bg-gray-100" aria-label="Close chat">
                  <FiX />
                </button>
              </div>
            </div>

            {/* Main content - messages area */}
            <div className="flex flex-col h-full">
              <div className="flex-1 p-6 pb-6 overflow-auto scrollbar-thin relative">
                {/* Inline skeleton loader (OpenWebUI-like) where the response will appear */}
                {loading && (
                  <div className="pt-2 pb-4">
                    <OpenWebUILoader lines={4} compact={false} variant="dark" />
                  </div>
                )}

                <div className="flex flex-col gap-4">
                  {messages.length === 0 && !loading && (
                    <div className="text-center text-gray-400">Welcome — ask anything related to your dataset or uploaded documents.</div>
                  )}

                  {messages.map(m => (
                    <Message key={m.id} from={m.from} text={m.text} onReadAloud={readAloud} />
                  ))}

                  <div ref={scrollRef} />
                </div>
              </div>

              {/* Composer (pinned; slightly higher if needed) */}
              <div className="px-6 py-4 border-t bg-white relative -translate-y-0">
                <div className="flex items-start gap-3">
                  <textarea
                    value={input}
                    onChange={(e) => setInput(e.target.value)}
                    placeholder="Type your question (Enter to send; Shift+Enter newline)"
                    className="flex-1 resize-none p-3 rounded-xl border focus:outline-none"
                    rows={2}
                    onKeyDown={(e) => {
                      if (e.key === 'Enter' && !e.shiftKey) {
                        e.preventDefault()
                        send()
                      }
                    }}
                    aria-label="Message input"
                  />

                  <div className="flex flex-col gap-2">
                    <button
                      title={recording ? 'Stop recording' : 'Record (speech-to-text)'}
                      onClick={() => { recording ? stopRecording() : startRecording() }}
                      className={`p-3 rounded-lg border ${recording ? 'bg-red-50' : 'bg-white'}`}
                      aria-pressed={recording}
                    >
                      <FiMic />
                    </button>

                    <button onClick={() => send()} className="px-4 py-2 rounded-lg bg-primary text-white flex items-center gap-2" aria-label="Send message">
                      <FiSend /> Send
                    </button>
                  </div>
                </div>

                {/* Typing suggestions rendered as small table-like prompt cards */}
                <div className="mt-3">
                  {suggests.length > 0 && (
                    <div className="flex gap-3">
                      {suggests.map((s, i) => (
                        <motion.div key={i} whileHover={{ y: -6 }} className="p-3 rounded-lg bg-gray-50 border">
                          <div className="text-xs font-medium">{s.title}</div>
                          <div className="text-xs text-gray-500 mt-1 max-w-xs">{s.prompt}</div>
                          <div className="mt-2">
                            <button onClick={() => onSuggestionClick(s)} className="px-2 py-1 text-xs rounded bg-primary text-white">Use</button>
                          </div>
                        </motion.div>
                      ))}
                    </div>
                  )}
                </div>
              </div>
            </div>
          </motion.div>
        </div>
      )}

      <PromptModal open={promptOpen} onClose={() => setPromptOpen(false)} tiles={TILE_QUESTIONS} onPick={onPromptPick} />
    </>
  )
}

