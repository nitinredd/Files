# Updated sections of utils.py

def response_HPLC_csv(
    data_np: np.ndarray,
    YminRT: float, YmaxRT: float,
    IminRT_list: List[float], ImaxRT_list: List[float],
    minRTISO: float, maxRTISO: float,
    nobj: int
) -> List[float]:
    """
    Computes yield and impurity responses from HPLC data.
    Fixed to properly handle RT filtering for each objective.
    """
    if data_np.size == 0:
        return [float('inf')] * nobj

    # Filter data to only include peaks within overall RT range of interest
    # This ensures we only process relevant peaks
    all_rt_ranges = [(YminRT, YmaxRT), (minRTISO, maxRTISO)]
    all_rt_ranges.extend([(IminRT_list[i], ImaxRT_list[i]) for i in range(min(len(IminRT_list), len(ImaxRT_list)))])
    
    min_rt_overall = min([r[0] for r in all_rt_ranges])
    max_rt_overall = max([r[1] for r in all_rt_ranges])
    
    # Filter data to relevant RT range
    filtered_data = []
    for i in range(data_np.shape[0]):
        if min_rt_overall <= data_np[i, 1] <= max_rt_overall:
            filtered_data.append(data_np[i])
    
    if not filtered_data:
        return [float('inf')] * nobj
    
    filtered_data = np.array(filtered_data)

    # Calculate yield area (main product)
    areaA = 0
    for i in range(filtered_data.shape[0]):
        if YminRT <= filtered_data[i, 1] <= YmaxRT:
            areaA += filtered_data[i, 0]
    print(f"Yield area (areaA): {areaA}")

    # Calculate internal standard area
    areaISO = 0
    for i in range(filtered_data.shape[0]):
        if minRTISO <= filtered_data[i, 1] <= maxRTISO:
            areaISO += filtered_data[i, 0]
    print(f"Internal standard area (areaISO): {areaISO}")

    response = []
    # Yield calculation (negative log for minimization)
    yield_result = areaA / areaISO if areaISO != 0 else 0.0
    response.append(-np.log(yield_result) if yield_result > 0 else float('inf'))
    print(f"Yield result: {yield_result}, -log(yield): {response[0]}")

    # Impurities calculation
    for i in range(nobj - 1):
        if i < len(IminRT_list) and i < len(ImaxRT_list):
            impurities_result = impurity_response_csv(filtered_data, IminRT_list[i], ImaxRT_list[i], areaISO)
            response.append(impurities_result)
            print(f"Impurity {i+1} result: {impurities_result}")
        else:
            response.append(0.0)
            print(f"Impurity {i+1} result: 0.0 (default)")

    return response


def suggest_experiments_and_append(num_suggestions: int, objectives: List[Dict[str, Any]], lhs):
    """
    Fixed to generate only the specified number of suggestions one at a time.
    This ensures proper SOR iteration control.
    """
    try:
        print("Building domain...")
        domain = build_domain_from_df(lhs, objectives)
        print(f"Domain created successfully")
        print(f"Domain has {len([v for v in domain.variables if not v.is_objective])} input variables and {len([v for v in domain.variables if v.is_objective])} objectives")
        
        # Print domain details
        input_vars = [v.name for v in domain.variables if not v.is_objective]
        obj_vars = [v.name for v in domain.variables if v.is_objective]
        print(f"Input variables: {input_vars}")
        print(f"Objective variables: {obj_vars}")
        
    except Exception as e:
        raise RuntimeError(f"Domain build failed: {e}")
    
    # FIXED: Only generate ONE suggestion per call, not num_suggestions
    # This allows proper control of SOR iterations
    print(f"\n=== Generating 1 suggestion (requested: {num_suggestions}) ===")
    
    try:
        out = run_summit_optimization(domain, lhs, len(objectives) or 1)
        print(f"Optimization returned: {type(out)}, shape: {out.shape if hasattr(out, 'shape') else 'N/A'}")
        
        if isinstance(out, pd.DataFrame) and out.shape[0] >= 1:
            print(f"Optimization output shape: {out.shape}")
            print(f"Optimization output columns: {list(out.columns)}")
            
            # Convert to dictionary - handle potential MultiIndex columns
            try:
                suggested = out.iloc[0].to_dict()
                print(f"Raw suggestions from optimization: {dict(list(suggested.items())[:5])}...")
            except Exception as e:
                print(f"Error converting output to dict: {e}")
                suggested = {}
        else:
            suggested = {}
            print("WARNING: No suggestions returned from optimization, using empty dict")

        # Create new row with proper column mapping
        new_row = {}
        print("Mapping suggestions to original columns:")
        
        for col in lhs.columns:
            # Check if we have a suggestion for this column
            col_clean = str(col).replace(" ", "_").replace("(", "").replace(")", "").replace("-", "_")
            
            if col_clean in suggested:
                new_row[col] = suggested[col_clean]
                print(f"  {col} <- {col_clean} = {suggested[col_clean]}")
            elif col in suggested:
                new_row[col] = suggested[col]
                print(f"  {col} = {suggested[col]}")
            else:
                # For objective columns or unmapped columns, use NaN
                new_row[col] = np.nan
                print(f"  {col} = NaN (no suggestion)")
        
        print(f"Final new row: {new_row}")
        lhs_updated = pd.concat([lhs, pd.DataFrame([new_row])], ignore_index=True)
        print(f"Successfully added suggestion, total rows: {len(lhs_updated)}")
        
        return lhs_updated
        
    except Exception as e:
        print(f"ERROR generating suggestion: {e}")
        import traceback
        traceback.print_exc()
        
        # Create a row with all NaN values as fallback
        new_row = {c: np.nan for c in lhs.columns}
        print(f"Using fallback row with all NaN: {new_row}")
        lhs_updated = pd.concat([lhs, pd.DataFrame([new_row])], ignore_index=True)
        return lhs_updated
############################################
# Updated WebSocketNotifier class in main.py

class WebSocketNotifier(FileSystemEventHandler):
    def __init__(self, websocket_clients, loop, id):
        self.websocket_clients = websocket_clients
        self.loop = loop
        self.id = id

    def on_created(self, event):
        if not event.is_directory:
            full_path_uploaded_csv = event.src_path
            object_id = ObjectId(self.id)
            experiment = collection.find_one({"_id": object_id})
            
            # Get Objectives 
            optimization = experiment.get("optimization_target", {})
            raw_objectives = optimization.get("objectives", {})
            lhs = experiment.get('final_result')
            df = pd.DataFrame(lhs[1:], columns=lhs[0])
            llm_response_with_objective_columns = df.apply(pd.to_numeric, errors='coerce')
            
            # Transform objectives dynamically
            transformed_objectives = []
            for i, name in enumerate(raw_objectives.get("Objectives", [])):
                obj = {
                    "name": name,
                    "maximize": raw_objectives.get("Condition", [])[i].lower() == "maximize"
                }
                if i < len(raw_objectives.get("Property", [])):
                    obj["Property"] = raw_objectives["Property"][i]
                transformed_objectives.append(obj)

            # Fetch uploaded CSV 
            df = pd.read_csv(full_path_uploaded_csv)
            
            # Process File with RT parameters
            objectives_rtmin = raw_objectives.get('RTMin')
            objectives_rtmax = raw_objectives.get('RTMax')
            minRTISO = float(optimization.get("rtMinIso", 0))
            maxRTISO = float(optimization.get("rtMaxIso", 0))
            YminRT = float(objectives_rtmin[0])
            YmaxRT = float(objectives_rtmax[0])
            IminRT_list = [float(x) for x in objectives_rtmin[1:]]
            ImaxRT_list = [float(x) for x in objectives_rtmax[1:]]
            
            full_path = optimization.get("hplcPath", "")
            completed_experiments = experiment.get('completed')
            count_of_lhs = experiment.get('lhs_response').get('no_of_LHS')
            user_sor_iterations = int(experiment.get('optimization_target', {}).get('iterations', 1))
            sys_sor_iterations = int(experiment.get('sor_iterations', 1))
            
            print(f"Completed: {completed_experiments}, LHS count: {count_of_lhs}")
            print(f"User SOR iterations: {user_sor_iterations}, Sys SOR iterations: {sys_sor_iterations}")
            
            # Process the uploaded HPLC file
            resp = utils.process_uploaded_csv_file(
                full_path_uploaded_csv,
                df,
                minRTISO,
                maxRTISO,
                YminRT,
                YmaxRT,
                IminRT_list,
                ImaxRT_list,
                transformed_objectives,
                llm_response_with_objective_columns
            )
            
            excel_path = os.path.join(full_path, "optimization.xlsx")
            
            # FIXED LOGIC: Proper phase handling
            if int(completed_experiments) < int(count_of_lhs):
                # LHS Phase: Just update the current row with results
                updated_df = merge_and_save_final_result(excel_path, object_id, resp)
                message = f"LHS experiment {completed_experiments + 1}/{count_of_lhs} completed. Upload next HPLC file."
                
            elif int(completed_experiments) == int(count_of_lhs):
                # Transition from LHS to SOR: Process last LHS experiment and generate first SOR row
                updated_df = merge_and_save_final_result(excel_path, object_id, resp)
                
                # Generate ONLY ONE SOR suggestion (fixed num_suggestions=1)
                sor_response_new_line = utils.suggest_experiments_and_append(1, transformed_objectives, updated_df)
                
                # Update final_result with the new SOR row
                final_result = [sor_response_new_line.columns.tolist()] + sor_response_new_line.values.tolist()
                collection.update_one(
                    {"_id": object_id}, 
                    {
                        "$set": {"final_result": final_result},
                        "$inc": {"sor_iterations": 1}
                    }
                )
                
                # Save updated Excel with new SOR row
                sor_response_new_line.to_excel(excel_path, index=False)
                
                message = f"LHS phase completed. Generated SOR iteration 1/{user_sor_iterations}. Upload HPLC file for next experiment."
                
            else:
                # SOR Phase: Handle ongoing SOR iterations
                current_sor_iteration = sys_sor_iterations - 1  # Adjust for 0-based indexing
                
                if current_sor_iteration < user_sor_iterations:
                    # Still in SOR phase: Update current row and generate next
                    updated_df = merge_and_save_final_result(excel_path, object_id, resp)
                    
                    if current_sor_iteration + 1 < user_sor_iterations:
                        # Generate ONLY ONE more SOR suggestion
                        sor_response_new_line = utils.suggest_experiments_and_append(1, transformed_objectives, updated_df)
                        
                        # Update final_result with the new SOR row
                        final_result = [sor_response_new_line.columns.tolist()] + sor_response_new_line.values.tolist()
                        collection.update_one(
                            {"_id": object_id}, 
                            {
                                "$set": {"final_result": final_result},
                                "$inc": {"sor_iterations": 1}
                            }
                        )
                        
                        # Save updated Excel with new SOR row
                        sor_response_new_line.to_excel(excel_path, index=False)
                        
                        message = f"SOR iteration {current_sor_iteration + 1}/{user_sor_iterations} completed. Generated next experiment. Upload HPLC file."
                    else:
                        # Last SOR iteration completed
                        message = f"SOR iteration {current_sor_iteration + 1}/{user_sor_iterations} completed. All experiments finished!"
                        collection.update_one(
                            {"_id": object_id},
                            {"$set": {"current_phase": "completed"}}
                        )
                else:
                    # All SOR iterations completed
                    message = "All SOR iterations completed. Optimization finished!"
                    collection.update_one(
                        {"_id": object_id},
                        {"$set": {"current_phase": "completed"}}
                    )
            
            # Send message to WebSocket clients
            for ws, _ in self.websocket_clients:
                asyncio.run_coroutine_threadsafe(ws.send_text(message), self.loop)
