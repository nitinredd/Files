// src/components/ChatWidget.jsx
import React, { useEffect, useRef, useState } from 'react'
import { motion } from 'framer-motion'
import {
  FiMessageCircle,
  FiX,
  FiMic,
  FiSend,
  FiChevronDown
} from 'react-icons/fi'
import Message from './Message'
import PromptModal from './PromptModal'
import FileUploader from './FileUploader'
import OpenWebUILoader from './OpenWebUILoader'
import { chatRequest, speechToTextUpload, textToSpeechUrl } from '../api'

/**
 * ChatWidget - Complete chat widget with loader inserted directly
 * below the user's query (after the user's message).
 */

const TILE_QUESTIONS = {
  "Product A": ["What is the API used?", "What is the batch size?", "Who is the manufacturer?"],
  "Line B": ["What is the speed range?", "What equipment is used?", "What is the pressure limit?"],
  "Formulation Z": ["List excipients used", "Describe dissolution method"],
  "Process Y": ["Steps in granulation?", "Drying temperature?"],
  "Machine Q": ["Model number details?", "Maintenance interval?"]
}

export default function ChatWidget() {
  const [open, setOpen] = useState(false)
  const [promptOpen, setPromptOpen] = useState(false)
  const [messages, setMessages] = useState([])
  const [input, setInput] = useState('')
  const [loading, setLoading] = useState(false)
  const [recording, setRecording] = useState(false)
  const [suggests, setSuggests] = useState([])

  const recorderRef = useRef(null)
  const audioChunksRef = useRef([])
  const scrollRef = useRef(null)
  const loaderRef = useRef(null)
  const typingTimeout = useRef(null)

  // Keep chat scrolled — when messages or loader change, try to scroll to loader or bottom
  useEffect(() => {
    if (loading) {
      // short delay so loader DOM renders first
      setTimeout(() => {
        if (loaderRef.current) {
          try { loaderRef.current.scrollIntoView({ behavior: 'smooth', block: 'center' }) } catch (e) {}
        } else {
          try { scrollRef.current?.scrollIntoView({ behavior: 'smooth', block: 'end' }) } catch (e) {}
        }
      }, 90)
    } else {
      // scroll to bottom when no longer loading (after a tiny delay to allow new agent message to render)
      setTimeout(() => {
        try { scrollRef.current?.scrollIntoView({ behavior: 'smooth', block: 'end' }) } catch (e) {}
      }, 120)
    }
  }, [loading, messages])

  function appendMsg(from, text) {
    setMessages(prev => [...prev, { id: crypto?.randomUUID?.() ?? Date.now(), from, text }])
  }

  async function send(promptToSend = null) {
    const q = (promptToSend !== null) ? String(promptToSend).trim() : input.trim()
    if (!q) return
    // Append user's message
    appendMsg('user', q)
    setInput('')
    // Start loader positioned under this user's message
    setLoading(true)

    try {
      const resp = await chatRequest(q)
      const ans = resp?.response ?? 'Oops! No relevant information found.'
      // Append the agent response (loader will be removed by setting loading=false)
      appendMsg('agent', ans)
    } catch (e) {
      appendMsg('agent', 'Error calling backend — ' + String(e.message ?? e))
    } finally {
      setLoading(false)
    }
  }

  // Prompt selected from modal -> populate input and auto-send
  function onPromptPick(p) {
    setInput(p)
    setTimeout(() => send(p), 260)
  }

  // Typing suggestions (simple heuristics)
  useEffect(() => {
    clearTimeout(typingTimeout.current)
    const val = (input || '').toLowerCase()
    typingTimeout.current = setTimeout(() => {
      const list = []
      if (val.includes('capacity') || val.includes('capacities')) {
        list.push({
          title: 'Capacities table',
          prompt: 'Provide a table with columns: Line | Max Capacity (kg/h) | Typical Batch Size (kg). Return only a markdown table.'
        })
      }
      if (val.includes('dissolution')) {
        list.push({
          title: 'Dissolution conditions table',
          prompt: 'Provide a table with columns: Method | Medium | RPM | Temperature. Return only a markdown table.'
        })
      }
      if (val.includes('excipients') || val.includes('excip')) {
        list.push({
          title: 'Excipients list',
          prompt: 'Return a markdown table with columns: Exipient | Function | Typical % w/w'
        })
      }
      setSuggests(list)
    }, 220)
    return () => clearTimeout(typingTimeout.current)
  }, [input])

  function onSuggestionClick(item) {
    setInput(item.prompt)
    setTimeout(() => send(item.prompt), 200)
  }

  // STT: record -> convert to WAV -> upload
  async function startRecording() {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
      const mr = new MediaRecorder(stream)
      recorderRef.current = mr
      audioChunksRef.current = []
      mr.ondataavailable = (e) => audioChunksRef.current.push(e.data)
      mr.onstop = async () => {
        try {
          const blob = new Blob(audioChunksRef.current, { type: audioChunksRef.current[0]?.type || 'audio/webm' })
          const wavBlob = await convertBlobToWav(blob)
          const r = await speechToTextUpload(wavBlob)
          const text = r?.text ?? ''
          if (text) setInput(text)
        } catch (err) {
          appendMsg('agent', 'STT Error: ' + String(err.message ?? err))
        }
      }
      mr.start()
      setRecording(true)
    } catch (e) {
      appendMsg('agent', 'Mic access denied: ' + (e.message || e))
    }
  }

  function stopRecording() {
    const mr = recorderRef.current
    if (mr && mr.state !== 'inactive') mr.stop()
    setRecording(false)
  }

  // convert audio blob to WAV (PCM16)
  async function convertBlobToWav(blob) {
    const arrayBuffer = await blob.arrayBuffer()
    const audioCtx = new (window.AudioContext || window.webkitAudioContext)()
    const audioBuffer = await audioCtx.decodeAudioData(arrayBuffer)
    const numChannels = audioBuffer.numberOfChannels
    const sampleRate = audioBuffer.sampleRate

    // interleave channels
    let interleaved
    if (numChannels === 1) {
      interleaved = audioBuffer.getChannelData(0)
    } else {
      const chData = []
      for (let i = 0; i < numChannels; i++) chData.push(audioBuffer.getChannelData(i))
      const length = chData[0].length
      interleaved = new Float32Array(length * numChannels)
      let idx = 0
      for (let i = 0; i < length; i++) {
        for (let c = 0; c < numChannels; c++) {
          interleaved[idx++] = chData[c][i]
        }
      }
    }

    const wavView = encodeWAV(interleaved, numChannels, sampleRate)
    return new Blob([wavView], { type: 'audio/wav' })
  }

  function encodeWAV(samples, numChannels, sampleRate) {
    const bytesPerSample = 2
    const blockAlign = numChannels * bytesPerSample
    const buffer = new ArrayBuffer(44 + samples.length * bytesPerSample)
    const view = new DataView(buffer)

    function writeString(view, offset, str) {
      for (let i = 0; i < str.length; i++) view.setUint8(offset + i, str.charCodeAt(i))
    }

    function floatTo16BitPCM(output, offset, input) {
      for (let i = 0; i < input.length; i++, offset += 2) {
        let s = Math.max(-1, Math.min(1, input[i]))
        s = s < 0 ? s * 0x8000 : s * 0x7FFF
        output.setInt16(offset, s, true)
      }
    }

    writeString(view, 0, 'RIFF')
    view.setUint32(4, 36 + samples.length * bytesPerSample, true)
    writeString(view, 8, 'WAVE')
    writeString(view, 12, 'fmt ')
    view.setUint32(16, 16, true)
    view.setUint16(20, 1, true)
    view.setUint16(22, numChannels, true)
    view.setUint32(24, sampleRate, true)
    view.setUint32(28, sampleRate * blockAlign, true)
    view.setUint16(32, blockAlign, true)
    view.setUint16(34, 16, true)
    writeString(view, 36, 'data')
    view.setUint32(40, samples.length * bytesPerSample, true)
    floatTo16BitPCM(view, 44, samples)
    return view
  }

  // TTS read aloud
  function readAloud(text) {
    const url = textToSpeechUrl(text)
    const audio = new Audio(url)
    audio.play()
  }

  // file upload result handler
  function onFileUploaded(data) {
    if (data?.filename) appendMsg('agent', `Uploaded: ${data.filename} — indexed and available for querying.`)
    else appendMsg('agent', `Upload result: ${JSON.stringify(data)}`)
  }

  // find index of last user message to insert loader after it
  const lastUserIndex = (() => {
    for (let i = messages.length - 1; i >= 0; i--) {
      if (messages[i].from === 'user') return i
    }
    return -1
  })()

  // Build rendered messages with loader inserted right after last user message when loading
  const renderedMessages = []
  messages.forEach((m, idx) => {
    renderedMessages.push(
      <Message key={m.id} from={m.from} text={m.text} onReadAloud={readAloud} />
    )
    if (loading && idx === lastUserIndex) {
      // loader inserted immediately after this user's message
      renderedMessages.push(
        <div key="__loader__" ref={loaderRef} className="pt-2 pb-4">
          <OpenWebUILoader lines={4} compact={false} variant="dark" />
          <div className="text-xs text-gray-400 text-center mt-2">Generating response...</div>
        </div>
      )
    }
  })

  // If there were no messages but loading somehow, render loader at top of messages area
  if (loading && messages.length === 0) {
    renderedMessages.unshift(
      <div key="__loader-first__" ref={loaderRef} className="pt-2 pb-4">
        <OpenWebUILoader lines={4} compact={false} variant="dark" />
        <div className="text-xs text-gray-400 text-center mt-2">Generating response...</div>
      </div>
    )
  }

  return (
    <>
      {/* Floating open button */}
      <div className="fixed bottom-6 right-6 z-50">
        <motion.button
          whileHover={{ scale: 1.05 }}
          whileTap={{ scale: 0.96 }}
          onClick={() => setOpen(true)}
          className="w-16 h-16 rounded-full shadow-glow bg-gradient-to-br from-primary to-indigo-500 flex items-center justify-center text-white text-2xl"
          aria-label="Open chat"
        >
          <FiMessageCircle />
        </motion.button>
      </div>

      {/* Centered Chat Modal */}
      {open && (
        <div className="fixed inset-0 z-60 flex items-center justify-center p-4">
          <div onClick={() => setOpen(false)} className="absolute inset-0 bg-black/40 backdrop-blur-sm" />

          <motion.div
            initial={{ opacity: 0, scale: 0.98 }}
            animate={{ opacity: 1, scale: 1 }}
            className="relative chat-modal bg-white rounded-2xl shadow-2xl overflow-hidden"
            style={{ height: 'min(760px,86vh)', width: 'min(1100px,94vw)' }}
            role="dialog"
            aria-modal="true"
          >
            {/* Header */}
            <div className="flex items-center justify-between px-6 py-4 border-b">
              <div className="flex items-center gap-3">
                <div className="w-11 h-11 rounded-lg bg-gradient-to-br from-primary to-indigo-400 flex items-center justify-center text-white font-bold">SP</div>
                <div>
                  <div className="font-semibold text-lg">Scaleup Predictor</div>
                  <div className="text-xs text-gray-500">Ask your documents & dataset</div>
                </div>
              </div>

              <div className="flex items-center gap-3">
                <button onClick={() => setPromptOpen(true)} className="px-3 py-2 rounded bg-white border flex items-center gap-2">
                  <FiChevronDown /> Prompts
                </button>

                <FileUploader onUploaded={onFileUploaded} />

                <button onClick={() => setOpen(false)} className="p-2 rounded hover:bg-gray-100" aria-label="Close chat">
                  <FiX />
                </button>
              </div>
            </div>

            {/* Main content - messages area */}
            <div className="flex flex-col h-full">
              <div className="flex-1 p-6 pb-6 overflow-auto scrollbar-thin relative">
                <div className="flex flex-col gap-4">
                  {renderedMessages.length === 0 && !loading && (
                    <div className="text-center text-gray-400">Welcome — ask anything related to your dataset or uploaded documents.</div>
                  )}

                  {renderedMessages}

                  <div ref={scrollRef} />
                </div>
              </div>

              {/* Composer pinned near bottom (tweak with -translate-y-2 if you want it slightly higher) */}
              <div className="px-6 py-4 border-t bg-white relative -translate-y-0">
                <div className="flex items-start gap-3">
                  <textarea
                    value={input}
                    onChange={(e) => setInput(e.target.value)}
                    placeholder="Type your question (Enter to send; Shift+Enter newline)"
                    className="flex-1 resize-none p-3 rounded-xl border focus:outline-none"
                    rows={2}
                    onKeyDown={(e) => {
                      if (e.key === 'Enter' && !e.shiftKey) {
                        e.preventDefault()
                        send()
                      }
                    }}
                    aria-label="Message input"
                  />

                  <div className="flex flex-col gap-2">
                    <button
                      title={recording ? 'Stop recording' : 'Record (speech-to-text)'}
                      onClick={() => { recording ? stopRecording() : startRecording() }}
                      className={`p-3 rounded-lg border ${recording ? 'bg-red-50' : 'bg-white'}`}
                      aria-pressed={recording}
                    >
                      <FiMic />
                    </button>

                    <button onClick={() => send()} className="px-4 py-2 rounded-lg bg-primary text-white flex items-center gap-2" aria-label="Send message">
                      <FiSend /> Send
                    </button>
                  </div>
                </div>

                {/* Typing suggestions rendered as small table-like prompt cards */}
                <div className="mt-3">
                  {suggests.length > 0 && (
                    <div className="flex gap-3">
                      {suggests.map((s, i) => (
                        <motion.div key={i} whileHover={{ y: -6 }} className="p-3 rounded-lg bg-gray-50 border">
                          <div className="text-xs font-medium">{s.title}</div>
                          <div className="text-xs text-gray-500 mt-1 max-w-xs">{s.prompt}</div>
                          <div className="mt-2">
                            <button onClick={() => onSuggestionClick(s)} className="px-2 py-1 text-xs rounded bg-primary text-white">Use</button>
                          </div>
                        </motion.div>
                      ))}
                    </div>
                  )}
                </div>
              </div>
            </div>
          </motion.div>
        </div>
      )}

      <PromptModal open={promptOpen} onClose={() => setPromptOpen(false)} tiles={TILE_QUESTIONS} onPick={onPromptPick} />
    </>
  )
}
