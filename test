import os
import subprocess
import json
import streamlit as st
from langchain_openai import AzureChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.pydantic_v1 import BaseModel, Field

# --- Azure settings ---
base_url = "https://your-resource.openai.azure.com/"  # Replace with your endpoint
api_version = "2024-02-15-preview"
api_key = "your_api_key_here"  # Replace with your key
deployment_name = "GPT4o"

# Initialize Azure Chat
chat_model = AzureChatOpenAI(
    azure_deployment=deployment_name,
    api_version=api_version,
    api_key=api_key,
    azure_endpoint=base_url,
    temperature=0
)

# === Python execution function ===
def execute_python(code: str) -> str:
    """Executes Python code safely and returns output"""
    try:
        # Wrap code in a function to prevent global scope issues
        wrapped_code = f"""
import sys
def safe_exec():
    try:
        {code}
    except Exception as e:
        print(f"ERROR: {{e}}", file=sys.stderr)
        
if __name__ == "__main__":
    safe_exec()
"""
        proc = subprocess.run(
            ["python", "-c", wrapped_code],
            capture_output=True,
            text=True,
            timeout=10
        )
        
        if proc.returncode != 0:
            return f"‚õî Execution Error (code {proc.returncode}):\n{proc.stderr.strip()}"
        return proc.stdout.strip() or "‚úÖ Executed successfully (no output)"
    
    except subprocess.TimeoutExpired:
        return "‚è∞ Timeout Error: Code took too long to execute"
    except Exception as e:
        return f"üî• System Error: {str(e)}"

# === Define structured output schema ===
class CodeExecutor(BaseModel):
    """Schema for Python code execution"""
    code: str = Field(..., 
        description="Python code to execute. Must assign final result to 'result' variable or print it."
    )
    
    def execute(self):
        return execute_python(self.code)

# Create structured model
structured_llm = chat_model.with_structured_output(CodeExecutor)

# === Streamlit UI ===
st.title("Azure GPT‚Äë4o + Python Sandbox")
st.caption("This agent can execute Python code for calculations and data processing")

# Initialize session state
if "history" not in st.session_state:
    st.session_state.history = []

# Display chat history
for msg in st.session_state.history:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])
        if "code" in msg:
            with st.expander("Generated Python Code"):
                st.code(msg["code"], language="python")
        if "execution" in msg:
            with st.expander("Execution Result"):
                st.text(msg["execution"])

# Handle user input
if prompt := st.chat_input("What would you like to compute?"):
    # Add user message to history
    st.session_state.history.append({"role": "user", "content": prompt})
    
    # Display user message
    with st.chat_message("user"):
        st.write(prompt)
    
    # Create prompt template
    prompt_template = ChatPromptTemplate.from_messages([
        ("system", 
         "You are a Python expert. Follow these rules:\n"
         "1. For ANY math, data processing, or calculations, generate Python code\n"
         "2. Code must assign final result to 'result' OR print it\n"
         "3. Always include error handling\n"
         "4. Use only built-in Python modules\n\n"
         "Example:\n"
         "User: Calculate 5 factorial\n"
         "Assistant: ```python\nresult = 1\nfor i in range(1,6):\n    result *= i```"),
        ("human", "{input}")
    ])
    
    # Get AI response
    with st.spinner("Analyzing request..."):
        try:
            chain = prompt_template | structured_llm
            response = chain.invoke({"input": prompt})
            code = response.code
        except Exception as e:
            st.error(f"‚ùå AI Error: {str(e)}")
            st.stop()
    
    # Add AI message to history
    st.session_state.history.append({
        "role": "assistant",
        "content": "Generated Python code",
        "code": code
    })
    
    # Display code
    with st.chat_message("assistant"):
        st.write("Executing Python code...")
        with st.expander("Generated Code", expanded=False):
            st.code(code, language="python")
        
        # Execute code
        with st.spinner("Running code..."):
            execution_result = execute_python(code)
        
        # Display execution result
        st.session_state.history[-1]["execution"] = execution_result
        with st.expander("Execution Result", expanded=True):
            st.text(execution_result)

    # Rerun to update UI
    st.rerun()
