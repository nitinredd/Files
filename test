import pandas as pd
import numpy as np
from summit.domain import Domain, ContinuousVariable
from typing import List, Dict
from summit.strategies import TSEMO,Random, SNOBFIT
from summit.utils.dataset import DataSet

def HPLC_data_read_csv(file_path: str) -> np.ndarray:
    """
    Reads HPLC data from a CSV file.
    Assumes the CSV has 'Area' and 'RT' columns.
    Returns a NumPy array with [Area, RT].
    """
    try:
        data = pd.read_csv(file_path)
        data_final = pd.DataFrame()
        data_final['Peak_Area'] = data['Area']
        data_final['RT'] = data['RT']
        return data_final.to_numpy()
    except Exception as e:
        print(f"Error reading HPLC CSV file {file_path}: {e}")
        return np.array([]) # Return empty array on error

def impurity_response_csv(data_np: np.ndarray, IminRT: float, ImaxRT: float, areaISO: float) -> float:
    """
    Calculates impurity response based on peak area within a given RT range.
    data_np: NumPy array with [Area, RT]
    IminRT, ImaxRT: Retention time range for the impurity
    areaISO: Isocratic peak area for normalization
    """
    areaB = 0
    for i in range(data_np.shape[0]):
        if IminRT <= data_np[i, 1] <= ImaxRT:
            areaB += data_np[i, 0]
    return areaB / areaISO if areaISO != 0 else 0.0

def response_HPLC_csv(
    data_np: np.ndarray,
    YminRT: float, YmaxRT: float,
    IminRT_list: List[float], ImaxRT_list: List[float],
    minRTISO: float, maxRTISO: float,
    nobj: int
) -> List[float]:
    """
    Computes yield and impurity responses from HPLC data.
    data_np: NumPy array with [Area, RT]
    YminRT, YmaxRT: RT range for the main product (yield)
    IminRT_list, ImaxRT_list: Lists of RT ranges for multiple impurities
    minRTISO, maxRTISO: RT range for the internal standard (isocratic)
    nobj: Number of objectives (including yield and impurities)
    """
    if data_np.size == 0:
        # Return default values if data is empty
        return [float('inf')] * nobj

    areaA = 0
    for i in range(data_np.shape[0]):
        if YminRT <= data_np[i, 1] <= YmaxRT:
            areaA += data_np[i, 0]

    areaISO = 0
    for i in range(data_np.shape[0]):
        if minRTISO <= data_np[i, 1] <= maxRTISO:
            areaISO += data_np[i, 0]

    response = []
    # Yield calculation (negative log for minimization)
    yield_result = areaA / areaISO if areaISO != 0 else 0.0
    response.append(-np.log(yield_result) if yield_result > 0 else float('inf')) # Handle log(0)

    # Impurities calculation
    # nobj includes yield, so iterate for nobj-1 impurities
    for i in range(nobj - 1):
        if i < len(IminRT_list) and i < len(ImaxRT_list):
            impurities_result = impurity_response_csv(data_np, IminRT_list[i], ImaxRT_list[i], areaISO)
            response.append(impurities_result)
        else:
            response.append(0.0) # Default if impurity range is missing

    return response

def monitor_folder_creation1_csv(
    file_path: str,
    nobj: List,
    YminRT: float, YmaxRT: float,
    IminRT: float, ImaxRT: float,
    minRTISO: float, maxRTISO: float
) -> Dict[str, Dict[str, List[float]]]:
    """
    Processes a single HPLC CSV file and returns the calculated responses.
    This function wraps the HPLC data reading and response calculation.
    filepath = new file path (excel file path)
    nobj = Objective data objectives names 
    """
    data = HPLC_data_read_csv(file_path)
    response = response_HPLC_csv(data,YminRT,YmaxRT,IminRT,ImaxRT,minRTISO,maxRTISO,nobj)
    return response

def create_domain_X(df):
    
    """
    -----------------------------------INPUTS-------------------------------------------
    df : Initial dataframe from user input on GUI - sheet related to LHS - Internal Pass
    ------------------------------------------------------------------------------------
    """
    
    domain = Domain()
    for i in range(1,df.shape[1]):
        if df.iloc[:,i].notna().all():
            name = df.iloc[:,i].name.replace(" ","")
            desc = df.iloc[:1,i][0]
            lb = df.iloc[1:2,i][1]
            ub = df.iloc[2:3,i][2]
            domain += ContinuousVariable(name=name, description=desc, bounds=[lb, ub])
    return domain

def create_domain_y(domain,df):
    
    """
    -----------------------------------INPUTS--------------------------------------------
    df : Initial dataframe from user input on GUI - sheet related to LHS - Internal Pass
    -------------------------------------------------------------------------------------
    """
    for i in range(1, df.shape[1]):
        if df.iloc[:,i].notna().all():
            name = df.iloc[:,i].name.replace(" ","")
            desc = df.iloc[:1,i][0]
            maximize = True if(df.iloc[1:2,i][1] == "Maximize") else False
            domain += ContinuousVariable(name=name, description=desc, bounds=[0, 100], is_objective = True, maximize = maximize)
    return domain

def multi_tsemo(domain,lhs_exp):
    """
    ------------------------------INPUTS-------------------------------------------
    nExp : No of experiments to be suggested by TSEMO algorithm - User Input.
    lhs_exp : Initial experiments generated by LHS Design function - Internal Pass.
    -------------------------------------------------------------------------------
    """
    print(lhs_exp,'in Multi Tsemo')
    print(domain)
    strat_TSEMO = TSEMO(domain,random_rate=0.00,n_spectral_points=4000)
    lhs_exp = DataSet.from_df(lhs_exp)
    tsemo_exp = strat_TSEMO.suggest_experiments(1,lhs_exp,use_spectral_sample=True, 
                                            pop_size=100, 
                                            iterations=100)
    print(tsemo_exp,'EXP')
    return tsemo_exp

def single_snobfit(domain,lhs_exp):
    """
    ------------------------------INPUTS-------------------------------------------
    nExp : No of experiments to be generated by LHS algorithm - User Input.
    lhs_exp : Initial experiments generated by LHS Design function - Internal Pass.
    --------------------------------------------------------------------------------
    """
    strat_SNOBFIT = SNOBFIT(domain)
    lhs_exp = DataSet.from_df(lhs_exp)
    snobfit_exp = strat_SNOBFIT.suggest_experiments(1,lhs_exp)
    return snobfit_exp

def run_optimization(domain,nobj,lhs_exp):
    if nobj > 1:
        print(lhs_exp,'+++_++_+__')
        sor_out = multi_tsemo(domain, lhs_exp)
    elif nobj == 1:
        sor_out = single_snobfit(domain,lhs_exp)

    sor_out.columns = [col[0] for col in sor_out.columns]   
    sor_out = sor_out.drop(columns={"strategy"})
    sor_out = sor_out[lhs_exp.columns.tolist()]
    
    return sor_out

def get_domain(df_userinput_lhs):
    """
    -----------------------------------INPUTS-------------------------------------------
    df_userinput_lhs : Initial dataframe from user input on GUI - sheet related to LHS - Internal Pass
    ------------------------------------------------------------------------------------
    """
    domain = create_domain_X(df_userinput_lhs)
    domain = create_domain_y(domain, df_userinput_lhs)
    return domain


def process_lhs_iteration(df_userinput_lhs,nobj,lhs_exp):
    domain = get_domain(df_userinput_lhs)
    response = run_optimization(domain,nobj,lhs_exp)
    return response
###############################################################
import os
import subprocess
import tempfile
import pandas as pd
import streamlit as st
from langchain_openai import AzureChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.pydantic_v1 import BaseModel, Field

# --- Azure settings ---
base_url=""
api_version="2025-01-01-preview"

api_key=""
deployment_name="api-ai"
model_name="gpt-4.1"

# Initialize Azure Chat
chat_model = AzureChatOpenAI(
    azure_deployment=deployment_name,
    api_version=api_version,
    api_key=api_key,
    azure_endpoint=base_url,
    temperature=0
)

# === Robust Python execution function ===
def execute_python(code: str, attempt: int = 1) -> str:
    """Executes Python code safely using temporary files"""
    MAX_ATTEMPTS = 3

    try:
        # Clean the code while preserving original formatting
        cleaned_code = code.strip().strip("`")
        if cleaned_code.lower().startswith("python"):
            cleaned_code = cleaned_code[6:].strip()

        # Create temporary Python file
        with tempfile.NamedTemporaryFile(suffix=".py", delete=False, mode="w") as tmpfile:
            tmpfile.write(cleaned_code)
            tmpfile_path = tmpfile.name

        try:
            # Execute the file
            proc = subprocess.run(
                ["python", tmpfile_path],
                capture_output=True,
                text=True,
                timeout=15
            )

            # Clean up
            os.unlink(tmpfile_path)

            if proc.returncode != 0:
                error_output = f"‚õî Execution Error (code {proc.returncode}):\n"
                if proc.stderr:
                    error_output += proc.stderr.strip()
                if proc.stdout:
                    error_output += "\n\nOutput:\n" + proc.stdout.strip()
                return error_output

            return proc.stdout.strip() or "‚úÖ Executed successfully (no output)"

        except Exception as e:
            # Clean up even if execution fails
            if os.path.exists(tmpfile_path):
                os.unlink(tmpfile_path)
            raise

    except subprocess.TimeoutExpired:
        return "‚è∞ Timeout Error: Code took too long to execute"
    except Exception as e:
        if attempt < MAX_ATTEMPTS:
            # Try to fix common issues automatically
            fixed_code = cleaned_code.replace("\t", "    ")  # Convert tabs to spaces
            return execute_python(fixed_code, attempt + 1)
        return f"üî• System Error: {str(e)}"


# === Define structured output schema ===
class CodeExecutor(BaseModel):
    """Schema for Python code execution"""
    code: str = Field(
        ...,
        description="Complete, runnable Python code. Must be properly formatted."
    )

    def execute(self):
        return execute_python(self.code)


# Create structured model
structured_llm = chat_model.with_structured_output(CodeExecutor)

# === Streamlit UI ===
st.title("SOR AI")
st.caption("Multi Reasoning Autonomous Agents for flow rate calculation")

# Initialize session state
if "history" not in st.session_state:
    st.session_state.history = []
    st.session_state.debug_mode = False
    st.session_state.excel_data = None

# Toggle for debug mode
st.session_state.debug_mode = st.sidebar.checkbox("Debug Mode", value=False)

# Upload Excel file
uploaded_file = st.sidebar.file_uploader("Upload your Excel file", type=["xlsx", "xls"])
if uploaded_file:
    try:
        # Read Excel file into a dictionary of DataFrames
        st.session_state.excel_data = pd.read_excel(uploaded_file, sheet_name=None)
        st.sidebar.success("Excel uploaded successfully!")
    except Exception as e:
        st.sidebar.error(f"Error loading file: {str(e)}")

# Display chat history
for msg in st.session_state.history:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])
        if "code" in msg:
            with st.expander("Generated Python Code"):
                st.code(msg["code"], language="python")
        if "execution" in msg:
            result = msg["execution"]
            if isinstance(result, pd.DataFrame):
                with st.expander("Execution Result - Table View", expanded=True):
                    st.dataframe(result)
            else:
                with st.expander("Execution Result", expanded=st.session_state.debug_mode):
                    st.text(result)
        if "debug" in msg and st.session_state.debug_mode:
            with st.expander("Debug Info", expanded=True):
                st.json(msg["debug"])

# Handle user input
if prompt := st.chat_input("What would you like to compute?"):
    # Add user message to history
    st.session_state.history.append({"role": "user", "content": prompt})

    # Display user message
    with st.chat_message("user"):
        st.write(prompt)

    # Create prompt template with stronger instructions
    prompt_template = ChatPromptTemplate.from_messages([
        ("system",
         "You are a Python coding expert. Strictly follow these rules:\n"
         "1. Generate COMPLETE, READY-TO-RUN Python code for any math/data operations\n"
         "2. Code MUST be properly indented with 4 spaces (NO tabs)\n"
         "3. Final result MUST be printed to stdout\n"
         "4. DO NOT include markdown code blocks (```python or ```)\n"
         "5. Use only built-in Python modules\n"
         "6. Include error handling with try/except blocks\n"
         "7. Add comments to explain complex logic\n"
         "8. Use uploaded Excel data if provided to extract upper and lower limits\n"
         "9. Test your code before outputting\n\n"
         "The user may describe how to use the Excel data."),
        ("human", "{input}")
    ])

    # Include Excel data in the prompt if available
    if st.session_state.excel_data:
        excel_data_details = {
            sheet_name: df.head(5).to_dict() for sheet_name, df in st.session_state.excel_data.items()
        }
        excel_context = f"Excel Data:\n{excel_data_details}\n\n"
    else:
        excel_context = "No Excel data uploaded.\n\n"

    # Get AI response
    debug_info = {}
    with st.spinner("Analyzing request..."):
        try:
            chain = prompt_template | structured_llm
            response = chain.invoke({"input": excel_context + prompt})
            code = response.code
            debug_info["generated_code"] = code
        except Exception as e:
            st.error(f"‚ùå AI Generation Error: {str(e)}")
            st.stop()

    # Add AI message to history
    st.session_state.history.append({
        "role": "assistant",
        "content": "Generated Python code",
        "code": code,
        "debug": debug_info
    })

    # Display code
    with st.chat_message("assistant"):
        st.write("Executing Python code...")
        with st.expander("Generated Code", expanded=st.session_state.debug_mode):
            st.code(code, language="python")

        # Execute code
        with st.spinner("Running code..."):
            execution_result = execute_python(code)
            
            # Transform output into a DataFrame for table representation if possible
            try:
                # Check for multi-column output
                if execution_result.startswith("[") and "]" in execution_result:
                    execution_result_df = pd.DataFrame(eval(execution_result))
                    execution_result = execution_result_df
            except Exception:
                pass

        # Add execution result to history
        st.session_state.history[-1]["execution"] = execution_result

        # Display execution result
        if isinstance(execution_result, pd.DataFrame):
            with st.expander("Execution Result - Table View", expanded=True):
                st.dataframe(execution_result)
        else:
            with st.expander("Execution Result", expanded=True):
                st.text(execution_result)

        # Add debug info if needed
        if "ERROR" in str(execution_result) and st.session_state.debug_mode:
            st.session_state.history[-1]["debug"]["execution_error"] = execution_result
            with st.expander("Debug Analysis", expanded=True):
                st.write("Attempting to fix code...")
                fix_prompt = f"""
Original code that failed:
{code}

Execution error:
{execution_result}

Please fix the code while following these rules:
1. Keep the same functionality
2. Fix any syntax or runtime errors
3. Maintain proper indentation
4. Add comments explaining fixes
"""
                try:
                    fix_chain = ChatPromptTemplate.from_messages([
                        ("system", "You are a Python debugging expert. Fix the provided code based on the error."),
                        ("human", "{input}")
                    ]) | structured_llm
                    fix_response = fix_chain.invoke({"input": fix_prompt})
                    fixed_code = fix_response.code

                    st.code(fixed_code, language="python")
                    st.session_state.history[-1]["debug"]["fixed_code"] = fixed_code

                    with st.spinner("Running fixed code..."):
                        fixed_result = execute_python(fixed_code)
                    if isinstance(fixed_result, pd.DataFrame):
                        st.dataframe(fixed_result)
                    else:
                        st.text(fixed_result)
                    st.session_state.history[-1]["debug"]["fixed_result"] = fixed_result

                except Exception as e:
                    st.error(f"‚ùå Debug Failed: {str(e)}")

    # Rerun to update UI
    st.rerun()

#########################################
Prompt
My Molecular weight mol/gm are 90.05, 101.19, 318.18, 532.09 and My densities are 1.00, 0.726, 1.08, 0.90 and my volumes(ml/g) are volumes(ml/g) 1 =  5*Equivalence1/2.5, volumes(ml/g) 2 = 2*Equivalence2/7.5, volumes(ml/g) 3 =  2.5*Equivalence3/3.125, and volumes(ml/g) 4 = 7, Moles1 = mass 1/molecular weight 1, Moles2 = mass 2/molecular weight 2, Moles3 = mass 3/molecular weight 3, Moles4 = mass 4/molecular weight 4, My Mass 1 = Equivalence 1 * Moles4 * Molecular weight 1 , Mass 2 = Equivalence 2 * Moles4 * Molecular weight 2 , Mass 3 = Equivalence 3 * Moles4 * Molecular weight 3 , Mass 4 = 1.00, Volume(ml) 1 = Mass 1/ Density 1, Volume(ml) 2 = volumes(ml/g) 1 * Mass 4, Volume(ml) 3 = Mass 2/ Density 2, Volume(ml) 4 = volumes(ml/g) 2 *Mass 4, Volume(ml) 5 = Mass 3/ (0.5*Density 3), Volume(ml) 6 = volumes(ml/g) 3 * Mass 4, Volume(ml) 7= Mass 4, Volume(ml) 8 = volumes(ml/g) 4 * Mass 4, My Observed Total Volume 1 = Volume(ml) 1 + Volume(ml) 2, Observed Total Volume 2 = Volume(ml) 3 + Volume(ml) 4, Observed Total Volume 3 = Volume(ml) 5 + Volume(ml) 6, Observed Total Volume 4 = Volume(ml) 7 + Volume(ml) 8, Total sum of Observed Total Volume = Observed Total Volume 1 + Observed Total Volume 2 + Observed Total Volume 3 + Observed Total Volume 4, Residence Time (min) 1 = Coil Volume 1 / (Flowrate 1 + Flowrate 2), Residence Time (min) 2 = Coil Volume 2 / Flowrate 1 + Flowrate 2 + Flowrate 3, Residence Time (min) 3 = Generated Value from the table, Reaction Time = Residence Time (min) 1 + Residence Time (min) 2 + Residence Time (min) 3, My Coil Volume (ml) 1 = 5.00, Coil Volume (ml) 2 = 10.00, Coil Volume (ml) 3 = 10.00, My flowrates 1 = Observed Total Volume 1/ Total sum of Observed Total Volume*Total Flowrate, My flowrates 2 = Observed Total Volume 2/ Total sum of Observed Total Volume*Total Flowrate, My flowrates 3 = Observed Total Volume 3/ Total sum of Observed Total Volume*Total Flowrate, My flowrates 4 = Observed Total Volume 4/ Total sum of Observed Total Volume*Total Flowrate, My Total Flowrate = Coil Volume (ml) 3/ Residence Time (min) 3. Strictly based on these above formulas I want you to generate a table with Equivalence 1 between range lower limit 1.5 and upper limit 3, Equivalence 2 between range lower limit 6 and upper limit 12, Equivalence 3 between range lower limit 1.5 and upper limit 3, Residence time between range lower limit 1.5 and upper limit 3, Reaction Temperature between range lower limit 35 and upper limit 65, Reaction Time, Flowrates of pump 1, Flowrates of pump 2, Flowrates of pump 3, Flowrates of pump 4, and Total Flowrate. Make sure the generation is logical and strictly maps with the Formulas. The generation shouldn‚Äôt be random rather based on latin hyper cube sampling. I don‚Äôt want any explanation just generate the table for 11 experiments.
