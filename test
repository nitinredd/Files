@app.post("/product/details")
def product_details(req: QARequest):
    """
    Robust product/details endpoint.

    Behavior:
      - If req.product_id is provided:
          * If question == canonical extraction prompt -> run structured extraction (cached) and return parsed structure.
          * Otherwise -> run retrieval QA on that single product and return {"answer":..., "sources":[...]}
      - If req.product_id is NOT provided:
          * Attempt to detect a product name mentioned in the question (normalized filename substring).
            - If a product is detected -> run retrieval QA on that product and return {"answer":..., "sources":[...]}
            - If no product detected -> fallback to a generative model response {"response": "..."} (no retriever).
    """
    import traceback

    try:
        q_text = (req.question or "").strip()
        if not q_text:
            return JSONResponse(status_code=400, content={"error": "question is required"})

        # canonical extraction text (case-insensitive)
        CANONICAL_EXTRACTION = "extract api name, reaction chemistry, yield, procedure, and tabular data"

        # --- helpers inside function to keep scope local and clear ---

        def _normalize_alnum(s: str) -> str:
            """Lowercase and remove non-alphanumeric characters for robust matching."""
            return re.sub(r"[^a-z0-9]", "", (s or "").lower())

        def _detect_product_by_name(question: str) -> Optional[Dict[str, Any]]:
            """
            Detect a product by checking normalized product filenames against normalized question.
            Prefer longer product names first to avoid accidental short substr matches.
            Returns product dict or None.
            """
            products = list_products()
            if not products:
                return None
            q_norm = _normalize_alnum(question)
            for p in sorted(products, key=lambda x: len(x["name"]), reverse=True):
                name_norm = _normalize_alnum(p["name"])
                if name_norm and name_norm in q_norm:
                    return p
            return None

        def _choose_prompt_for_extraction() -> Any:
            """Return extraction prompt (EXTRACTION_PROMPT or fallback)."""
            try:
                return EXTRACTION_PROMPT
            except NameError:
                # fallback to PROMPT if present
                if "PROMPT" in globals():
                    return PROMPT
                # If nothing is configured, raise
                raise RuntimeError("No extraction prompt configured (EXTRACTION_PROMPT or PROMPT missing).")

        def _choose_prompt_for_qa() -> Any:
            """Return QA prompt (QA_PROMPT or fallback)."""
            try:
                return QA_PROMPT
            except NameError:
                # fallback to PROMPT if present (less ideal but safe)
                if "PROMPT" in globals():
                    return PROMPT
                # As last resort, attempt to use EXTRACTION_PROMPT if available
                try:
                    return EXTRACTION_PROMPT
                except NameError:
                    raise RuntimeError("No QA prompt configured (QA_PROMPT, PROMPT, or EXTRACTION_PROMPT missing).")

        def _run_retrieval_for_product(product: Dict[str, Any], question: str, k: int = 3) -> Dict[str, Any]:
            """
            Build a temporary retriever over a single product PDF and run QA using QA_PROMPT.
            Returns {"answer": "...", "sources":[{product_id, product_name}, ...]}
            """
            pdf_path = product.get("pdf_path")
            if not pdf_path or not os.path.exists(pdf_path):
                raise HTTPException(status_code=404, detail=f"PDF not found for product {product.get('id')}")

            # Extract text (may raise)
            text = extract_pdf_text(pdf_path)
            if not text or len(text.strip()) < 20:
                raise HTTPException(status_code=500, detail="Document content empty or unreadable")

            doc = Document(
                page_content=text,
                metadata={
                    "product_id": product["id"],
                    "product_name": product["name"],
                    "reaction_type": product["reaction_type"],
                    "source": pdf_path,
                }
            )

            # Build FAISS for this single doc (acceptable for single-product queries)
            try:
                vs = FAISS.from_documents([doc], cached_embeddings)
            except Exception as e:
                raise HTTPException(status_code=500, detail=f"Failed building FAISS index for product: {e}")

            retriever = vs.as_retriever(search_kwargs={"k": k})

            # Choose QA prompt (with safe fallback)
            try:
                prompt_to_use = _choose_prompt_for_qa()
            except Exception as e:
                raise HTTPException(status_code=500, detail=str(e))

            qa_chain = RetrievalQA.from_chain_type(
                llm=chat_model,
                chain_type="stuff",
                retriever=retriever,
                chain_type_kwargs={"prompt": prompt_to_use},
                return_source_documents=True,
            )

            out = qa_chain({"query": question})
            answer_text = out.get("result") or out.get("output_text") or ""
            source_docs = out.get("source_documents", []) or []

            # Build unique ordered sources
            seen = set()
            sources = []
            for sd in source_docs:
                pid = sd.metadata.get("product_id")
                pname = sd.metadata.get("product_name")
                if pid and pid not in seen:
                    seen.add(pid)
                    sources.append({"product_id": pid, "product_name": pname})
            return {"answer": answer_text, "sources": sources}

        # -------------------------
        # Main logic
        # -------------------------

        # 1) If explicit product_id provided -> use it
        if req.product_id:
            products = list_products()
            product = next((p for p in products if p["id"] == req.product_id), None)
            if not product:
                return JSONResponse(status_code=404, content={"error": "Product not found"})

            is_extraction = q_text.strip().lower() == CANONICAL_EXTRACTION

            if not is_extraction:
                # User question about this product -> run retrieval QA and return answer + sources
                return _run_retrieval_for_product(product, q_text, k=3)

            # Structured extraction requested -> reuse cached parsed result if available
            if req.product_id in _product_details_cache:
                return _product_details_cache[req.product_id]

            # Build or reuse vectorstore and run extraction prompt (k=1)
            vs = build_product_vector_store(product)
            if not vs:
                return JSONResponse(status_code=500, content={"error": "Failed to build vector store (empty/invalid PDF)"})

            retriever = vs.as_retriever(search_kwargs={"k": 1})

            try:
                prompt_for_extraction = _choose_prompt_for_extraction()
            except Exception as e:
                return JSONResponse(status_code=500, content={"error": str(e)})

            qa_chain = RetrievalQA.from_chain_type(
                llm=chat_model,
                chain_type="stuff",
                retriever=retriever,
                chain_type_kwargs={"prompt": prompt_for_extraction},
                return_source_documents=False,
            )

            try:
                raw_response = qa_chain.run(q_text)
            except Exception as e:
                raise HTTPException(status_code=500, detail=f"LLM extraction error: {e}")

            parsed = parse_structured_response(raw_response)
            _product_details_cache[req.product_id] = parsed
            return parsed

        # 2) No explicit product_id -> try to detect a product name mention in the question
        detected_product = _detect_product_by_name(q_text)
        if detected_product:
            # IMPORTANT: build retriever and run QA on the detected product (fixes earlier bug)
            return _run_retrieval_for_product(detected_product, q_text, k=3)

        # 3) Fallback: no product detected -> do a generative response (concise QA prompt)
        try:
            prompt_for_gen = _choose_prompt_for_qa()
        except Exception as e:
            return JSONResponse(status_code=500, content={"error": str(e)})

        qa_chain = RetrievalQA.from_chain_type(
            llm=chat_model,
            chain_type="stuff",
            retriever=None,
            chain_type_kwargs={"prompt": prompt_for_gen},
            return_source_documents=False,
        )

        raw_response = qa_chain.run(q_text)
        return {"response": raw_response}

    except HTTPException as he:
        # Known HTTP exceptions - re-raise so FastAPI handles status codes correctly
        raise he
    except Exception as e:
        # Unexpected error: log and return helpful JSON for local debugging
        tb = traceback.format_exc()
        print("=== /product/details ERROR ===")
        print(tb)
        trace_lines = tb.splitlines()[-20:]
        return JSONResponse(status_code=500, content={
            "error": "Internal server error in /product/details",
            "message": str(e),
            "trace": trace_lines
        })
