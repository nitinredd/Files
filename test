import streamlit as st
import torch
import clip
from PIL import Image
import numpy as np
import faiss
import os

# Load CLIP model
@st.cache_resource
def load_clip_model():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model, preprocess = clip.load("ViT-B/32", device=device)
    return model, preprocess, device

model, preprocess, device = load_clip_model()

# Initialize FAISS index and image database
if "faiss_index" not in st.session_state:
    st.session_state.faiss_index = None
if "image_paths" not in st.session_state:
    st.session_state.image_paths = []

# Function to generate embeddings
def image_to_embedding(image):
    image = preprocess(image).unsqueeze(0).to(device)
    with torch.no_grad():
        embedding = model.encode_image(image)
    return embedding.cpu().numpy().astype('float32')

# Streamlit UI
st.title("Fruit Image Search Engine üçé")

# Option 1: Upload images or load from a folder
image_folder = st.text_input("Path to your fruit images folder:", "fruits_dataset")

if st.button("Load Images"):
    embeddings = []
    image_paths = []
    for img_file in os.listdir(image_folder):
        if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
            image_path = os.path.join(image_folder, img_file)
            image = Image.open(image_path)
            embedding = image_to_embedding(image)
            embeddings.append(embedding)
            image_paths.append(image_path)
    
    if embeddings:
        embeddings = np.array(embeddings).reshape(len(embeddings), -1)
        index = faiss.IndexFlatL2(embeddings.shape[1])
        index.add(embeddings)
        st.session_state.faiss_index = index
        st.session_state.image_paths = image_paths
        st.success(f"Loaded {len(image_paths)} fruit
