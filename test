def predictive_optimal_combinations_advanced(ref_df, test_df, regulation, 
                                             window_min, window_max, diff_threshold=None,
                                             interp_method='gpr', points_per_stratum=None):
    """
    Hybrid stratification: Ensures 2 points per 10-min time window AND 2 points per dissolution stratum,
    with aggressive pruning so that only one candidate (the first) that crosses 80% is retained.
    
    The valid time grid is restricted to only 3- and 5-minute increments.
    For FDA (or similar), once a candidate time point with both predicted dissolution values >=80%
    is encountered (after the starting point), no further time points are added.
    """
    import numpy as np
    import random
    from sklearn.gaussian_process import GaussianProcessRegressor
    from sklearn.gaussian_process.kernels import ConstantKernel, RBF, WhiteKernel

    # --- Dual stratification parameters ---
    # Time-based stratification: 2 points per 10-minute window (e.g., 0-10, 10-20, …)
    time_strata = [(0, 10), (10, 20), (20, 30), (30, 40), (40, 50), (50, 60)]
    points_per_time_stratum = 2  
    # Dissolution-based stratification: 2 points per dissolution range (e.g., 0-30%, 30-60%, etc.)
    diss_strata = [(0, 30), (30, 60), (60, 90), (90, 101)]
    points_per_diss_stratum = 2

    # --- Generate base time grid (only 3- and 5-minute increments) ---
    valid_times = np.sort(np.unique(np.concatenate([
        np.arange(window_min, window_max+1, 3),
        np.arange(window_min, window_max+1, 5)
    ])))
    
    # --- Enhanced interpolation setup ---
    kernel = ConstantKernel(1.0) * RBF(length_scale=10.0) + WhiteKernel()
    ref_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5)
    test_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=5)

    # --- Clean and fit data ---
    ref_clean = ref_df.dropna()
    test_clean = test_df.dropna()
    ref_model.fit(ref_clean.iloc[:, 0].values.reshape(-1, 1), ref_clean.iloc[:, 1].values)
    test_model.fit(test_clean.iloc[:, 0].values.reshape(-1, 1), test_clean.iloc[:, 1].values)

    # --- Prediction function ---
    def predict_diss(model, times):
        return model.predict(np.array(times).reshape(-1, 1)).flatten()

    # Precompute predictions for all valid times
    all_ref_pred = predict_diss(ref_model, valid_times)
    all_test_pred = predict_diss(test_model, valid_times)

    # --- Time-based stratification ---
    time_candidates = []
    for t_low, t_high in time_strata:
        in_window = [t for t in valid_times if t_low <= t < t_high]
        if len(in_window) >= points_per_time_stratum:
            time_candidates.extend(random.sample(list(in_window), points_per_time_stratum))
        else:
            time_candidates.extend(in_window)

    # --- Dissolution-based stratification ---
    diss_candidates = []
    for d_low, d_high in diss_strata:
        valid_in_stratum = [t for t, ref in zip(valid_times, all_ref_pred)
                            if d_low <= ref < d_high]
        if len(valid_in_stratum) >= points_per_diss_stratum:
            diss_candidates.extend(random.sample(list(valid_in_stratum), points_per_diss_stratum))
        else:
            diss_candidates.extend(valid_in_stratum)

    # --- Combine candidates (union of time-based and dissolution-based selections) ---
    candidate = sorted(list(set(time_candidates + diss_candidates)))

    # Force initial time point into candidate list if missing
    if window_min not in candidate:
        candidate.insert(0, window_min)

    # --- Aggressive pruning: Stop at the first candidate (after start) that crosses 80% ---
    pruned_candidate = [candidate[0]]  # always include the starting point
    for t in candidate[1:]:
        idx = int(np.where(valid_times == t)[0][0])
        ref_val = all_ref_pred[idx]
        test_val = all_test_pred[idx]
        pruned_candidate.append(t)
        # Once we find a candidate with both predictions >=80%, break out.
        if ref_val >= 80 and test_val >= 80:
            break
    candidate = sorted(pruned_candidate)

    # --- Final predictions for the candidate times ---
    ref_vals = predict_diss(ref_model, candidate)
    test_vals = predict_diss(test_model, candidate)

    # Force the starting point to 0% dissolution
    if candidate[0] == window_min:
        ref_vals[0] = 0.0
        test_vals[0] = 0.0

    # --- Calculate f2 (using the provided formula) ---
    diff = test_vals - ref_vals
    f2 = 50 * np.log10(100 / (1 + np.sqrt(np.mean(diff ** 2))))

    # --- Regulatory compliance check (assumed to be defined elsewhere) ---
    compliant, reasons = check_regulatory_compliance(candidate, regulation,
                                                     dict(zip(candidate, ref_vals)),
                                                     dict(zip(candidate, test_vals)))
    
    return [{
        'sequence': candidate,
        'f2': round(f2, 2),
        'compliant': compliant,
        'reasons': reasons,
        'ref_vals': ref_vals.tolist(),
        'test_vals': test_vals.tolist()
    }], []
####################################
if run_predictive.lower() == 'yes':
    # Determine candidate window (assumes determine_candidate_window is defined elsewhere)
    window_min, window_max = determine_candidate_window(
        reference_mean_df,
        test_mean_df,
        step=5,
        initial_threshold=10
    )
    
    # Map regulation for predictive analysis
    regulation_map = {1: "FDA", 2: "EMA", 3: "China", 4: "ASEAN", 5: "ANVISA"}
    selected_regulation = regulation_map.get(input1, "FDA")
    
    print(f"\nCandidate window for combination search: {window_min} to {window_max} (using hybrid stratification)")
    
    # Although the original block allowed specifying points per stratum,
    # this hybrid approach uses fixed dual stratification so we ignore the provided points_per_stratum.
    user_points_per_stratum = {(0, 30): 2, (30, 60): 2, (60, 90): 2, (90, 100): 2}
    
    # Run predictive analysis using the updated hybrid approach.
    results, all_results = predictive_optimal_combinations_advanced(
        reference_mean_df,
        test_mean_df,
        regulation=selected_regulation,
        window_min=window_min,
        window_max=window_max,
        diff_threshold=None,
        interp_method='gpr',
        points_per_stratum=user_points_per_stratum  # not used in the new function
    )
    
    # Convert candidate time points to standard Python ints.
    for cand in results:
        cand['sequence'] = [int(t) for t in cand['sequence']]
    
    overall_best = results[0] if results else None
    
    if overall_best:
        print("\n=== Optimal Predictive Combination ===")
        print(f"Condition: {overall_best.get('condition','N/A')}")
        print(f"Dissolution Range: {overall_best.get('diss_range','N/A')}")
        print(f"Time Points (diverse candidate): {overall_best['sequence']}")
        print(f"Length: {len(overall_best['sequence'])}")
        print(f"Predicted f2 Score: {overall_best['f2']}")
        print(f"Diverse Combination: {overall_best.get('diverse', 'N/A')}")
        
        if overall_best['reasons']:
            print(f"Compliance Issues: {', '.join(overall_best['reasons'])}")
        else:
            print("Regulatory Compliance: Passed")
        
        # Plot predicted dissolution curves for the optimal candidate.
        import matplotlib.pyplot as plt
        plt.figure(figsize=(12, 6))
        time_points = overall_best['sequence']
        ref_diss = interpolate_dissolution_curve(reference_mean_df, time_points, method='gpr')
        test_diss = interpolate_dissolution_curve(test_mean_df, time_points, method='gpr')
        if time_points[0] == window_min:
            ref_diss[0] = 0.0
            test_diss[0] = 0.0
        plt.plot(time_points, ref_diss, 'bo-', label='Reference')
        plt.plot(time_points, test_diss, 'r*--', label='Test')
        plt.title(f"Optimal Profile: Predicted Dissolution (f2 = {overall_best['f2']})")
        plt.xlabel('Time (min)')
        plt.ylabel('Dissolution (%)')
        plt.legend()
        plt.grid(True)
        plt.show()
        
        print("\nPredicted Reference Dissolution Percentages:")
        for t, d in zip(time_points, ref_diss):
            print(f"Time {t} min: {d:.2f}%")
        print("\nPredicted Test Dissolution Percentages:")
        for t, d in zip(time_points, test_diss):
            print(f"Time {t} min: {d:.2f}%")
    else:
        print("❌ No candidate sequence was generated.")
    
    print("\n=== All Candidate Combination (Diverse) ===")
    for idx, cand in enumerate(results):
        seq_print = [int(t) for t in cand['sequence']]
        print(f"{idx+1:3d}. {cand.get('diss_range','N/A')} | Points: {seq_print} | Length: {len(seq_print)} | f2: {cand['f2']} | Compliant: {cand['compliant']}")
