# main.py
import os
import re
import glob
import base64
import fitz  # PyMuPDF
import pandas as pd
import io
import logging
from typing import List, Optional, Dict, Any
from fastapi import FastAPI, HTTPException, Query, Path, Depends, Body
from fastapi.responses import JSONResponse, FileResponse, StreamingResponse
from fastapi.middleware.cors import CORSMiddleware

# === Begin: Keep this Azure block EXACTLY as provided by you (do not change) ===
# Azure Configuration
base_url=""
api_version="2025-01-01-preview"

api_key=""
deployment_name="api-ai4o"
model_name="gpt-4o"

# Initialize Azure services
file_store = LocalFileStore('langchain-embeddings')
base = AzureOpenAIEmbeddings(
    model="text-embedding-3-large",
    api_version="2025-01-01-preview",
    azure_endpoint="",
    api_key="",
    azure_deployment="api-ai-3l"
)
chat_model = AzureChatOpenAI(
    azure_deployment=deployment_name,
    model=model_name,
    api_version=api_version,
    api_key=api_key,
    azure_endpoint=base_url
)
cached_embeddings = CacheBackedEmbeddings.from_bytes_store(base, file_store, namespace=base.model)
# === End Azure block (unchanged) ===

# Note: the Azure classes used above require the same imports as in your original Streamlit code.
# Ensure the following imports are present (they come from your original environment):
from langchain_openai import AzureChatOpenAI
from langchain.openai import AzureOpenAIEmbeddings  # alias - some installs differ; you had langchain_openai earlier
from langchain.embeddings.cache import CacheBackedEmbeddings
from langchain.storage.file_system import LocalFileStore
from langchain_community.vectorstores import FAISS
from langchain.docstore.document import Document
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

# If your environment uses different import paths for AzureOpenAIEmbeddings, adjust accordingly.
# The code above mirrors the classes used in your Streamlit snippet.

# -------------------------
# App & Logging
# -------------------------
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("chemhub_api")

# Keep the same root path & title as your login snippet indicated
app = FastAPI(
    title="ChemHub",
    redoc_url=None,
    root_path="/chemhub/api",
)

# Allow CORS from everywhere (for demo). You may restrict this for production.
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# -------------------------
# Reaction types and Paths (kept same)
# -------------------------
REACTION_TYPES = [
    "C-C_Bond_Formation", "C-N_Bond_Formation", "Salt_Formation", "Hydrolysis",
    "Amidation", "Reduction", "Oxidation", "Cyclization", "Purification",
    "Metal_mediated_catalyzed", "C-halogen Bond Formation", "Miscellaneous"
]

# Base directories (kept your original path)
BASE_DIR = r"C:\Users\Desktop\WORK\API\Reaction_Database\Datasets_O\Reaction_Database"
PRODUCTS_DIR = os.path.join(BASE_DIR, "Products")
SCHEMES_DIR = os.path.join(BASE_DIR, "Synthetic_Schemes")
os.makedirs(PRODUCTS_DIR, exist_ok=True)
os.makedirs(SCHEMES_DIR, exist_ok=True)

# -------------------------
# Prompt (identical to Streamlit)
# -------------------------
PROMPT_TEMPLATE = """
You are a pharmaceutical chemistry expert specializing in reaction chemistry. 
Extract the following information from the document in a structured format:

1. **API Name**: The active pharmaceutical ingredient
2. **Reaction Chemistry**: Type and description
3. **Yield**: Exact yield percentage or value
4. **Procedure**: Complete procedure EXACTLY as written in the source. 
   Preserve all formatting, punctuation, and structure. Do NOT modify or summarize.
5. **Tabular Data**: Provide COMPLETE tabular data in markdown table format. 
   Do NOT omit, summarize, or transform any content.

Structure your response as follows:

### API Name
[API name here]

### Reaction Chemistry
[Reaction chemistry description here]

### Yield
[Yield value here]

### Procedure
[Complete procedure here]

### Tabular Data
[Markdown table here]

Document Content:
{context}

Question: {question}
Answer:
"""
PROMPT = PromptTemplate(
    template=PROMPT_TEMPLATE,
    input_variables=["context", "question"]
)

# -------------------------
# In-memory caches and product registry
# -------------------------
_products_registry: List[Dict[str, Any]] = []
_product_details_cache: Dict[str, str] = {}   # product_id -> QA result (string)

# -------------------------
# Utility functions (mirrors Streamlit logic)
# -------------------------
def find_scheme_image(reaction_type: str, product_name: str) -> Optional[str]:
    extensions = ['.jpeg', '.jpg', '.png', '.gif']
    for ext in extensions:
        scheme_path = os.path.join(SCHEMES_DIR, reaction_type, f"{product_name}{ext}")
        if os.path.exists(scheme_path):
            return scheme_path
    return None

def load_product_database() -> List[Dict[str, Any]]:
    """
    Scans PRODUCTS_DIR and returns a list of product metadata dictionaries.
    """
    products = []
    for reaction_type in REACTION_TYPES:
        reaction_dir = os.path.join(PRODUCTS_DIR, reaction_type)
        if not os.path.exists(reaction_dir):
            continue
        pdf_files = glob.glob(os.path.join(reaction_dir, "*.pdf"))
        for pdf_path in pdf_files:
            try:
                filename = os.path.basename(pdf_path)
                product_name = os.path.splitext(filename)[0]
                scheme_image = find_scheme_image(reaction_type, product_name)
                scheme_cdx = os.path.join(SCHEMES_DIR, reaction_type, f"{product_name}.cdx")
                product_id = f"{reaction_type}_{product_name}"
                products.append({
                    "id": product_id,
                    "name": product_name,
                    "reaction_type": reaction_type,
                    "pdf_path": pdf_path,
                    "scheme_image": scheme_image if scheme_image else None,
                    "scheme_cdx": scheme_cdx if os.path.exists(scheme_cdx) else None
                })
            except Exception as e:
                logger.exception("Error processing file %s: %s", pdf_path, str(e))
    return products

def extract_pdf_text(pdf_path: str) -> str:
    text = ""
    try:
        doc = fitz.open(pdf_path)
        for page in doc:
            text += page.get_text() + "\n"
        return text
    except Exception as e:
        logger.exception("Error reading PDF %s: %s", pdf_path, str(e))
        return ""

def build_product_vector_store(product: Dict[str, Any]):
    """
    Returns a FAISS vectorstore built for the single product or None if insufficient text.
    """
    text = extract_pdf_text(product["pdf_path"])
    if not text or len(text.strip()) < 100:
        return None
    doc = Document(
        page_content=text,
        metadata={
            "product_id": product["id"],
            "product_name": product["name"],
            "reaction_type": product["reaction_type"],
            "source": product["pdf_path"]
        }
    )
    return FAISS.from_documents([doc], cached_embeddings)

def get_product_by_id(product_id: str) -> Optional[Dict[str, Any]]:
    for p in _products_registry:
        if p["id"] == product_id:
            return p
    return None

# -------------------------
# Startup - load product registry
# -------------------------
@app.on_event("startup")
def startup_load_products():
    global _products_registry
    logger.info("Loading product database from %s", PRODUCTS_DIR)
    _products_registry = load_product_database()
    logger.info("Loaded %d products", len(_products_registry))

# -------------------------
# API Endpoints
# -------------------------

# Health
@app.get("/health")
@app.get("/api/health")
def health():
    return {"status": "ok", "products_count": len(_products_registry)}

# List reaction types
@app.get("/reactions")
@app.get("/api/reactions")
def list_reactions():
    return {"reactions": REACTION_TYPES}

# List products (optionally by reaction type)
@app.get("/products")
@app.get("/api/products")
def list_products(reaction_type: Optional[str] = Query(None, description="Filter by reaction type")):
    if reaction_type:
        matched = [p for p in _products_registry if p["reaction_type"] == reaction_type]
        return {"count": len(matched), "products": matched}
    return {"count": len(_products_registry), "products": _products_registry}

# Endpoint used by your React frontend in earlier code: /api/reaction?type=...
@app.get("/reaction")
@app.get("/api/reaction")
def reaction_query(type: str = Query(..., alias="type")):
    # mirror process_reaction_query
    products = [p for p in _products_registry if p["reaction_type"] == type]
    if not products:
        return {"message": f"No products found for {type}", "products": []}
    return {"message": f"Found {len(products)} products for {type}:", "products": products}

# Get product metadata (and optionally details)
@app.get("/product/{product_id}")
@app.get("/api/product/{product_id}")
def product_metadata(product_id: str = Path(...), include_details: bool = Query(False)):
    product = get_product_by_id(product_id)
    if not product:
        raise HTTPException(status_code=404, detail="Product not found")
    result = {"product": product}
    if include_details:
        # Try to fetch cached details or build the QA chain
        details = _product_details_cache.get(product_id)
        if not details:
            details = process_product_query_sync(product)
            if not details:
                raise HTTPException(status_code=500, detail="Failed to extract product details")
        result["details"] = details
    return result

# Download PDF
@app.get("/product/{product_id}/download")
@app.get("/api/product/{product_id}/download")
def download_product_pdf(product_id: str = Path(...)):
    product = get_product_by_id(product_id)
    if not product:
        raise HTTPException(status_code=404, detail="Product not found")
    pdf_path = product.get("pdf_path")
    if not pdf_path or not os.path.exists(pdf_path):
        raise HTTPException(status_code=404, detail="PDF file not found")
    # Stream file for download
    return FileResponse(path=pdf_path, filename=os.path.basename(pdf_path), media_type="application/pdf")

# Serve scheme image
@app.get("/product/{product_id}/scheme")
@app.get("/api/product/{product_id}/scheme")
def get_scheme_image(product_id: str = Path(...)):
    product = get_product_by_id(product_id)
    if not product:
        raise HTTPException(status_code=404, detail="Product not found")
    img = product.get("scheme_image")
    if not img or not os.path.exists(img):
        raise HTTPException(status_code=404, detail="Scheme image not found")
    # Return image file
    return FileResponse(path=img, filename=os.path.basename(img), media_type="image/png")

# Download CDX (ChemDraw) if available
@app.get("/product/{product_id}/download_cdx")
@app.get("/api/product/{product_id}/download_cdx")
def download_product_cdx(product_id: str = Path(...)):
    product = get_product_by_id(product_id)
    if not product:
        raise HTTPException(status_code=404, detail="Product not found")
    cdx = product.get("scheme_cdx")
    if not cdx or not os.path.exists(cdx):
        raise HTTPException(status_code=404, detail="CDX not found")
    return FileResponse(path=cdx, filename=os.path.basename(cdx), media_type="application/octet-stream")

# Endpoint to run the RetrievalQA and return the structured details (synchronous)
@app.get("/product/{product_id}/details")
@app.get("/api/product/{product_id}/details")
def product_details(product_id: str = Path(...)):
    product = get_product_by_id(product_id)
    if not product:
        raise HTTPException(status_code=404, detail="Product not found")
    # return cached if present
    if product_id in _product_details_cache:
        return {"product_id": product_id, "details": _product_details_cache[product_id], "cached": True}
    details = process_product_query_sync(product)
    if not details:
        raise HTTPException(status_code=500, detail="Failed to process product document")
    _product_details_cache[product_id] = details
    return {"product_id": product_id, "details": details, "cached": False}

# A convenience endpoint to run an arbitrary query against a product's vectorstore (for dev)
@app.post("/product/{product_id}/query")
@app.post("/api/product/{product_id}/query")
def product_query(product_id: str = Path(...), query: Dict[str, Any] = Body(...)):
    """
    Body: { "query": "Extract API Name ..." }
    """
    product = get_product_by_id(product_id)
    if not product:
        raise HTTPException(status_code=404, detail="Product not found")
    q = query.get("query")
    if not q:
        raise HTTPException(status_code=400, detail="Missing 'query' in request body")
    vector_store = build_product_vector_store(product)
    if not vector_store:
        raise HTTPException(status_code=500, detail="Failed to build vector store for product")
    retriever = vector_store.as_retriever(search_kwargs={"k": 1})
    qa_chain = RetrievalQA.from_chain_type(
        llm=chat_model,
        chain_type="stuff",
        retriever=retriever,
        chain_type_kwargs={"prompt": PROMPT},
        return_source_documents=False
    )
    # Call the chain:
    try:
        response = qa_chain.invoke({"query": q})["result"]
    except Exception as e:
        logger.exception("QA chain invocation failed: %s", str(e))
        raise HTTPException(status_code=500, detail=f"QA chain failed: {str(e)}")
    return {"product_id": product_id, "result": response}

# -------------------------
# Under-the-hood product processing function (sync)
# -------------------------
def process_product_query_sync(product: Dict[str, Any]) -> Optional[str]:
    """
    Mirrors streamlit process_product_query: builds vector store, creates retriever, runs RetrievalQA,
    and returns the QA result string (which will contain the structured sections).
    """
    try:
        vector_store = build_product_vector_store(product)
        if not vector_store:
            logger.warning("Vector store not created for product %s", product["id"])
            return None
        retriever = vector_store.as_retriever(search_kwargs={"k": 1})
        qa_chain = RetrievalQA.from_chain_type(
            llm=chat_model,
            chain_type="stuff",
            retriever=retriever,
            chain_type_kwargs={"prompt": PROMPT},
            return_source_documents=False
        )
        query = "Extract API Name, Reaction Chemistry, Yield, Procedure, and Tabular Data"
        # invoke the chain similar to streamlit
        try:
            response = qa_chain.invoke({"query": query})["result"]
        except Exception as e:
            # Try fallback: call run (some versions use qa_chain.run)
            logger.exception("qa_chain.invoke failed, attempting qa_chain.run: %s", str(e))
            try:
                response = qa_chain.run(query)
            except Exception as e2:
                logger.exception("qa_chain.run also failed: %s", str(e2))
                raise
        return response
    except Exception as e:
        logger.exception("process_product_query_sync failed for %s: %s", product.get("id"), str(e))
        return None

# -------------------------
# Login backend (kept as-is, combined)
# -------------------------
# NOTE: This block uses your provided login snippet. It expects 'config.check_ldap_auth' to be available.
from fastapi.security import HTTPBasic
from datetime import datetime, timedelta
from jose import jwt
from pydantic import BaseModel
from pymongo import MongoClient
import config  # your external config with check_ldap_auth etc
from typing import Optional

# 🔐 JWT Config
SECRET_KEY = "myFAV"
ALGORITHM = ""
ACCESS_TOKEN_EXPIRE_MINUTES = 60

# 🚀 Security
security = HTTPBasic()

# 🔓 Login Endpoint (kept as you provided)
def create_access_token(data: dict, expires_delta: Optional[timedelta] = None):
    to_encode = data.copy()
    expire = datetime.utcnow() + (expires_delta or timedelta(minutes=15))
    to_encode.update({"exp": expire})
    return jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)

@app.post("/login")
async def login(user_info: dict = Depends(config.check_ldap_auth)):
    if not user_info:
        raise HTTPException(status_code=400, detail="Invalid Credentials")

    access_token_expires = timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
    access_token = create_access_token(
        data={"sub": user_info["first_name"]},
        expires_delta=access_token_expires
    )

    return {
        "access_token": access_token,
        "token_type": "Bearer",
        "firstname": user_info["first_name"],
        "lastname": user_info["last_name"],
    }

# -------------------------
# Run with Uvicorn (if executed directly)
# -------------------------
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)
