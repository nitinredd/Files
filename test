import os
import streamlit as st
import tempfile
import logging
from io import BytesIO
import json
import time
import google.auth
from vertexai.preview.generative_models import GenerativeModel, Image as GeminiImage, Part, HarmCategory, HarmBlockThreshold, SafetySetting
import fitz  # PyMuPDF
from docx import Document
from docx.shared import Pt
import re
from moviepy.editor import VideoFileClip, AudioFileClip, TextClip, CompositeVideoClip
from gtts import gTTS

# Configure logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

# Gemini configuration as per template (no location specified)
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "D:/datascience-254609-genai.json"
credentials, project_id = google.auth.default()
multimodal_model = GenerativeModel("gemini-2.0-flash-thinking-exp-01-21")  # For translation

# Model and Safety settings required for Gemini filter
safety_config = [
    SafetySetting(
        category=HarmCategory.HARM_CATEGORY_UNSPECIFIED,
        threshold=HarmBlockThreshold.BLOCK_NONE,
    ),
    SafetySetting(
        category=HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
        threshold=HarmBlockThreshold.BLOCK_NONE,
    ),
    SafetySetting(
        category=HarmCategory.HARM_CATEGORY_HARASSMENT,
        threshold=HarmBlockThreshold.BLOCK_NONE,
    ),
    SafetySetting(
        category=HarmCategory.HARM_CATEGORY_HATE_SPEECH,
        threshold=HarmBlockThreshold.BLOCK_NONE,
    ),
    SafetySetting(
        category=HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
        threshold=HarmBlockThreshold.BLOCK_NONE,
    ),
]

# Initialize Gemini-1.5 for audio transcription (using your Gemini configuration style)
transcription_model = GenerativeModel("gemini-1.5-flash-002")

#############################################
# Gemini-based Audio Transcription Function
#############################################
def transcribe_audio(audio_path):
    """
    Transcribe the audio using Gemini-1.5.
    Reads the local audio file by creating a file:// URI and sends it along with a prompt
    asking for a transcription (with timecodes, speaker labels, and captions).
    """
    try:
        # Create a URI from the local file path
        audio_uri = f"file://{audio_path}"
        audio_part = Part.from_uri(audio_uri, mime_type="audio/mpeg")
        prompt = (
            "Can you transcribe this interview in the format of timecode, speaker, caption.\n"
            "Use speaker A, speaker B, etc. to identify speakers."
        )
        contents = [audio_part, prompt]
        response = transcription_model.generate_content(contents, safety_settings=safety_config)
        logger.debug(f"Transcription response: {response.text}")
        return response.text
    except Exception as e:
        logger.error(f"Transcription error: {str(e)}")
        return ""

#############################################
# Gemini-based Translation Function
#############################################
def translate_text(text, target_language="Spanish"):
    """
    Translate English text to the target language using Gemini.
    """
    if not text:
        return ""
    prompt = f"Translate the following English text to {target_language}:\n\n{text}"
    try:
        responses = multimodal_model.generate_content([prompt], safety_settings=safety_config)
        translated = responses.text if hasattr(responses, 'text') else ''.join([r.text for r in responses])
        logger.debug(f"Translated text: {translated}")
        return translated
    except Exception as e:
        logger.error(f"Translation error: {str(e)}")
        return text

#############################################
# Generate Spanish Audio using gTTS
#############################################
def generate_spanish_audio(text, output_path):
    try:
        tts = gTTS(text=text, lang='es')
        tts.save(output_path)
        logger.debug(f"Spanish audio saved to {output_path}")
    except Exception as e:
        logger.error(f"gTTS error: {str(e)}")

#############################################
# Create Approximate Subtitles from Transcript
#############################################
def create_subtitles(text, video_duration):
    """
    Split the transcript into sentences and evenly distribute them across the video duration.
    This provides approximate timings for subtitles.
    """
    sentences = re.split(r'(?<=[.!?]) +', text)
    sentences = [s.strip() for s in sentences if s.strip()]
    num_sentences = len(sentences)
    if num_sentences == 0:
        return []
    duration_per_sentence = video_duration / num_sentences
    subtitles = []
    current_time = 0
    for sentence in sentences:
        start = current_time
        end = current_time + duration_per_sentence
        subtitles.append((start, end, sentence))
        current_time = end
    logger.debug(f"Created {len(subtitles)} subtitle segments.")
    return subtitles

#############################################
# Merge Video, New Audio, and Subtitles
#############################################
def merge_video_audio(video_path, audio_path, subtitles, output_path):
    video = VideoFileClip(video_path)
    audio = AudioFileClip(audio_path)
    # Replace original audio with the new Spanish audio
    video = video.set_audio(audio)

    subtitle_clips = []
    for start, end, text in subtitles:
        # Create a TextClip for each subtitle segment
        txt_clip = TextClip(
            text,
            fontsize=24,
            color='white',
            bg_color='black',
            method='caption',
            size=(video.w, None)
        )
        txt_clip = txt_clip.set_position(('center', 'bottom')).set_start(start).set_duration(end - start)
        subtitle_clips.append(txt_clip)
    
    final_video = CompositeVideoClip([video, *subtitle_clips])
    final_video.write_videofile(output_path, codec='libx264', audio_codec='aac')
    final_video.close()
    video.close()
    audio.close()

#############################################
# Main Streamlit Application
#############################################
def main():
    st.title("Video Translator: English â†’ Spanish with Subtitles")
    st.write("Upload an English video to translate its audio to Spanish and overlay English subtitles.")

    uploaded_video = st.file_uploader("Upload Video", type=["mp4", "mov", "avi"])
    
    if uploaded_video is not None:
        # Save the uploaded video to a temporary file.
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as temp_video_file:
            temp_video_file.write(uploaded_video.read())
            temp_video_path = temp_video_file.name
        
        st.video(temp_video_path)

        if st.button("Translate Video"):
            # Initialize temp file variables to None so that cleanup works even on error.
            temp_video_path_var = temp_video_path
            temp_audio_path = None
            temp_spanish_audio_path = None
            try:
                # Extract video duration and audio
                video_clip = VideoFileClip(temp_video_path_var)
                video_duration = video_clip.duration
                with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as temp_audio_file:
                    temp_audio_path = temp_audio_file.name
                video_clip.audio.write_audiofile(temp_audio_path, codec='mp3')
                video_clip.close()

                st.info("Transcribing audio using Gemini-1.5...")
                transcript = transcribe_audio(temp_audio_path)
                if not transcript:
                    st.error("Could not transcribe audio.")
                    return

                st.info("Translating transcript to Spanish...")
                translated_text = translate_text(transcript, target_language="Spanish")

                st.info("Generating Spanish audio...")
                with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as temp_spanish_audio_file:
                    temp_spanish_audio_path = temp_spanish_audio_file.name
                generate_spanish_audio(translated_text, temp_spanish_audio_path)

                st.info("Creating subtitles...")
                subtitles = create_subtitles(transcript, video_duration)

                st.info("Merging video, audio, and subtitles...")
                with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as temp_output_video_file:
                    output_video_path = temp_output_video_file.name
                merge_video_audio(temp_video_path_var, temp_spanish_audio_path, subtitles, output_video_path)

                st.success("Video translation completed!")
                st.video(output_video_path)
                with open(output_video_path, "rb") as video_file:
                    st.download_button("Download Translated Video",
                                       video_file.read(),
                                       file_name="translated_video.mp4",
                                       mime="video/mp4")
            except Exception as e:
                st.error(f"An error occurred during processing: {str(e)}")
                logger.exception("Processing error")
            finally:
                # Clean up temporary files if they were created
                for path in [temp_video_path_var, temp_audio_path, temp_spanish_audio_path]:
                    if path is not None and os.path.exists(path):
                        try:
                            os.remove(path)
                        except Exception as cleanup_e:
                            logger.error(f"Error cleaning up temporary file {path}: {cleanup_e}")

if __name__ == "__main__":
    main()
