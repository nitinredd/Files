# Add to imports
import numpy as np
from tqdm import tqdm

def predictive_optimal_combinations_advanced(ref_df, test_df, regulation, 
                                            window_min, window_max, diff_threshold,
                                            num_samples=500000):
    """Ultra-fast version with precomputation and vectorization"""
    # ===== 1. PRECOMPUTE DISSOLUTION VALUES =====
    # Create dense time grid (1-minute resolution)
    time_grid = np.arange(window_min, window_max + 1)
    
    # Create interpolation functions
    ref_f = interp1d(ref_df.iloc[:,0], ref_df.iloc[:,1], 
                    bounds_error=False, fill_value="extrapolate")
    test_f = interp1d(test_df.iloc[:,0], test_df.iloc[:,1],
                     bounds_error=False, fill_value="extrapolate")
    
    # Precompute values for all possible times
    ref_values = ref_f(time_grid)
    test_values = test_f(time_grid)
    
    # ===== 2. GENERATE TIME POINTS =====
    max_diss = max(ref_values.max(), test_values.max())
    if max_diss <= 60:
        step_mask = (time_grid % 3 == 0) | (time_grid % 5 == 0)
    else:
        step_mask = time_grid % 5 == 0
    
    valid_times = time_grid[step_mask]
    if 0 not in valid_times:
        valid_times = np.insert(valid_times, 0, 0)
    
    # ===== 3. VECTORIZED SAMPLING =====
    start_time = time.time()
    
    # Generate all sequences at once
    seq_lengths = np.random.randint(3, 7, num_samples)
    all_seqs = []
    
    # Progress bar setup
    pbar = tqdm(total=num_samples, desc="Generating combinations")
    
    for i in range(num_samples):
        # Create sequence with 0 and window_max
        seq = np.sort(np.random.choice(
            valid_times[(valid_times > 0) & (valid_times < window_max)],
            size=seq_lengths[i]-2,
            replace=False
        ))
        seq = np.insert(seq, 0, 0)
        seq = np.append(seq, window_max)
        all_seqs.append(seq)
        pbar.update(1)
    pbar.close()
    
    # ===== 4. VECTORIZED COMPUTATIONS =====
    # Convert to numpy array of arrays
    all_seqs = np.array([np.pad(s, (0, 6-len(s)), mode='constant') for s in all_seqs])
    
    # Get dissolution values (vectorized)
    ref_diss = ref_values[all_seqs]
    test_diss = test_values[all_seqs]
    
    # Calculate F2 scores
    diffs = test_diss - ref_diss
    valid_mask = ~np.isnan(diffs)
    sum_sq = np.nansum(diffs**2, axis=1)
    lengths = np.sum(valid_mask, axis=1)
    f2_scores = 100 - 25 * np.log10(1 + (sum_sq/lengths))
    
    # ===== 5. FIND BEST RESULT =====
    best_idx = np.nanargmax(f2_scores)
    
    print(f"\nProcessed {num_samples} combinations in {time.time()-start_time:.2f}s")
    
    return {
        "sequence": all_seqs[best_idx][:lengths[best_idx]],
        "f2": f2_scores[best_idx],
        "time_points": valid_times
    }, f2_scores
