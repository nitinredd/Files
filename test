import os
import google.auth
import time
import logging
from vertexai.preview.generative_models import (
    GenerativeModel,
    Image as GeminiImage,
    Part,
    HarmCategory,
    HarmBlockThreshold,
    SafetySetting
)

# ── ENVIRONMENT & AUTH ─────────────────────────────────────────────
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "D:/datascience-254609-genai.json"
credentials, project_id = google.auth.default()

# ── MODEL INITIALIZATION ───────────────────────────────────────────
multimodal_model = GenerativeModel("gemini-2.0-flash-thinking-exp-01-21")

# ── SAFETY SETTINGS ────────────────────────────────────────────────
safety_config = [
    SafetySetting(
        category=HarmCategory.HARM_CATEGORY_UNSPECIFIED,
        threshold=HarmBlockThreshold.BLOCK_NONE,
    ),
    SafetySetting(
        category=HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
        threshold=HarmBlockThreshold.BLOCK_NONE,
    ),
    SafetySetting(
        category=HarmCategory.HARM_CATEGORY_HARASSMENT,
        threshold=HarmBlockThreshold.BLOCK_NONE,
    ),
    SafetySetting(
        category=HarmCategory.HARM_CATEGORY_HATE_SPEECH,
        threshold=HarmBlockThreshold.BLOCK_NONE,
    ),
    SafetySetting(
        category=HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
        threshold=HarmBlockThreshold.BLOCK_NONE,
    ),
]

# ── LOGGING ────────────────────────────────────────────────────────
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ── GEMINI CLIENT ──────────────────────────────────────────────────
class GeminiClient:
    def __init__(self):
        self.model = multimodal_model
        self.safety_settings = safety_config
        self.max_retries = 3
        self.retry_delay = 1

    def generate_content(self, prompt, stream=False, generation_config=None) -> str:
        for attempt in range(self.max_retries):
            try:
                response = self.model.generate_content(
                    contents=prompt,
                    generation_config=generation_config or {
                        "max_output_tokens": 1024,
                        "temperature": 0.2
                    },
                    safety_settings=self.safety_settings,
                    stream=stream
                )
                return self._handle_response(response)
            except Exception as e:
                logger.warning(f"Attempt {attempt + 1} failed: {e}")
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay * (attempt + 1))
                    continue
                raise

    def _handle_response(self, response) -> str:
        if getattr(response, "candidates", None):
            return response.candidates[0].content.text
        if getattr(response, "filters", None):
            reasons = [f"{f.category.name}:{f.action.name}" for f in response.filters]
            raise ValueError("Blocked: " + ", ".join(reasons))
        raise ValueError("Empty response")

# ── SAFE CALL EXAMPLE (OPTIONAL) ───────────────────────────────────
def safe_gemini_call(image, max_retries=3, delay=2):
    prompt = get_safe_extraction_prompt()  # Make sure you define this function
    for attempt in range(max_retries):
        try:
            response = multimodal_model.generate_content(
                [
                    prompt,
                    image
                ],
                safety_settings=safety_config
            )
            return response.candidates[0].content.text
        except Exception as e:
            logger.warning(f"Attempt {attempt + 1} failed: {e}")
            if attempt < max_retries - 1:
                time.sleep(delay * (attempt + 1))
                continue
            raise
